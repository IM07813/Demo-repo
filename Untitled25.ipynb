{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0956d21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "Accuracy: 0.9991398774325342\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "features_df = pd.read_csv('features.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn import svm \n",
    "from sklearn.metrics import accuracy_score \n",
    "features_df.head() \n",
    "# Extract the MFCC features and corresponding labels \n",
    "X = features_df.iloc[:, :-1]  # Assuming MFCC features are in columns 1 to n \n",
    "y = features_df.iloc[:, -1]  # Assuming labels are in the first column \n",
    "X.head() \n",
    "y.head() \n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "# Initialize the LabelEncoder \n",
    "label_encoder = LabelEncoder() \n",
    " \n",
    "# Encode the labels \n",
    "y = label_encoder.fit_transform(y) \n",
    " \n",
    "# Print the encoded DataFrame \n",
    "print(y) \n",
    " \n",
    "X.shape, y.shape \n",
    "# Split the dataset into training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "# Standardize the features \n",
    "scaler = StandardScaler() \n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test = scaler.transform(X_test) \n",
    "# Initialize and train the machine learning algorithm (e.g., Support Vector Machine) \n",
    "model = svm.SVC() \n",
    "model.fit(X_train, y_train) \n",
    "# Predict the labels for the test set \n",
    "y_pred = model.predict(X_test) \n",
    "# Evaluate the accuracy of the model \n",
    "accuracy = accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy:\", accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7731ea76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained SVM model to a file\n",
    "joblib.dump(model, 'svm_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e8b4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in something directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 1/1 [00:00<00:00, 14716.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "\n",
    "        # MFCC (Mel-frequency cepstral coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "        # Chroma feature\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral contrast\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral centroid\n",
    "        spectral_centroids = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Zero-crossing rate\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio).T, axis=0)\n",
    "\n",
    "        # Spectral rolloff\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Combine all features into a 1D array\n",
    "        features = np.hstack([mfccs_processed, chroma_stft, spectral_contrast, spectral_centroids, zero_crossing_rate, spectral_rolloff])\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_name}\")\n",
    "        return None\n",
    "\n",
    "# Specify the directory containing the .mp3 files\n",
    "directory = 'something'\n",
    "\n",
    "# Create an empty DataFrame to store the features\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "print(f\"Processing files in {directory} directory\")\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith('.mp3'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            features = extract_features(file_path)\n",
    "            # Append the features to the DataFrame\n",
    "            if features is not None:\n",
    "                features_df = features_df.append(pd.Series(features), ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered while processing file: {file_path}\")\n",
    "            continue\n",
    "\n",
    "# Rename the DataFrame columns as needed\n",
    "# features_df.columns = [list_of_feature_names]\n",
    "\n",
    "# Now, you have the features in the 'features_df' DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "404e9a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in something directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "\n",
    "        # MFCC (Mel-frequency cepstral coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "        # Chroma feature\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral contrast\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral centroid\n",
    "        spectral_centroids = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Zero-crossing rate\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio).T, axis=0)\n",
    "\n",
    "        # Spectral rolloff\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Combine all features into a 1D array\n",
    "        features = np.hstack([mfccs_processed, chroma_stft, spectral_contrast, spectral_centroids, zero_crossing_rate, spectral_rolloff])\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_name}\")\n",
    "        return None\n",
    "\n",
    "# Specify the directories containing the .mp3 files\n",
    "directories = ['something']\n",
    "\n",
    "# Create an empty DataFrame to store the features\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "for directory in directories:\n",
    "    print(f\"Processing files in {directory} directory\")\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                features = extract_features(file_path)\n",
    "                # Append the features to the DataFrame as a new row\n",
    "                if features is not None:\n",
    "                    features_series = pd.Series(features)\n",
    "                    features_df = pd.concat([features_df, features_series], axis=0)  # Concatenate along rows (axis=0)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered while processing file: {file_path}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "# Rename the DataFrame columns as needed\n",
    "# features_df.columns = [list_of_feature_names]\n",
    "\n",
    "# Now, you have the features in the 'features_df' DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99bee43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-295.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.629883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-17.675768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-12.216038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.229759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0 -295.009888\n",
       "1   77.629883\n",
       "2  -17.675768\n",
       "3  -12.216038\n",
       "4  -32.229759"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71947f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data= features_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09024ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-295.009888</td>\n",
       "      <td>77.629883</td>\n",
       "      <td>-17.675768</td>\n",
       "      <td>-12.216038</td>\n",
       "      <td>-32.229759</td>\n",
       "      <td>7.095298</td>\n",
       "      <td>-43.206612</td>\n",
       "      <td>5.056969</td>\n",
       "      <td>-26.058151</td>\n",
       "      <td>1.967294</td>\n",
       "      <td>...</td>\n",
       "      <td>16.61427</td>\n",
       "      <td>18.739539</td>\n",
       "      <td>20.115752</td>\n",
       "      <td>18.420383</td>\n",
       "      <td>19.458295</td>\n",
       "      <td>17.778198</td>\n",
       "      <td>42.708423</td>\n",
       "      <td>2599.433174</td>\n",
       "      <td>0.152152</td>\n",
       "      <td>4829.782551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4         5   \\\n",
       "0 -295.009888  77.629883 -17.675768 -12.216038 -32.229759  7.095298   \n",
       "\n",
       "          6         7          8         9   ...        52         53  \\\n",
       "0 -43.206612  5.056969 -26.058151  1.967294  ...  16.61427  18.739539   \n",
       "\n",
       "          54         55         56         57         58           59  \\\n",
       "0  20.115752  18.420383  19.458295  17.778198  42.708423  2599.433174   \n",
       "\n",
       "         60           61  \n",
       "0  0.152152  4829.782551  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40f33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a82eaa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved SVM model\n",
    "loaded_model = joblib.load('svm_model.pkl')\n",
    "\n",
    "# Now you can use the loaded_model for predictions\n",
    "# Replace with your new data\n",
    "predictions = loaded_model.predict(new_data)\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dc0117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "class_labels = loaded_model.classes_\n",
    "print(class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b84b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = [class_labels[prediction] for prediction in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7665a666",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but SVC is expecting 62 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Now you can use the loaded_model for predictions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m new_data \u001b[38;5;241m=\u001b[39m features_df  \u001b[38;5;66;03m# Replace with your new data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get the class labels from the model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m class_labels \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mclasses_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:820\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    818\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:433\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:613\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    610\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 613\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39misspmatrix(X):\n\u001b[1;32m    623\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features, but SVC is expecting 62 features as input."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved SVM model\n",
    "loaded_model = joblib.load('svm_model.pkl')\n",
    "\n",
    "# Now you can use the loaded_model for predictions\n",
    "new_data = features_df  # Replace with your new data\n",
    "predictions = loaded_model.predict(new_data)\n",
    "\n",
    "# Get the class labels from the model\n",
    "class_labels = loaded_model.classes_\n",
    "\n",
    "# Map the predictions to actual class labels\n",
    "predicted_labels = [class_labels[prediction] for prediction in predictions]\n",
    "\n",
    "print(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9418212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
