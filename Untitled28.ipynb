{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19874e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording audio for 1 minute...\n",
      "Finished recording.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Continuous loop for recording and classifying audio\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[43mrecord_and_classify_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Sleep for a few seconds before starting the next recording\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Adjust the sleep duration as needed\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 45\u001b[0m, in \u001b[0;36mrecord_and_classify_audio\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m recorded_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([recorded_features])\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Standardize the features (like you did with the training data)\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m recorded_df \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(recorded_df)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Feed the features to the trained PyTorch model for classification\u001b[39;00m\n\u001b[1;32m     48\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import os\n",
    "\n",
    "def record_and_classify_audio():\n",
    "    # Record audio for 1 minute\n",
    "    audio_duration = 60  # 1 minute\n",
    "    sample_rate = 44100  # You may need to adjust this based on your audio device\n",
    "\n",
    "    audio_frames = []\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    print(\"Recording audio for 1 minute...\")\n",
    "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=sample_rate, input=True, frames_per_buffer=1024)\n",
    "\n",
    "    for _ in range(0, int(sample_rate / 1024 * audio_duration)):\n",
    "        data = stream.read(1024)\n",
    "        audio_frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Save the recorded audio to a WAV file\n",
    "    output_audio_file = \"recorded_audio.wav\"\n",
    "    wf = wave.open(output_audio_file, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(sample_rate)\n",
    "    wf.writeframes(b''.join(audio_frames))\n",
    "    wf.close()\n",
    "\n",
    "    # Now, extract features from the recorded audio\n",
    "    recorded_features = extract_features(output_audio_file)\n",
    "\n",
    "    # Check if features are successfully extracted\n",
    "    if recorded_features is not None:\n",
    "        # Convert the features to a pandas DataFrame\n",
    "        recorded_df = pd.DataFrame([recorded_features])\n",
    "\n",
    "        # Standardize the features (like you did with the training data)\n",
    "        recorded_df = scaler.transform(recorded_df)\n",
    "\n",
    "        # Feed the features to the trained PyTorch model for classification\n",
    "        model.eval()\n",
    "        recorded_tensor = torch.tensor(recorded_df, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            predicted_output = model(recorded_tensor.unsqueeze(1))\n",
    "            _, predicted_class = torch.max(predicted_output, 1)\n",
    "\n",
    "        # Decode the predicted class using the label encoder\n",
    "        predicted_class_label = label_encoder.inverse_transform(predicted_class.numpy())\n",
    "\n",
    "        # Print the classification result\n",
    "        print(\"Predicted Class:\", predicted_class_label[0])\n",
    "\n",
    "        # Delete the audio file\n",
    "        os.remove(output_audio_file)\n",
    "    else:\n",
    "        print(\"Error occurred while extracting features from recorded audio.\")\n",
    "\n",
    "# Continuous loop for recording and classifying audio\n",
    "while True:\n",
    "    record_and_classify_audio()\n",
    "    # Sleep for a few seconds before starting the next recording\n",
    "    time.sleep(3)  # Adjust the sleep duration as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36751a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
