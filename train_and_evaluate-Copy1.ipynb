{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fddd38ce",
   "metadata": {},
   "source": [
    "## train the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abbfdfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4207, 62)\n",
      "Epoch [1/300], Training Loss: 0.6062\n",
      "Epoch [1/300], Validation Loss: 0.5376, Validation Accuracy: 0.8632\n",
      "Epoch [2/300], Training Loss: 0.5364\n",
      "Epoch [2/300], Validation Loss: 0.4764, Validation Accuracy: 0.9073\n",
      "Epoch [3/300], Training Loss: 0.4746\n",
      "Epoch [3/300], Validation Loss: 0.4226, Validation Accuracy: 0.9301\n",
      "Epoch [4/300], Training Loss: 0.4205\n",
      "Epoch [4/300], Validation Loss: 0.3759, Validation Accuracy: 0.9416\n",
      "Epoch [5/300], Training Loss: 0.3734\n",
      "Epoch [5/300], Validation Loss: 0.3354, Validation Accuracy: 0.9494\n",
      "Epoch [6/300], Training Loss: 0.3328\n",
      "Epoch [6/300], Validation Loss: 0.3005, Validation Accuracy: 0.9544\n",
      "Epoch [7/300], Training Loss: 0.2978\n",
      "Epoch [7/300], Validation Loss: 0.2704, Validation Accuracy: 0.9579\n",
      "Epoch [8/300], Training Loss: 0.2677\n",
      "Epoch [8/300], Validation Loss: 0.2445, Validation Accuracy: 0.9629\n",
      "Epoch [9/300], Training Loss: 0.2419\n",
      "Epoch [9/300], Validation Loss: 0.2222, Validation Accuracy: 0.9665\n",
      "Epoch [10/300], Training Loss: 0.2197\n",
      "Epoch [10/300], Validation Loss: 0.2029, Validation Accuracy: 0.9679\n",
      "Epoch [11/300], Training Loss: 0.2006\n",
      "Epoch [11/300], Validation Loss: 0.1862, Validation Accuracy: 0.9701\n",
      "Epoch [12/300], Training Loss: 0.1840\n",
      "Epoch [12/300], Validation Loss: 0.1717, Validation Accuracy: 0.9729\n",
      "Epoch [13/300], Training Loss: 0.1697\n",
      "Epoch [13/300], Validation Loss: 0.1590, Validation Accuracy: 0.9751\n",
      "Epoch [14/300], Training Loss: 0.1571\n",
      "Epoch [14/300], Validation Loss: 0.1479, Validation Accuracy: 0.9758\n",
      "Epoch [15/300], Training Loss: 0.1462\n",
      "Epoch [15/300], Validation Loss: 0.1381, Validation Accuracy: 0.9758\n",
      "Epoch [16/300], Training Loss: 0.1366\n",
      "Epoch [16/300], Validation Loss: 0.1294, Validation Accuracy: 0.9765\n",
      "Epoch [17/300], Training Loss: 0.1281\n",
      "Epoch [17/300], Validation Loss: 0.1217, Validation Accuracy: 0.9765\n",
      "Epoch [18/300], Training Loss: 0.1205\n",
      "Epoch [18/300], Validation Loss: 0.1149, Validation Accuracy: 0.9786\n",
      "Epoch [19/300], Training Loss: 0.1138\n",
      "Epoch [19/300], Validation Loss: 0.1087, Validation Accuracy: 0.9793\n",
      "Epoch [20/300], Training Loss: 0.1078\n",
      "Epoch [20/300], Validation Loss: 0.1032, Validation Accuracy: 0.9800\n",
      "Epoch [21/300], Training Loss: 0.1024\n",
      "Epoch [21/300], Validation Loss: 0.0982, Validation Accuracy: 0.9800\n",
      "Epoch [22/300], Training Loss: 0.0975\n",
      "Epoch [22/300], Validation Loss: 0.0937, Validation Accuracy: 0.9808\n",
      "Epoch [23/300], Training Loss: 0.0931\n",
      "Epoch [23/300], Validation Loss: 0.0896, Validation Accuracy: 0.9815\n",
      "Epoch [24/300], Training Loss: 0.0891\n",
      "Epoch [24/300], Validation Loss: 0.0859, Validation Accuracy: 0.9822\n",
      "Epoch [25/300], Training Loss: 0.0854\n",
      "Epoch [25/300], Validation Loss: 0.0824, Validation Accuracy: 0.9822\n",
      "Epoch [26/300], Training Loss: 0.0821\n",
      "Epoch [26/300], Validation Loss: 0.0793, Validation Accuracy: 0.9836\n",
      "Epoch [27/300], Training Loss: 0.0790\n",
      "Epoch [27/300], Validation Loss: 0.0764, Validation Accuracy: 0.9843\n",
      "Epoch [28/300], Training Loss: 0.0761\n",
      "Epoch [28/300], Validation Loss: 0.0737, Validation Accuracy: 0.9850\n",
      "Epoch [29/300], Training Loss: 0.0734\n",
      "Epoch [29/300], Validation Loss: 0.0712, Validation Accuracy: 0.9850\n",
      "Epoch [30/300], Training Loss: 0.0710\n",
      "Epoch [30/300], Validation Loss: 0.0689, Validation Accuracy: 0.9857\n",
      "Epoch [31/300], Training Loss: 0.0687\n",
      "Epoch [31/300], Validation Loss: 0.0667, Validation Accuracy: 0.9865\n",
      "Epoch [32/300], Training Loss: 0.0665\n",
      "Epoch [32/300], Validation Loss: 0.0647, Validation Accuracy: 0.9872\n",
      "Epoch [33/300], Training Loss: 0.0645\n",
      "Epoch [33/300], Validation Loss: 0.0629, Validation Accuracy: 0.9879\n",
      "Epoch [34/300], Training Loss: 0.0627\n",
      "Epoch [34/300], Validation Loss: 0.0611, Validation Accuracy: 0.9879\n",
      "Epoch [35/300], Training Loss: 0.0609\n",
      "Epoch [35/300], Validation Loss: 0.0594, Validation Accuracy: 0.9879\n",
      "Epoch [36/300], Training Loss: 0.0593\n",
      "Epoch [36/300], Validation Loss: 0.0579, Validation Accuracy: 0.9879\n",
      "Epoch [37/300], Training Loss: 0.0577\n",
      "Epoch [37/300], Validation Loss: 0.0564, Validation Accuracy: 0.9879\n",
      "Epoch [38/300], Training Loss: 0.0562\n",
      "Epoch [38/300], Validation Loss: 0.0550, Validation Accuracy: 0.9879\n",
      "Epoch [39/300], Training Loss: 0.0549\n",
      "Epoch [39/300], Validation Loss: 0.0537, Validation Accuracy: 0.9879\n",
      "Epoch [40/300], Training Loss: 0.0535\n",
      "Epoch [40/300], Validation Loss: 0.0525, Validation Accuracy: 0.9886\n",
      "Epoch [41/300], Training Loss: 0.0523\n",
      "Epoch [41/300], Validation Loss: 0.0513, Validation Accuracy: 0.9886\n",
      "Epoch [42/300], Training Loss: 0.0511\n",
      "Epoch [42/300], Validation Loss: 0.0502, Validation Accuracy: 0.9886\n",
      "Epoch [43/300], Training Loss: 0.0500\n",
      "Epoch [43/300], Validation Loss: 0.0492, Validation Accuracy: 0.9886\n",
      "Epoch [44/300], Training Loss: 0.0490\n",
      "Epoch [44/300], Validation Loss: 0.0482, Validation Accuracy: 0.9886\n",
      "Epoch [45/300], Training Loss: 0.0480\n",
      "Epoch [45/300], Validation Loss: 0.0472, Validation Accuracy: 0.9886\n",
      "Epoch [46/300], Training Loss: 0.0470\n",
      "Epoch [46/300], Validation Loss: 0.0463, Validation Accuracy: 0.9886\n",
      "Epoch [47/300], Training Loss: 0.0461\n",
      "Epoch [47/300], Validation Loss: 0.0455, Validation Accuracy: 0.9886\n",
      "Epoch [48/300], Training Loss: 0.0453\n",
      "Epoch [48/300], Validation Loss: 0.0446, Validation Accuracy: 0.9886\n",
      "Epoch [49/300], Training Loss: 0.0444\n",
      "Epoch [49/300], Validation Loss: 0.0439, Validation Accuracy: 0.9886\n",
      "Epoch [50/300], Training Loss: 0.0437\n",
      "Epoch [50/300], Validation Loss: 0.0431, Validation Accuracy: 0.9886\n",
      "Epoch [51/300], Training Loss: 0.0429\n",
      "Epoch [51/300], Validation Loss: 0.0424, Validation Accuracy: 0.9886\n",
      "Epoch [52/300], Training Loss: 0.0422\n",
      "Epoch [52/300], Validation Loss: 0.0417, Validation Accuracy: 0.9900\n",
      "Epoch [53/300], Training Loss: 0.0415\n",
      "Epoch [53/300], Validation Loss: 0.0410, Validation Accuracy: 0.9900\n",
      "Epoch [54/300], Training Loss: 0.0409\n",
      "Epoch [54/300], Validation Loss: 0.0404, Validation Accuracy: 0.9900\n",
      "Epoch [55/300], Training Loss: 0.0402\n",
      "Epoch [55/300], Validation Loss: 0.0398, Validation Accuracy: 0.9900\n",
      "Epoch [56/300], Training Loss: 0.0396\n",
      "Epoch [56/300], Validation Loss: 0.0392, Validation Accuracy: 0.9900\n",
      "Epoch [57/300], Training Loss: 0.0390\n",
      "Epoch [57/300], Validation Loss: 0.0386, Validation Accuracy: 0.9900\n",
      "Epoch [58/300], Training Loss: 0.0385\n",
      "Epoch [58/300], Validation Loss: 0.0381, Validation Accuracy: 0.9893\n",
      "Epoch [59/300], Training Loss: 0.0380\n",
      "Epoch [59/300], Validation Loss: 0.0376, Validation Accuracy: 0.9893\n",
      "Epoch [60/300], Training Loss: 0.0374\n",
      "Epoch [60/300], Validation Loss: 0.0370, Validation Accuracy: 0.9893\n",
      "Epoch [61/300], Training Loss: 0.0370\n",
      "Epoch [61/300], Validation Loss: 0.0365, Validation Accuracy: 0.9893\n",
      "Epoch [62/300], Training Loss: 0.0365\n",
      "Epoch [62/300], Validation Loss: 0.0361, Validation Accuracy: 0.9893\n",
      "Epoch [63/300], Training Loss: 0.0360\n",
      "Epoch [63/300], Validation Loss: 0.0356, Validation Accuracy: 0.9893\n",
      "Epoch [64/300], Training Loss: 0.0356\n",
      "Epoch [64/300], Validation Loss: 0.0351, Validation Accuracy: 0.9886\n",
      "Epoch [65/300], Training Loss: 0.0351\n",
      "Epoch [65/300], Validation Loss: 0.0347, Validation Accuracy: 0.9886\n",
      "Epoch [66/300], Training Loss: 0.0347\n",
      "Epoch [66/300], Validation Loss: 0.0343, Validation Accuracy: 0.9886\n",
      "Epoch [67/300], Training Loss: 0.0343\n",
      "Epoch [67/300], Validation Loss: 0.0338, Validation Accuracy: 0.9900\n",
      "Epoch [68/300], Training Loss: 0.0339\n",
      "Epoch [68/300], Validation Loss: 0.0334, Validation Accuracy: 0.9914\n",
      "Epoch [69/300], Training Loss: 0.0336\n",
      "Epoch [69/300], Validation Loss: 0.0330, Validation Accuracy: 0.9907\n",
      "Epoch [70/300], Training Loss: 0.0332\n",
      "Epoch [70/300], Validation Loss: 0.0326, Validation Accuracy: 0.9907\n",
      "Epoch [71/300], Training Loss: 0.0328\n",
      "Epoch [71/300], Validation Loss: 0.0322, Validation Accuracy: 0.9893\n",
      "Epoch [72/300], Training Loss: 0.0325\n",
      "Epoch [72/300], Validation Loss: 0.0319, Validation Accuracy: 0.9893\n",
      "Epoch [73/300], Training Loss: 0.0322\n",
      "Epoch [73/300], Validation Loss: 0.0315, Validation Accuracy: 0.9907\n",
      "Epoch [74/300], Training Loss: 0.0318\n",
      "Epoch [74/300], Validation Loss: 0.0312, Validation Accuracy: 0.9907\n",
      "Epoch [75/300], Training Loss: 0.0315\n",
      "Epoch [75/300], Validation Loss: 0.0308, Validation Accuracy: 0.9907\n",
      "Epoch [76/300], Training Loss: 0.0312\n",
      "Epoch [76/300], Validation Loss: 0.0305, Validation Accuracy: 0.9907\n",
      "Epoch [77/300], Training Loss: 0.0309\n",
      "Epoch [77/300], Validation Loss: 0.0301, Validation Accuracy: 0.9907\n",
      "Epoch [78/300], Training Loss: 0.0306\n",
      "Epoch [78/300], Validation Loss: 0.0298, Validation Accuracy: 0.9907\n",
      "Epoch [79/300], Training Loss: 0.0303\n",
      "Epoch [79/300], Validation Loss: 0.0295, Validation Accuracy: 0.9907\n",
      "Epoch [80/300], Training Loss: 0.0300\n",
      "Epoch [80/300], Validation Loss: 0.0292, Validation Accuracy: 0.9907\n",
      "Epoch [81/300], Training Loss: 0.0298\n",
      "Epoch [81/300], Validation Loss: 0.0288, Validation Accuracy: 0.9907\n",
      "Epoch [82/300], Training Loss: 0.0295\n",
      "Epoch [82/300], Validation Loss: 0.0285, Validation Accuracy: 0.9907\n",
      "Epoch [83/300], Training Loss: 0.0292\n",
      "Epoch [83/300], Validation Loss: 0.0282, Validation Accuracy: 0.9907\n",
      "Epoch [84/300], Training Loss: 0.0290\n",
      "Epoch [84/300], Validation Loss: 0.0279, Validation Accuracy: 0.9907\n",
      "Epoch [85/300], Training Loss: 0.0287\n",
      "Epoch [85/300], Validation Loss: 0.0276, Validation Accuracy: 0.9907\n",
      "Epoch [86/300], Training Loss: 0.0285\n",
      "Epoch [86/300], Validation Loss: 0.0274, Validation Accuracy: 0.9907\n",
      "Epoch [87/300], Training Loss: 0.0282\n",
      "Epoch [87/300], Validation Loss: 0.0271, Validation Accuracy: 0.9907\n",
      "Epoch [88/300], Training Loss: 0.0280\n",
      "Epoch [88/300], Validation Loss: 0.0268, Validation Accuracy: 0.9907\n",
      "Epoch [89/300], Training Loss: 0.0277\n",
      "Epoch [89/300], Validation Loss: 0.0265, Validation Accuracy: 0.9914\n",
      "Epoch [90/300], Training Loss: 0.0275\n",
      "Epoch [90/300], Validation Loss: 0.0263, Validation Accuracy: 0.9914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/300], Training Loss: 0.0273\n",
      "Epoch [91/300], Validation Loss: 0.0260, Validation Accuracy: 0.9914\n",
      "Epoch [92/300], Training Loss: 0.0270\n",
      "Epoch [92/300], Validation Loss: 0.0258, Validation Accuracy: 0.9914\n",
      "Epoch [93/300], Training Loss: 0.0268\n",
      "Epoch [93/300], Validation Loss: 0.0255, Validation Accuracy: 0.9914\n",
      "Epoch [94/300], Training Loss: 0.0266\n",
      "Epoch [94/300], Validation Loss: 0.0252, Validation Accuracy: 0.9922\n",
      "Epoch [95/300], Training Loss: 0.0264\n",
      "Epoch [95/300], Validation Loss: 0.0250, Validation Accuracy: 0.9922\n",
      "Epoch [96/300], Training Loss: 0.0262\n",
      "Epoch [96/300], Validation Loss: 0.0248, Validation Accuracy: 0.9922\n",
      "Epoch [97/300], Training Loss: 0.0260\n",
      "Epoch [97/300], Validation Loss: 0.0245, Validation Accuracy: 0.9929\n",
      "Epoch [98/300], Training Loss: 0.0258\n",
      "Epoch [98/300], Validation Loss: 0.0243, Validation Accuracy: 0.9936\n",
      "Epoch [99/300], Training Loss: 0.0256\n",
      "Epoch [99/300], Validation Loss: 0.0241, Validation Accuracy: 0.9936\n",
      "Epoch [100/300], Training Loss: 0.0254\n",
      "Epoch [100/300], Validation Loss: 0.0238, Validation Accuracy: 0.9936\n",
      "Epoch [101/300], Training Loss: 0.0252\n",
      "Epoch [101/300], Validation Loss: 0.0236, Validation Accuracy: 0.9943\n",
      "Epoch [102/300], Training Loss: 0.0250\n",
      "Epoch [102/300], Validation Loss: 0.0234, Validation Accuracy: 0.9943\n",
      "Epoch [103/300], Training Loss: 0.0248\n",
      "Epoch [103/300], Validation Loss: 0.0232, Validation Accuracy: 0.9943\n",
      "Epoch [104/300], Training Loss: 0.0246\n",
      "Epoch [104/300], Validation Loss: 0.0230, Validation Accuracy: 0.9943\n",
      "Epoch [105/300], Training Loss: 0.0244\n",
      "Epoch [105/300], Validation Loss: 0.0228, Validation Accuracy: 0.9943\n",
      "Epoch [106/300], Training Loss: 0.0242\n",
      "Epoch [106/300], Validation Loss: 0.0225, Validation Accuracy: 0.9943\n",
      "Epoch [107/300], Training Loss: 0.0240\n",
      "Epoch [107/300], Validation Loss: 0.0223, Validation Accuracy: 0.9943\n",
      "Epoch [108/300], Training Loss: 0.0238\n",
      "Epoch [108/300], Validation Loss: 0.0221, Validation Accuracy: 0.9943\n",
      "Epoch [109/300], Training Loss: 0.0237\n",
      "Epoch [109/300], Validation Loss: 0.0219, Validation Accuracy: 0.9943\n",
      "Epoch [110/300], Training Loss: 0.0235\n",
      "Epoch [110/300], Validation Loss: 0.0217, Validation Accuracy: 0.9943\n",
      "Epoch [111/300], Training Loss: 0.0233\n",
      "Epoch [111/300], Validation Loss: 0.0215, Validation Accuracy: 0.9943\n",
      "Epoch [112/300], Training Loss: 0.0231\n",
      "Epoch [112/300], Validation Loss: 0.0214, Validation Accuracy: 0.9943\n",
      "Epoch [113/300], Training Loss: 0.0230\n",
      "Epoch [113/300], Validation Loss: 0.0212, Validation Accuracy: 0.9943\n",
      "Epoch [114/300], Training Loss: 0.0228\n",
      "Epoch [114/300], Validation Loss: 0.0210, Validation Accuracy: 0.9943\n",
      "Epoch [115/300], Training Loss: 0.0226\n",
      "Epoch [115/300], Validation Loss: 0.0208, Validation Accuracy: 0.9943\n",
      "Epoch [116/300], Training Loss: 0.0225\n",
      "Epoch [116/300], Validation Loss: 0.0206, Validation Accuracy: 0.9950\n",
      "Epoch [117/300], Training Loss: 0.0223\n",
      "Epoch [117/300], Validation Loss: 0.0204, Validation Accuracy: 0.9950\n",
      "Epoch [118/300], Training Loss: 0.0221\n",
      "Epoch [118/300], Validation Loss: 0.0202, Validation Accuracy: 0.9950\n",
      "Epoch [119/300], Training Loss: 0.0220\n",
      "Epoch [119/300], Validation Loss: 0.0201, Validation Accuracy: 0.9950\n",
      "Epoch [120/300], Training Loss: 0.0218\n",
      "Epoch [120/300], Validation Loss: 0.0199, Validation Accuracy: 0.9950\n",
      "Epoch [121/300], Training Loss: 0.0217\n",
      "Epoch [121/300], Validation Loss: 0.0197, Validation Accuracy: 0.9950\n",
      "Epoch [122/300], Training Loss: 0.0215\n",
      "Epoch [122/300], Validation Loss: 0.0196, Validation Accuracy: 0.9950\n",
      "Epoch [123/300], Training Loss: 0.0214\n",
      "Epoch [123/300], Validation Loss: 0.0194, Validation Accuracy: 0.9950\n",
      "Epoch [124/300], Training Loss: 0.0212\n",
      "Epoch [124/300], Validation Loss: 0.0192, Validation Accuracy: 0.9950\n",
      "Epoch [125/300], Training Loss: 0.0211\n",
      "Epoch [125/300], Validation Loss: 0.0190, Validation Accuracy: 0.9950\n",
      "Epoch [126/300], Training Loss: 0.0209\n",
      "Epoch [126/300], Validation Loss: 0.0189, Validation Accuracy: 0.9950\n",
      "Epoch [127/300], Training Loss: 0.0208\n",
      "Epoch [127/300], Validation Loss: 0.0187, Validation Accuracy: 0.9950\n",
      "Epoch [128/300], Training Loss: 0.0206\n",
      "Epoch [128/300], Validation Loss: 0.0186, Validation Accuracy: 0.9950\n",
      "Epoch [129/300], Training Loss: 0.0205\n",
      "Epoch [129/300], Validation Loss: 0.0184, Validation Accuracy: 0.9950\n",
      "Epoch [130/300], Training Loss: 0.0203\n",
      "Epoch [130/300], Validation Loss: 0.0182, Validation Accuracy: 0.9950\n",
      "Epoch [131/300], Training Loss: 0.0202\n",
      "Epoch [131/300], Validation Loss: 0.0181, Validation Accuracy: 0.9950\n",
      "Epoch [132/300], Training Loss: 0.0201\n",
      "Epoch [132/300], Validation Loss: 0.0179, Validation Accuracy: 0.9950\n",
      "Epoch [133/300], Training Loss: 0.0199\n",
      "Epoch [133/300], Validation Loss: 0.0178, Validation Accuracy: 0.9950\n",
      "Epoch [134/300], Training Loss: 0.0198\n",
      "Epoch [134/300], Validation Loss: 0.0176, Validation Accuracy: 0.9950\n",
      "Epoch [135/300], Training Loss: 0.0197\n",
      "Epoch [135/300], Validation Loss: 0.0175, Validation Accuracy: 0.9957\n",
      "Epoch [136/300], Training Loss: 0.0195\n",
      "Epoch [136/300], Validation Loss: 0.0173, Validation Accuracy: 0.9957\n",
      "Epoch [137/300], Training Loss: 0.0194\n",
      "Epoch [137/300], Validation Loss: 0.0172, Validation Accuracy: 0.9950\n",
      "Epoch [138/300], Training Loss: 0.0193\n",
      "Epoch [138/300], Validation Loss: 0.0171, Validation Accuracy: 0.9950\n",
      "Epoch [139/300], Training Loss: 0.0191\n",
      "Epoch [139/300], Validation Loss: 0.0169, Validation Accuracy: 0.9950\n",
      "Epoch [140/300], Training Loss: 0.0190\n",
      "Epoch [140/300], Validation Loss: 0.0168, Validation Accuracy: 0.9950\n",
      "Epoch [141/300], Training Loss: 0.0189\n",
      "Epoch [141/300], Validation Loss: 0.0166, Validation Accuracy: 0.9950\n",
      "Epoch [142/300], Training Loss: 0.0188\n",
      "Epoch [142/300], Validation Loss: 0.0165, Validation Accuracy: 0.9950\n",
      "Epoch [143/300], Training Loss: 0.0186\n",
      "Epoch [143/300], Validation Loss: 0.0164, Validation Accuracy: 0.9950\n",
      "Epoch [144/300], Training Loss: 0.0185\n",
      "Epoch [144/300], Validation Loss: 0.0162, Validation Accuracy: 0.9950\n",
      "Epoch [145/300], Training Loss: 0.0184\n",
      "Epoch [145/300], Validation Loss: 0.0161, Validation Accuracy: 0.9950\n",
      "Epoch [146/300], Training Loss: 0.0183\n",
      "Epoch [146/300], Validation Loss: 0.0160, Validation Accuracy: 0.9950\n",
      "Epoch [147/300], Training Loss: 0.0182\n",
      "Epoch [147/300], Validation Loss: 0.0158, Validation Accuracy: 0.9950\n",
      "Epoch [148/300], Training Loss: 0.0180\n",
      "Epoch [148/300], Validation Loss: 0.0157, Validation Accuracy: 0.9950\n",
      "Epoch [149/300], Training Loss: 0.0179\n",
      "Epoch [149/300], Validation Loss: 0.0156, Validation Accuracy: 0.9950\n",
      "Epoch [150/300], Training Loss: 0.0178\n",
      "Epoch [150/300], Validation Loss: 0.0155, Validation Accuracy: 0.9950\n",
      "Epoch [151/300], Training Loss: 0.0177\n",
      "Epoch [151/300], Validation Loss: 0.0153, Validation Accuracy: 0.9950\n",
      "Epoch [152/300], Training Loss: 0.0176\n",
      "Epoch [152/300], Validation Loss: 0.0152, Validation Accuracy: 0.9950\n",
      "Epoch [153/300], Training Loss: 0.0175\n",
      "Epoch [153/300], Validation Loss: 0.0151, Validation Accuracy: 0.9950\n",
      "Epoch [154/300], Training Loss: 0.0174\n",
      "Epoch [154/300], Validation Loss: 0.0150, Validation Accuracy: 0.9950\n",
      "Epoch [155/300], Training Loss: 0.0173\n",
      "Epoch [155/300], Validation Loss: 0.0149, Validation Accuracy: 0.9957\n",
      "Epoch [156/300], Training Loss: 0.0171\n",
      "Epoch [156/300], Validation Loss: 0.0147, Validation Accuracy: 0.9957\n",
      "Epoch [157/300], Training Loss: 0.0170\n",
      "Epoch [157/300], Validation Loss: 0.0146, Validation Accuracy: 0.9957\n",
      "Epoch [158/300], Training Loss: 0.0169\n",
      "Epoch [158/300], Validation Loss: 0.0145, Validation Accuracy: 0.9957\n",
      "Epoch [159/300], Training Loss: 0.0168\n",
      "Epoch [159/300], Validation Loss: 0.0144, Validation Accuracy: 0.9957\n",
      "Epoch [160/300], Training Loss: 0.0167\n",
      "Epoch [160/300], Validation Loss: 0.0143, Validation Accuracy: 0.9957\n",
      "Epoch [161/300], Training Loss: 0.0166\n",
      "Epoch [161/300], Validation Loss: 0.0142, Validation Accuracy: 0.9957\n",
      "Epoch [162/300], Training Loss: 0.0165\n",
      "Epoch [162/300], Validation Loss: 0.0141, Validation Accuracy: 0.9957\n",
      "Epoch [163/300], Training Loss: 0.0164\n",
      "Epoch [163/300], Validation Loss: 0.0140, Validation Accuracy: 0.9957\n",
      "Epoch [164/300], Training Loss: 0.0163\n",
      "Epoch [164/300], Validation Loss: 0.0139, Validation Accuracy: 0.9957\n",
      "Epoch [165/300], Training Loss: 0.0162\n",
      "Epoch [165/300], Validation Loss: 0.0138, Validation Accuracy: 0.9957\n",
      "Epoch [166/300], Training Loss: 0.0161\n",
      "Epoch [166/300], Validation Loss: 0.0136, Validation Accuracy: 0.9957\n",
      "Epoch [167/300], Training Loss: 0.0160\n",
      "Epoch [167/300], Validation Loss: 0.0135, Validation Accuracy: 0.9957\n",
      "Epoch [168/300], Training Loss: 0.0159\n",
      "Epoch [168/300], Validation Loss: 0.0134, Validation Accuracy: 0.9957\n",
      "Epoch [169/300], Training Loss: 0.0158\n",
      "Epoch [169/300], Validation Loss: 0.0133, Validation Accuracy: 0.9957\n",
      "Epoch [170/300], Training Loss: 0.0157\n",
      "Epoch [170/300], Validation Loss: 0.0132, Validation Accuracy: 0.9957\n",
      "Epoch [171/300], Training Loss: 0.0156\n",
      "Epoch [171/300], Validation Loss: 0.0131, Validation Accuracy: 0.9957\n",
      "Epoch [172/300], Training Loss: 0.0156\n",
      "Epoch [172/300], Validation Loss: 0.0130, Validation Accuracy: 0.9964\n",
      "Epoch [173/300], Training Loss: 0.0155\n",
      "Epoch [173/300], Validation Loss: 0.0129, Validation Accuracy: 0.9964\n",
      "Epoch [174/300], Training Loss: 0.0154\n",
      "Epoch [174/300], Validation Loss: 0.0129, Validation Accuracy: 0.9964\n",
      "Epoch [175/300], Training Loss: 0.0153\n",
      "Epoch [175/300], Validation Loss: 0.0128, Validation Accuracy: 0.9964\n",
      "Epoch [176/300], Training Loss: 0.0152\n",
      "Epoch [176/300], Validation Loss: 0.0127, Validation Accuracy: 0.9964\n",
      "Epoch [177/300], Training Loss: 0.0151\n",
      "Epoch [177/300], Validation Loss: 0.0126, Validation Accuracy: 0.9964\n",
      "Epoch [178/300], Training Loss: 0.0150\n",
      "Epoch [178/300], Validation Loss: 0.0125, Validation Accuracy: 0.9964\n",
      "Epoch [179/300], Training Loss: 0.0149\n",
      "Epoch [179/300], Validation Loss: 0.0124, Validation Accuracy: 0.9964\n",
      "Epoch [180/300], Training Loss: 0.0148\n",
      "Epoch [180/300], Validation Loss: 0.0123, Validation Accuracy: 0.9964\n",
      "Epoch [181/300], Training Loss: 0.0148\n",
      "Epoch [181/300], Validation Loss: 0.0122, Validation Accuracy: 0.9964\n",
      "Epoch [182/300], Training Loss: 0.0147\n",
      "Epoch [182/300], Validation Loss: 0.0121, Validation Accuracy: 0.9964\n",
      "Epoch [183/300], Training Loss: 0.0146\n",
      "Epoch [183/300], Validation Loss: 0.0120, Validation Accuracy: 0.9964\n",
      "Epoch [184/300], Training Loss: 0.0145\n",
      "Epoch [184/300], Validation Loss: 0.0119, Validation Accuracy: 0.9964\n",
      "Epoch [185/300], Training Loss: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [185/300], Validation Loss: 0.0119, Validation Accuracy: 0.9964\n",
      "Epoch [186/300], Training Loss: 0.0143\n",
      "Epoch [186/300], Validation Loss: 0.0118, Validation Accuracy: 0.9964\n",
      "Epoch [187/300], Training Loss: 0.0143\n",
      "Epoch [187/300], Validation Loss: 0.0117, Validation Accuracy: 0.9971\n",
      "Epoch [188/300], Training Loss: 0.0142\n",
      "Epoch [188/300], Validation Loss: 0.0116, Validation Accuracy: 0.9971\n",
      "Epoch [189/300], Training Loss: 0.0141\n",
      "Epoch [189/300], Validation Loss: 0.0115, Validation Accuracy: 0.9971\n",
      "Epoch [190/300], Training Loss: 0.0140\n",
      "Epoch [190/300], Validation Loss: 0.0114, Validation Accuracy: 0.9971\n",
      "Epoch [191/300], Training Loss: 0.0139\n",
      "Epoch [191/300], Validation Loss: 0.0114, Validation Accuracy: 0.9971\n",
      "Epoch [192/300], Training Loss: 0.0139\n",
      "Epoch [192/300], Validation Loss: 0.0113, Validation Accuracy: 0.9971\n",
      "Epoch [193/300], Training Loss: 0.0138\n",
      "Epoch [193/300], Validation Loss: 0.0112, Validation Accuracy: 0.9979\n",
      "Epoch [194/300], Training Loss: 0.0137\n",
      "Epoch [194/300], Validation Loss: 0.0111, Validation Accuracy: 0.9979\n",
      "Epoch [195/300], Training Loss: 0.0136\n",
      "Epoch [195/300], Validation Loss: 0.0111, Validation Accuracy: 0.9979\n",
      "Epoch [196/300], Training Loss: 0.0136\n",
      "Epoch [196/300], Validation Loss: 0.0110, Validation Accuracy: 0.9979\n",
      "Epoch [197/300], Training Loss: 0.0135\n",
      "Epoch [197/300], Validation Loss: 0.0109, Validation Accuracy: 0.9979\n",
      "Epoch [198/300], Training Loss: 0.0134\n",
      "Epoch [198/300], Validation Loss: 0.0108, Validation Accuracy: 0.9979\n",
      "Epoch [199/300], Training Loss: 0.0133\n",
      "Epoch [199/300], Validation Loss: 0.0107, Validation Accuracy: 0.9979\n",
      "Epoch [200/300], Training Loss: 0.0133\n",
      "Epoch [200/300], Validation Loss: 0.0107, Validation Accuracy: 0.9979\n",
      "Epoch [201/300], Training Loss: 0.0132\n",
      "Epoch [201/300], Validation Loss: 0.0106, Validation Accuracy: 0.9979\n",
      "Epoch [202/300], Training Loss: 0.0131\n",
      "Epoch [202/300], Validation Loss: 0.0105, Validation Accuracy: 0.9979\n",
      "Epoch [203/300], Training Loss: 0.0130\n",
      "Epoch [203/300], Validation Loss: 0.0105, Validation Accuracy: 0.9979\n",
      "Epoch [204/300], Training Loss: 0.0130\n",
      "Epoch [204/300], Validation Loss: 0.0104, Validation Accuracy: 0.9979\n",
      "Epoch [205/300], Training Loss: 0.0129\n",
      "Epoch [205/300], Validation Loss: 0.0103, Validation Accuracy: 0.9979\n",
      "Epoch [206/300], Training Loss: 0.0128\n",
      "Epoch [206/300], Validation Loss: 0.0103, Validation Accuracy: 0.9979\n",
      "Epoch [207/300], Training Loss: 0.0128\n",
      "Epoch [207/300], Validation Loss: 0.0102, Validation Accuracy: 0.9979\n",
      "Epoch [208/300], Training Loss: 0.0127\n",
      "Epoch [208/300], Validation Loss: 0.0101, Validation Accuracy: 0.9979\n",
      "Epoch [209/300], Training Loss: 0.0126\n",
      "Epoch [209/300], Validation Loss: 0.0100, Validation Accuracy: 0.9979\n",
      "Epoch [210/300], Training Loss: 0.0125\n",
      "Epoch [210/300], Validation Loss: 0.0100, Validation Accuracy: 0.9979\n",
      "Epoch [211/300], Training Loss: 0.0125\n",
      "Epoch [211/300], Validation Loss: 0.0099, Validation Accuracy: 0.9979\n",
      "Epoch [212/300], Training Loss: 0.0124\n",
      "Epoch [212/300], Validation Loss: 0.0099, Validation Accuracy: 0.9979\n",
      "Epoch [213/300], Training Loss: 0.0123\n",
      "Epoch [213/300], Validation Loss: 0.0098, Validation Accuracy: 0.9979\n",
      "Epoch [214/300], Training Loss: 0.0123\n",
      "Epoch [214/300], Validation Loss: 0.0097, Validation Accuracy: 0.9979\n",
      "Epoch [215/300], Training Loss: 0.0122\n",
      "Epoch [215/300], Validation Loss: 0.0097, Validation Accuracy: 0.9979\n",
      "Epoch [216/300], Training Loss: 0.0121\n",
      "Epoch [216/300], Validation Loss: 0.0096, Validation Accuracy: 0.9979\n",
      "Epoch [217/300], Training Loss: 0.0121\n",
      "Epoch [217/300], Validation Loss: 0.0095, Validation Accuracy: 0.9979\n",
      "Epoch [218/300], Training Loss: 0.0120\n",
      "Epoch [218/300], Validation Loss: 0.0095, Validation Accuracy: 0.9979\n",
      "Epoch [219/300], Training Loss: 0.0120\n",
      "Epoch [219/300], Validation Loss: 0.0094, Validation Accuracy: 0.9979\n",
      "Epoch [220/300], Training Loss: 0.0119\n",
      "Epoch [220/300], Validation Loss: 0.0094, Validation Accuracy: 0.9986\n",
      "Epoch [221/300], Training Loss: 0.0118\n",
      "Epoch [221/300], Validation Loss: 0.0093, Validation Accuracy: 0.9986\n",
      "Epoch [222/300], Training Loss: 0.0118\n",
      "Epoch [222/300], Validation Loss: 0.0092, Validation Accuracy: 0.9986\n",
      "Epoch [223/300], Training Loss: 0.0117\n",
      "Epoch [223/300], Validation Loss: 0.0092, Validation Accuracy: 0.9986\n",
      "Epoch [224/300], Training Loss: 0.0116\n",
      "Epoch [224/300], Validation Loss: 0.0091, Validation Accuracy: 0.9986\n",
      "Epoch [225/300], Training Loss: 0.0116\n",
      "Epoch [225/300], Validation Loss: 0.0091, Validation Accuracy: 0.9986\n",
      "Epoch [226/300], Training Loss: 0.0115\n",
      "Epoch [226/300], Validation Loss: 0.0090, Validation Accuracy: 0.9986\n",
      "Epoch [227/300], Training Loss: 0.0115\n",
      "Epoch [227/300], Validation Loss: 0.0089, Validation Accuracy: 0.9986\n",
      "Epoch [228/300], Training Loss: 0.0114\n",
      "Epoch [228/300], Validation Loss: 0.0089, Validation Accuracy: 0.9986\n",
      "Epoch [229/300], Training Loss: 0.0113\n",
      "Epoch [229/300], Validation Loss: 0.0088, Validation Accuracy: 0.9986\n",
      "Epoch [230/300], Training Loss: 0.0113\n",
      "Epoch [230/300], Validation Loss: 0.0088, Validation Accuracy: 0.9986\n",
      "Epoch [231/300], Training Loss: 0.0112\n",
      "Epoch [231/300], Validation Loss: 0.0087, Validation Accuracy: 0.9986\n",
      "Epoch [232/300], Training Loss: 0.0112\n",
      "Epoch [232/300], Validation Loss: 0.0087, Validation Accuracy: 0.9986\n",
      "Epoch [233/300], Training Loss: 0.0111\n",
      "Epoch [233/300], Validation Loss: 0.0086, Validation Accuracy: 0.9986\n",
      "Epoch [234/300], Training Loss: 0.0110\n",
      "Epoch [234/300], Validation Loss: 0.0086, Validation Accuracy: 0.9986\n",
      "Epoch [235/300], Training Loss: 0.0110\n",
      "Epoch [235/300], Validation Loss: 0.0085, Validation Accuracy: 0.9986\n",
      "Epoch [236/300], Training Loss: 0.0109\n",
      "Epoch [236/300], Validation Loss: 0.0085, Validation Accuracy: 0.9986\n",
      "Epoch [237/300], Training Loss: 0.0109\n",
      "Epoch [237/300], Validation Loss: 0.0084, Validation Accuracy: 0.9986\n",
      "Epoch [238/300], Training Loss: 0.0108\n",
      "Epoch [238/300], Validation Loss: 0.0084, Validation Accuracy: 0.9986\n",
      "Epoch [239/300], Training Loss: 0.0108\n",
      "Epoch [239/300], Validation Loss: 0.0083, Validation Accuracy: 0.9986\n",
      "Epoch [240/300], Training Loss: 0.0107\n",
      "Epoch [240/300], Validation Loss: 0.0083, Validation Accuracy: 0.9986\n",
      "Epoch [241/300], Training Loss: 0.0106\n",
      "Epoch [241/300], Validation Loss: 0.0082, Validation Accuracy: 0.9986\n",
      "Epoch [242/300], Training Loss: 0.0106\n",
      "Epoch [242/300], Validation Loss: 0.0082, Validation Accuracy: 0.9986\n",
      "Epoch [243/300], Training Loss: 0.0105\n",
      "Epoch [243/300], Validation Loss: 0.0081, Validation Accuracy: 0.9986\n",
      "Epoch [244/300], Training Loss: 0.0105\n",
      "Epoch [244/300], Validation Loss: 0.0081, Validation Accuracy: 0.9986\n",
      "Epoch [245/300], Training Loss: 0.0104\n",
      "Epoch [245/300], Validation Loss: 0.0080, Validation Accuracy: 0.9986\n",
      "Epoch [246/300], Training Loss: 0.0104\n",
      "Epoch [246/300], Validation Loss: 0.0080, Validation Accuracy: 0.9986\n",
      "Epoch [247/300], Training Loss: 0.0103\n",
      "Epoch [247/300], Validation Loss: 0.0079, Validation Accuracy: 0.9986\n",
      "Epoch [248/300], Training Loss: 0.0103\n",
      "Epoch [248/300], Validation Loss: 0.0079, Validation Accuracy: 0.9986\n",
      "Epoch [249/300], Training Loss: 0.0102\n",
      "Epoch [249/300], Validation Loss: 0.0078, Validation Accuracy: 0.9986\n",
      "Epoch [250/300], Training Loss: 0.0102\n",
      "Epoch [250/300], Validation Loss: 0.0078, Validation Accuracy: 0.9986\n",
      "Epoch [251/300], Training Loss: 0.0101\n",
      "Epoch [251/300], Validation Loss: 0.0077, Validation Accuracy: 0.9986\n",
      "Epoch [252/300], Training Loss: 0.0101\n",
      "Epoch [252/300], Validation Loss: 0.0077, Validation Accuracy: 0.9986\n",
      "Epoch [253/300], Training Loss: 0.0100\n",
      "Epoch [253/300], Validation Loss: 0.0077, Validation Accuracy: 0.9986\n",
      "Epoch [254/300], Training Loss: 0.0099\n",
      "Epoch [254/300], Validation Loss: 0.0076, Validation Accuracy: 0.9986\n",
      "Epoch [255/300], Training Loss: 0.0099\n",
      "Epoch [255/300], Validation Loss: 0.0076, Validation Accuracy: 0.9986\n",
      "Epoch [256/300], Training Loss: 0.0098\n",
      "Epoch [256/300], Validation Loss: 0.0075, Validation Accuracy: 0.9993\n",
      "Epoch [257/300], Training Loss: 0.0098\n",
      "Epoch [257/300], Validation Loss: 0.0075, Validation Accuracy: 0.9993\n",
      "Epoch [258/300], Training Loss: 0.0097\n",
      "Epoch [258/300], Validation Loss: 0.0074, Validation Accuracy: 0.9993\n",
      "Epoch [259/300], Training Loss: 0.0097\n",
      "Epoch [259/300], Validation Loss: 0.0074, Validation Accuracy: 0.9993\n",
      "Epoch [260/300], Training Loss: 0.0096\n",
      "Epoch [260/300], Validation Loss: 0.0074, Validation Accuracy: 0.9993\n",
      "Epoch [261/300], Training Loss: 0.0096\n",
      "Epoch [261/300], Validation Loss: 0.0073, Validation Accuracy: 0.9993\n",
      "Epoch [262/300], Training Loss: 0.0095\n",
      "Epoch [262/300], Validation Loss: 0.0073, Validation Accuracy: 0.9993\n",
      "Epoch [263/300], Training Loss: 0.0095\n",
      "Epoch [263/300], Validation Loss: 0.0072, Validation Accuracy: 0.9993\n",
      "Epoch [264/300], Training Loss: 0.0094\n",
      "Epoch [264/300], Validation Loss: 0.0072, Validation Accuracy: 0.9993\n",
      "Epoch [265/300], Training Loss: 0.0094\n",
      "Epoch [265/300], Validation Loss: 0.0072, Validation Accuracy: 0.9993\n",
      "Epoch [266/300], Training Loss: 0.0093\n",
      "Epoch [266/300], Validation Loss: 0.0071, Validation Accuracy: 0.9993\n",
      "Epoch [267/300], Training Loss: 0.0093\n",
      "Epoch [267/300], Validation Loss: 0.0071, Validation Accuracy: 0.9993\n",
      "Epoch [268/300], Training Loss: 0.0093\n",
      "Epoch [268/300], Validation Loss: 0.0070, Validation Accuracy: 0.9993\n",
      "Epoch [269/300], Training Loss: 0.0092\n",
      "Epoch [269/300], Validation Loss: 0.0070, Validation Accuracy: 0.9993\n",
      "Epoch [270/300], Training Loss: 0.0092\n",
      "Epoch [270/300], Validation Loss: 0.0070, Validation Accuracy: 0.9993\n",
      "Epoch [271/300], Training Loss: 0.0091\n",
      "Epoch [271/300], Validation Loss: 0.0069, Validation Accuracy: 0.9993\n",
      "Epoch [272/300], Training Loss: 0.0091\n",
      "Epoch [272/300], Validation Loss: 0.0069, Validation Accuracy: 0.9993\n",
      "Epoch [273/300], Training Loss: 0.0090\n",
      "Epoch [273/300], Validation Loss: 0.0068, Validation Accuracy: 0.9993\n",
      "Epoch [274/300], Training Loss: 0.0090\n",
      "Epoch [274/300], Validation Loss: 0.0068, Validation Accuracy: 0.9993\n",
      "Epoch [275/300], Training Loss: 0.0089\n",
      "Epoch [275/300], Validation Loss: 0.0068, Validation Accuracy: 0.9993\n",
      "Epoch [276/300], Training Loss: 0.0089\n",
      "Epoch [276/300], Validation Loss: 0.0067, Validation Accuracy: 0.9993\n",
      "Epoch [277/300], Training Loss: 0.0088\n",
      "Epoch [277/300], Validation Loss: 0.0067, Validation Accuracy: 0.9993\n",
      "Epoch [278/300], Training Loss: 0.0088\n",
      "Epoch [278/300], Validation Loss: 0.0067, Validation Accuracy: 0.9993\n",
      "Epoch [279/300], Training Loss: 0.0087\n",
      "Epoch [279/300], Validation Loss: 0.0066, Validation Accuracy: 0.9993\n",
      "Epoch [280/300], Training Loss: 0.0087\n",
      "Epoch [280/300], Validation Loss: 0.0066, Validation Accuracy: 0.9993\n",
      "Epoch [281/300], Training Loss: 0.0087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [281/300], Validation Loss: 0.0066, Validation Accuracy: 0.9993\n",
      "Epoch [282/300], Training Loss: 0.0086\n",
      "Epoch [282/300], Validation Loss: 0.0065, Validation Accuracy: 0.9993\n",
      "Epoch [283/300], Training Loss: 0.0086\n",
      "Epoch [283/300], Validation Loss: 0.0065, Validation Accuracy: 0.9993\n",
      "Epoch [284/300], Training Loss: 0.0085\n",
      "Epoch [284/300], Validation Loss: 0.0065, Validation Accuracy: 0.9993\n",
      "Epoch [285/300], Training Loss: 0.0085\n",
      "Epoch [285/300], Validation Loss: 0.0064, Validation Accuracy: 0.9993\n",
      "Epoch [286/300], Training Loss: 0.0084\n",
      "Epoch [286/300], Validation Loss: 0.0064, Validation Accuracy: 0.9993\n",
      "Epoch [287/300], Training Loss: 0.0084\n",
      "Epoch [287/300], Validation Loss: 0.0064, Validation Accuracy: 0.9993\n",
      "Epoch [288/300], Training Loss: 0.0084\n",
      "Epoch [288/300], Validation Loss: 0.0063, Validation Accuracy: 0.9993\n",
      "Epoch [289/300], Training Loss: 0.0083\n",
      "Epoch [289/300], Validation Loss: 0.0063, Validation Accuracy: 0.9993\n",
      "Epoch [290/300], Training Loss: 0.0083\n",
      "Epoch [290/300], Validation Loss: 0.0063, Validation Accuracy: 0.9993\n",
      "Epoch [291/300], Training Loss: 0.0082\n",
      "Epoch [291/300], Validation Loss: 0.0062, Validation Accuracy: 0.9993\n",
      "Epoch [292/300], Training Loss: 0.0082\n",
      "Epoch [292/300], Validation Loss: 0.0062, Validation Accuracy: 0.9993\n",
      "Epoch [293/300], Training Loss: 0.0081\n",
      "Epoch [293/300], Validation Loss: 0.0062, Validation Accuracy: 0.9993\n",
      "Epoch [294/300], Training Loss: 0.0081\n",
      "Epoch [294/300], Validation Loss: 0.0061, Validation Accuracy: 0.9993\n",
      "Epoch [295/300], Training Loss: 0.0081\n",
      "Epoch [295/300], Validation Loss: 0.0061, Validation Accuracy: 0.9993\n",
      "Epoch [296/300], Training Loss: 0.0080\n",
      "Epoch [296/300], Validation Loss: 0.0061, Validation Accuracy: 0.9993\n",
      "Epoch [297/300], Training Loss: 0.0080\n",
      "Epoch [297/300], Validation Loss: 0.0060, Validation Accuracy: 0.9993\n",
      "Epoch [298/300], Training Loss: 0.0079\n",
      "Epoch [298/300], Validation Loss: 0.0060, Validation Accuracy: 0.9993\n",
      "Epoch [299/300], Training Loss: 0.0079\n",
      "Epoch [299/300], Validation Loss: 0.0060, Validation Accuracy: 0.9993\n",
      "Epoch [300/300], Training Loss: 0.0079\n",
      "Epoch [300/300], Validation Loss: 0.0059, Validation Accuracy: 0.9993\n",
      "Test Accuracy: 0.9978617248752673\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features_df = pd.read_csv('features.csv')\n",
    "\n",
    "# Extract features and corresponding labels\n",
    "X = features_df.iloc[:, :-1].values  # features \n",
    "y = features_df.iloc[:, -1].values  # labels \n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the labels\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "print(X_train.shape)\n",
    "hidden_size = 64 \n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 300 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    outputs = model(X_train_tensor.unsqueeze(1))  \n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs.squeeze(), y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor.unsqueeze(1))\n",
    "        val_loss = criterion(val_outputs.squeeze(), y_val)\n",
    "        _, val_predicted = torch.max(val_outputs, 1)\n",
    "        val_accuracy = accuracy_score(y_val.numpy(), val_predicted.numpy())\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss.item():.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor.unsqueeze(1))\n",
    "    _, test_predicted = torch.max(test_outputs, 1)\n",
    "    test_accuracy = accuracy_score(y_test.numpy(), test_predicted.numpy())\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2689db",
   "metadata": {},
   "source": [
    "## Test phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f32215ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in something directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "\n",
    "        # MFCC (Mel-frequency cepstral coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "        # Chroma feature\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral contrast\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral centroid\n",
    "        spectral_centroids = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Zero-crossing rate\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio).T, axis=0)\n",
    "\n",
    "        # Spectral rolloff\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Combine all features into a 1D array\n",
    "        features = np.hstack([mfccs_processed, chroma_stft, spectral_contrast, spectral_centroids, zero_crossing_rate, spectral_rolloff])\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_name}\")\n",
    "        return None\n",
    "\n",
    "# Specify the directories containing the .mp3 files\n",
    "directories = ['something']\n",
    "\n",
    "# Create an empty DataFrame \n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "for directory in directories:\n",
    "    print(f\"Processing files in {directory} directory\")\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                features = extract_features(file_path)\n",
    "                # Append the features to the DataFrame as a new row\n",
    "                if features is not None:\n",
    "                    features_series = pd.Series(features)\n",
    "                    features_df = pd.concat([features_df, features_series], axis=0)  # Concatenate along rows (axis=0)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered while processing file: {file_path}\")\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8cfb4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-224.141861</td>\n",
       "      <td>123.548615</td>\n",
       "      <td>-11.934964</td>\n",
       "      <td>35.14872</td>\n",
       "      <td>-2.978472</td>\n",
       "      <td>11.988633</td>\n",
       "      <td>-10.192609</td>\n",
       "      <td>7.214376</td>\n",
       "      <td>-13.9877</td>\n",
       "      <td>1.976113</td>\n",
       "      <td>...</td>\n",
       "      <td>20.868756</td>\n",
       "      <td>15.711451</td>\n",
       "      <td>19.730115</td>\n",
       "      <td>19.38868</td>\n",
       "      <td>19.780333</td>\n",
       "      <td>19.137458</td>\n",
       "      <td>41.547228</td>\n",
       "      <td>1692.69833</td>\n",
       "      <td>0.082245</td>\n",
       "      <td>3374.557483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2         3         4          5   \\\n",
       "0 -224.141861  123.548615 -11.934964  35.14872 -2.978472  11.988633   \n",
       "\n",
       "          6         7        8         9   ...         52         53  \\\n",
       "0 -10.192609  7.214376 -13.9877  1.976113  ...  20.868756  15.711451   \n",
       "\n",
       "          54        55         56         57         58          59        60  \\\n",
       "0  19.730115  19.38868  19.780333  19.137458  41.547228  1692.69833  0.082245   \n",
       "\n",
       "            61  \n",
       "0  3374.557483  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new= features_df.T\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e7bf0",
   "metadata": {},
   "source": [
    "## load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f7f60ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b079b6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39meval()  \n\u001b[0;32m----> 4\u001b[0m X_new \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mX_new\u001b[49m) \n\u001b[1;32m      5\u001b[0m X_new_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_new, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_new' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_model.eval()  \n",
    "\n",
    "\n",
    "X_new = scaler.transform(X_new) \n",
    "X_new_tensor = torch.tensor(X_new, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    new_outputs = loaded_model(X_new_tensor.unsqueeze(1))\n",
    "    _, new_predicted = torch.max(new_outputs, 1)\n",
    "\n",
    "print(new_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d09666d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = RNN( input_size, hidden_size, num_classes)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('rnn_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording audio for 1 minute...\n",
      "Finished recording.\n",
      "Error encountered while parsing file: recorded_audio.wav\n",
      "Error occurred while extracting features from recorded audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording audio for 1 minute...\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import os\n",
    "\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "\n",
    "        # MFCC (Mel-frequency cepstral coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "        # Chroma feature\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral contrast\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral centroid\n",
    "        spectral_centroids = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Zero-crossing rate\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio).T, axis=0)\n",
    "\n",
    "        # Spectral rolloff\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Combine all features into a 1D array\n",
    "        features = np.hstack([mfccs_processed, chroma_stft, spectral_contrast, spectral_centroids, zero_crossing_rate, spectral_rolloff])\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_name}\")\n",
    "        return None\n",
    "    \n",
    "def record_and_classify_audio():\n",
    "    # Record audio for 1 minute\n",
    "    audio_duration = 60 \n",
    "    sample_rate = 44100 \n",
    "\n",
    "    audio_frames = []\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    print(\"Recording audio for 1 minute...\")\n",
    "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=sample_rate, input=True, frames_per_buffer=1024)\n",
    "\n",
    "    for _ in range(0, int(sample_rate / 1024 * audio_duration)):\n",
    "        data = stream.read(1024)\n",
    "        audio_frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Save the recorded audio to a WAV file\n",
    "    output_audio_file = \"recorded_audio.wav\"\n",
    "    wf = wave.open(output_audio_file, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(sample_rate)\n",
    "    wf.writeframes(b''.join(audio_frames))\n",
    "    wf.close()\n",
    "\n",
    "    # extract features \n",
    "    recorded_features = extract_features(output_audio_file)\n",
    "\n",
    "    # Check if features are successfully extracted\n",
    "    if recorded_features is not None:\n",
    "        # Convert the features to a pandas DataFrame\n",
    "        recorded_df = pd.DataFrame([recorded_features])\n",
    "\n",
    "        # Standardize the features (like you did with the training data)\n",
    "        recorded_df = scaler.transform(recorded_df)\n",
    "\n",
    "        # Feed the features to the trained PyTorch model for classification\n",
    "        model.eval()\n",
    "        recorded_tensor = torch.tensor(recorded_df, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            predicted_output = model(recorded_tensor.unsqueeze(1))\n",
    "            _, predicted_class = torch.max(predicted_output, 1)\n",
    "\n",
    "        # Decode the predicted class using the label encoder\n",
    "        predicted_class_label = label_encoder.inverse_transform(predicted_class.numpy())\n",
    "\n",
    "        # Print the classification result\n",
    "        print(\"Predicted Class:\", predicted_class_label[0])\n",
    "\n",
    "        # Delete the audio file\n",
    "        os.remove(output_audio_file)\n",
    "    else:\n",
    "        print(\"Error occurred while extracting features from recorded audio.\")\n",
    "\n",
    "# Continuous loop for recording and classifying audio\n",
    "while True:\n",
    "    record_and_classify_audio()\n",
    "    \n",
    "    time.sleep(3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cc9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
