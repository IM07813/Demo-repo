{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fddd38ce",
   "metadata": {},
   "source": [
    "## train the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abbfdfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Training Loss: 0.6108\n",
      "Epoch [1/300], Validation Loss: 0.5418, Validation Accuracy: 0.9031\n",
      "Epoch [2/300], Training Loss: 0.5401\n",
      "Epoch [2/300], Validation Loss: 0.4804, Validation Accuracy: 0.9416\n",
      "Epoch [3/300], Training Loss: 0.4780\n",
      "Epoch [3/300], Validation Loss: 0.4268, Validation Accuracy: 0.9601\n",
      "Epoch [4/300], Training Loss: 0.4239\n",
      "Epoch [4/300], Validation Loss: 0.3802, Validation Accuracy: 0.9679\n",
      "Epoch [5/300], Training Loss: 0.3771\n",
      "Epoch [5/300], Validation Loss: 0.3400, Validation Accuracy: 0.9715\n",
      "Epoch [6/300], Training Loss: 0.3366\n",
      "Epoch [6/300], Validation Loss: 0.3052, Validation Accuracy: 0.9729\n",
      "Epoch [7/300], Training Loss: 0.3017\n",
      "Epoch [7/300], Validation Loss: 0.2751, Validation Accuracy: 0.9751\n",
      "Epoch [8/300], Training Loss: 0.2715\n",
      "Epoch [8/300], Validation Loss: 0.2490, Validation Accuracy: 0.9751\n",
      "Epoch [9/300], Training Loss: 0.2455\n",
      "Epoch [9/300], Validation Loss: 0.2264, Validation Accuracy: 0.9751\n",
      "Epoch [10/300], Training Loss: 0.2230\n",
      "Epoch [10/300], Validation Loss: 0.2067, Validation Accuracy: 0.9758\n",
      "Epoch [11/300], Training Loss: 0.2035\n",
      "Epoch [11/300], Validation Loss: 0.1896, Validation Accuracy: 0.9758\n",
      "Epoch [12/300], Training Loss: 0.1865\n",
      "Epoch [12/300], Validation Loss: 0.1746, Validation Accuracy: 0.9765\n",
      "Epoch [13/300], Training Loss: 0.1716\n",
      "Epoch [13/300], Validation Loss: 0.1614, Validation Accuracy: 0.9772\n",
      "Epoch [14/300], Training Loss: 0.1586\n",
      "Epoch [14/300], Validation Loss: 0.1498, Validation Accuracy: 0.9786\n",
      "Epoch [15/300], Training Loss: 0.1472\n",
      "Epoch [15/300], Validation Loss: 0.1396, Validation Accuracy: 0.9793\n",
      "Epoch [16/300], Training Loss: 0.1372\n",
      "Epoch [16/300], Validation Loss: 0.1305, Validation Accuracy: 0.9800\n",
      "Epoch [17/300], Training Loss: 0.1282\n",
      "Epoch [17/300], Validation Loss: 0.1224, Validation Accuracy: 0.9808\n",
      "Epoch [18/300], Training Loss: 0.1203\n",
      "Epoch [18/300], Validation Loss: 0.1152, Validation Accuracy: 0.9815\n",
      "Epoch [19/300], Training Loss: 0.1132\n",
      "Epoch [19/300], Validation Loss: 0.1087, Validation Accuracy: 0.9815\n",
      "Epoch [20/300], Training Loss: 0.1069\n",
      "Epoch [20/300], Validation Loss: 0.1029, Validation Accuracy: 0.9822\n",
      "Epoch [21/300], Training Loss: 0.1012\n",
      "Epoch [21/300], Validation Loss: 0.0977, Validation Accuracy: 0.9822\n",
      "Epoch [22/300], Training Loss: 0.0961\n",
      "Epoch [22/300], Validation Loss: 0.0929, Validation Accuracy: 0.9822\n",
      "Epoch [23/300], Training Loss: 0.0915\n",
      "Epoch [23/300], Validation Loss: 0.0886, Validation Accuracy: 0.9829\n",
      "Epoch [24/300], Training Loss: 0.0872\n",
      "Epoch [24/300], Validation Loss: 0.0847, Validation Accuracy: 0.9836\n",
      "Epoch [25/300], Training Loss: 0.0834\n",
      "Epoch [25/300], Validation Loss: 0.0811, Validation Accuracy: 0.9843\n",
      "Epoch [26/300], Training Loss: 0.0799\n",
      "Epoch [26/300], Validation Loss: 0.0779, Validation Accuracy: 0.9850\n",
      "Epoch [27/300], Training Loss: 0.0767\n",
      "Epoch [27/300], Validation Loss: 0.0749, Validation Accuracy: 0.9850\n",
      "Epoch [28/300], Training Loss: 0.0737\n",
      "Epoch [28/300], Validation Loss: 0.0721, Validation Accuracy: 0.9850\n",
      "Epoch [29/300], Training Loss: 0.0710\n",
      "Epoch [29/300], Validation Loss: 0.0695, Validation Accuracy: 0.9850\n",
      "Epoch [30/300], Training Loss: 0.0685\n",
      "Epoch [30/300], Validation Loss: 0.0672, Validation Accuracy: 0.9850\n",
      "Epoch [31/300], Training Loss: 0.0661\n",
      "Epoch [31/300], Validation Loss: 0.0650, Validation Accuracy: 0.9857\n",
      "Epoch [32/300], Training Loss: 0.0639\n",
      "Epoch [32/300], Validation Loss: 0.0629, Validation Accuracy: 0.9865\n",
      "Epoch [33/300], Training Loss: 0.0619\n",
      "Epoch [33/300], Validation Loss: 0.0610, Validation Accuracy: 0.9865\n",
      "Epoch [34/300], Training Loss: 0.0600\n",
      "Epoch [34/300], Validation Loss: 0.0592, Validation Accuracy: 0.9865\n",
      "Epoch [35/300], Training Loss: 0.0583\n",
      "Epoch [35/300], Validation Loss: 0.0575, Validation Accuracy: 0.9857\n",
      "Epoch [36/300], Training Loss: 0.0566\n",
      "Epoch [36/300], Validation Loss: 0.0560, Validation Accuracy: 0.9850\n",
      "Epoch [37/300], Training Loss: 0.0551\n",
      "Epoch [37/300], Validation Loss: 0.0545, Validation Accuracy: 0.9850\n",
      "Epoch [38/300], Training Loss: 0.0536\n",
      "Epoch [38/300], Validation Loss: 0.0531, Validation Accuracy: 0.9850\n",
      "Epoch [39/300], Training Loss: 0.0522\n",
      "Epoch [39/300], Validation Loss: 0.0518, Validation Accuracy: 0.9857\n",
      "Epoch [40/300], Training Loss: 0.0509\n",
      "Epoch [40/300], Validation Loss: 0.0506, Validation Accuracy: 0.9850\n",
      "Epoch [41/300], Training Loss: 0.0497\n",
      "Epoch [41/300], Validation Loss: 0.0494, Validation Accuracy: 0.9857\n",
      "Epoch [42/300], Training Loss: 0.0485\n",
      "Epoch [42/300], Validation Loss: 0.0483, Validation Accuracy: 0.9857\n",
      "Epoch [43/300], Training Loss: 0.0474\n",
      "Epoch [43/300], Validation Loss: 0.0472, Validation Accuracy: 0.9857\n",
      "Epoch [44/300], Training Loss: 0.0464\n",
      "Epoch [44/300], Validation Loss: 0.0462, Validation Accuracy: 0.9857\n",
      "Epoch [45/300], Training Loss: 0.0454\n",
      "Epoch [45/300], Validation Loss: 0.0452, Validation Accuracy: 0.9865\n",
      "Epoch [46/300], Training Loss: 0.0444\n",
      "Epoch [46/300], Validation Loss: 0.0443, Validation Accuracy: 0.9857\n",
      "Epoch [47/300], Training Loss: 0.0435\n",
      "Epoch [47/300], Validation Loss: 0.0434, Validation Accuracy: 0.9865\n",
      "Epoch [48/300], Training Loss: 0.0427\n",
      "Epoch [48/300], Validation Loss: 0.0426, Validation Accuracy: 0.9872\n",
      "Epoch [49/300], Training Loss: 0.0418\n",
      "Epoch [49/300], Validation Loss: 0.0418, Validation Accuracy: 0.9872\n",
      "Epoch [50/300], Training Loss: 0.0411\n",
      "Epoch [50/300], Validation Loss: 0.0410, Validation Accuracy: 0.9872\n",
      "Epoch [51/300], Training Loss: 0.0403\n",
      "Epoch [51/300], Validation Loss: 0.0403, Validation Accuracy: 0.9872\n",
      "Epoch [52/300], Training Loss: 0.0396\n",
      "Epoch [52/300], Validation Loss: 0.0396, Validation Accuracy: 0.9872\n",
      "Epoch [53/300], Training Loss: 0.0389\n",
      "Epoch [53/300], Validation Loss: 0.0389, Validation Accuracy: 0.9872\n",
      "Epoch [54/300], Training Loss: 0.0383\n",
      "Epoch [54/300], Validation Loss: 0.0382, Validation Accuracy: 0.9872\n",
      "Epoch [55/300], Training Loss: 0.0376\n",
      "Epoch [55/300], Validation Loss: 0.0376, Validation Accuracy: 0.9872\n",
      "Epoch [56/300], Training Loss: 0.0370\n",
      "Epoch [56/300], Validation Loss: 0.0370, Validation Accuracy: 0.9872\n",
      "Epoch [57/300], Training Loss: 0.0364\n",
      "Epoch [57/300], Validation Loss: 0.0364, Validation Accuracy: 0.9879\n",
      "Epoch [58/300], Training Loss: 0.0359\n",
      "Epoch [58/300], Validation Loss: 0.0359, Validation Accuracy: 0.9893\n",
      "Epoch [59/300], Training Loss: 0.0354\n",
      "Epoch [59/300], Validation Loss: 0.0353, Validation Accuracy: 0.9900\n",
      "Epoch [60/300], Training Loss: 0.0348\n",
      "Epoch [60/300], Validation Loss: 0.0348, Validation Accuracy: 0.9900\n",
      "Epoch [61/300], Training Loss: 0.0344\n",
      "Epoch [61/300], Validation Loss: 0.0343, Validation Accuracy: 0.9900\n",
      "Epoch [62/300], Training Loss: 0.0339\n",
      "Epoch [62/300], Validation Loss: 0.0338, Validation Accuracy: 0.9900\n",
      "Epoch [63/300], Training Loss: 0.0334\n",
      "Epoch [63/300], Validation Loss: 0.0333, Validation Accuracy: 0.9900\n",
      "Epoch [64/300], Training Loss: 0.0330\n",
      "Epoch [64/300], Validation Loss: 0.0329, Validation Accuracy: 0.9907\n",
      "Epoch [65/300], Training Loss: 0.0325\n",
      "Epoch [65/300], Validation Loss: 0.0324, Validation Accuracy: 0.9907\n",
      "Epoch [66/300], Training Loss: 0.0321\n",
      "Epoch [66/300], Validation Loss: 0.0320, Validation Accuracy: 0.9907\n",
      "Epoch [67/300], Training Loss: 0.0317\n",
      "Epoch [67/300], Validation Loss: 0.0316, Validation Accuracy: 0.9907\n",
      "Epoch [68/300], Training Loss: 0.0313\n",
      "Epoch [68/300], Validation Loss: 0.0312, Validation Accuracy: 0.9907\n",
      "Epoch [69/300], Training Loss: 0.0310\n",
      "Epoch [69/300], Validation Loss: 0.0308, Validation Accuracy: 0.9907\n",
      "Epoch [70/300], Training Loss: 0.0306\n",
      "Epoch [70/300], Validation Loss: 0.0304, Validation Accuracy: 0.9907\n",
      "Epoch [71/300], Training Loss: 0.0303\n",
      "Epoch [71/300], Validation Loss: 0.0300, Validation Accuracy: 0.9907\n",
      "Epoch [72/300], Training Loss: 0.0299\n",
      "Epoch [72/300], Validation Loss: 0.0297, Validation Accuracy: 0.9907\n",
      "Epoch [73/300], Training Loss: 0.0296\n",
      "Epoch [73/300], Validation Loss: 0.0293, Validation Accuracy: 0.9907\n",
      "Epoch [74/300], Training Loss: 0.0293\n",
      "Epoch [74/300], Validation Loss: 0.0290, Validation Accuracy: 0.9907\n",
      "Epoch [75/300], Training Loss: 0.0289\n",
      "Epoch [75/300], Validation Loss: 0.0286, Validation Accuracy: 0.9907\n",
      "Epoch [76/300], Training Loss: 0.0286\n",
      "Epoch [76/300], Validation Loss: 0.0283, Validation Accuracy: 0.9907\n",
      "Epoch [77/300], Training Loss: 0.0283\n",
      "Epoch [77/300], Validation Loss: 0.0280, Validation Accuracy: 0.9907\n",
      "Epoch [78/300], Training Loss: 0.0280\n",
      "Epoch [78/300], Validation Loss: 0.0277, Validation Accuracy: 0.9907\n",
      "Epoch [79/300], Training Loss: 0.0278\n",
      "Epoch [79/300], Validation Loss: 0.0274, Validation Accuracy: 0.9907\n",
      "Epoch [80/300], Training Loss: 0.0275\n",
      "Epoch [80/300], Validation Loss: 0.0271, Validation Accuracy: 0.9907\n",
      "Epoch [81/300], Training Loss: 0.0272\n",
      "Epoch [81/300], Validation Loss: 0.0268, Validation Accuracy: 0.9907\n",
      "Epoch [82/300], Training Loss: 0.0269\n",
      "Epoch [82/300], Validation Loss: 0.0265, Validation Accuracy: 0.9907\n",
      "Epoch [83/300], Training Loss: 0.0267\n",
      "Epoch [83/300], Validation Loss: 0.0262, Validation Accuracy: 0.9907\n",
      "Epoch [84/300], Training Loss: 0.0264\n",
      "Epoch [84/300], Validation Loss: 0.0259, Validation Accuracy: 0.9907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/300], Training Loss: 0.0262\n",
      "Epoch [85/300], Validation Loss: 0.0257, Validation Accuracy: 0.9907\n",
      "Epoch [86/300], Training Loss: 0.0259\n",
      "Epoch [86/300], Validation Loss: 0.0254, Validation Accuracy: 0.9907\n",
      "Epoch [87/300], Training Loss: 0.0257\n",
      "Epoch [87/300], Validation Loss: 0.0251, Validation Accuracy: 0.9907\n",
      "Epoch [88/300], Training Loss: 0.0255\n",
      "Epoch [88/300], Validation Loss: 0.0249, Validation Accuracy: 0.9914\n",
      "Epoch [89/300], Training Loss: 0.0252\n",
      "Epoch [89/300], Validation Loss: 0.0246, Validation Accuracy: 0.9914\n",
      "Epoch [90/300], Training Loss: 0.0250\n",
      "Epoch [90/300], Validation Loss: 0.0244, Validation Accuracy: 0.9914\n",
      "Epoch [91/300], Training Loss: 0.0248\n",
      "Epoch [91/300], Validation Loss: 0.0241, Validation Accuracy: 0.9914\n",
      "Epoch [92/300], Training Loss: 0.0245\n",
      "Epoch [92/300], Validation Loss: 0.0239, Validation Accuracy: 0.9914\n",
      "Epoch [93/300], Training Loss: 0.0243\n",
      "Epoch [93/300], Validation Loss: 0.0236, Validation Accuracy: 0.9914\n",
      "Epoch [94/300], Training Loss: 0.0241\n",
      "Epoch [94/300], Validation Loss: 0.0234, Validation Accuracy: 0.9914\n",
      "Epoch [95/300], Training Loss: 0.0239\n",
      "Epoch [95/300], Validation Loss: 0.0231, Validation Accuracy: 0.9922\n",
      "Epoch [96/300], Training Loss: 0.0237\n",
      "Epoch [96/300], Validation Loss: 0.0229, Validation Accuracy: 0.9922\n",
      "Epoch [97/300], Training Loss: 0.0235\n",
      "Epoch [97/300], Validation Loss: 0.0227, Validation Accuracy: 0.9922\n",
      "Epoch [98/300], Training Loss: 0.0233\n",
      "Epoch [98/300], Validation Loss: 0.0224, Validation Accuracy: 0.9922\n",
      "Epoch [99/300], Training Loss: 0.0231\n",
      "Epoch [99/300], Validation Loss: 0.0222, Validation Accuracy: 0.9922\n",
      "Epoch [100/300], Training Loss: 0.0229\n",
      "Epoch [100/300], Validation Loss: 0.0220, Validation Accuracy: 0.9929\n",
      "Epoch [101/300], Training Loss: 0.0227\n",
      "Epoch [101/300], Validation Loss: 0.0218, Validation Accuracy: 0.9929\n",
      "Epoch [102/300], Training Loss: 0.0225\n",
      "Epoch [102/300], Validation Loss: 0.0216, Validation Accuracy: 0.9929\n",
      "Epoch [103/300], Training Loss: 0.0223\n",
      "Epoch [103/300], Validation Loss: 0.0213, Validation Accuracy: 0.9929\n",
      "Epoch [104/300], Training Loss: 0.0222\n",
      "Epoch [104/300], Validation Loss: 0.0211, Validation Accuracy: 0.9929\n",
      "Epoch [105/300], Training Loss: 0.0220\n",
      "Epoch [105/300], Validation Loss: 0.0209, Validation Accuracy: 0.9929\n",
      "Epoch [106/300], Training Loss: 0.0218\n",
      "Epoch [106/300], Validation Loss: 0.0207, Validation Accuracy: 0.9929\n",
      "Epoch [107/300], Training Loss: 0.0216\n",
      "Epoch [107/300], Validation Loss: 0.0205, Validation Accuracy: 0.9929\n",
      "Epoch [108/300], Training Loss: 0.0215\n",
      "Epoch [108/300], Validation Loss: 0.0203, Validation Accuracy: 0.9929\n",
      "Epoch [109/300], Training Loss: 0.0213\n",
      "Epoch [109/300], Validation Loss: 0.0201, Validation Accuracy: 0.9929\n",
      "Epoch [110/300], Training Loss: 0.0211\n",
      "Epoch [110/300], Validation Loss: 0.0199, Validation Accuracy: 0.9929\n",
      "Epoch [111/300], Training Loss: 0.0209\n",
      "Epoch [111/300], Validation Loss: 0.0197, Validation Accuracy: 0.9929\n",
      "Epoch [112/300], Training Loss: 0.0208\n",
      "Epoch [112/300], Validation Loss: 0.0195, Validation Accuracy: 0.9929\n",
      "Epoch [113/300], Training Loss: 0.0206\n",
      "Epoch [113/300], Validation Loss: 0.0193, Validation Accuracy: 0.9929\n",
      "Epoch [114/300], Training Loss: 0.0205\n",
      "Epoch [114/300], Validation Loss: 0.0191, Validation Accuracy: 0.9929\n",
      "Epoch [115/300], Training Loss: 0.0203\n",
      "Epoch [115/300], Validation Loss: 0.0189, Validation Accuracy: 0.9929\n",
      "Epoch [116/300], Training Loss: 0.0201\n",
      "Epoch [116/300], Validation Loss: 0.0188, Validation Accuracy: 0.9929\n",
      "Epoch [117/300], Training Loss: 0.0200\n",
      "Epoch [117/300], Validation Loss: 0.0186, Validation Accuracy: 0.9929\n",
      "Epoch [118/300], Training Loss: 0.0198\n",
      "Epoch [118/300], Validation Loss: 0.0184, Validation Accuracy: 0.9936\n",
      "Epoch [119/300], Training Loss: 0.0197\n",
      "Epoch [119/300], Validation Loss: 0.0182, Validation Accuracy: 0.9936\n",
      "Epoch [120/300], Training Loss: 0.0195\n",
      "Epoch [120/300], Validation Loss: 0.0181, Validation Accuracy: 0.9936\n",
      "Epoch [121/300], Training Loss: 0.0194\n",
      "Epoch [121/300], Validation Loss: 0.0179, Validation Accuracy: 0.9936\n",
      "Epoch [122/300], Training Loss: 0.0193\n",
      "Epoch [122/300], Validation Loss: 0.0177, Validation Accuracy: 0.9936\n",
      "Epoch [123/300], Training Loss: 0.0191\n",
      "Epoch [123/300], Validation Loss: 0.0175, Validation Accuracy: 0.9936\n",
      "Epoch [124/300], Training Loss: 0.0190\n",
      "Epoch [124/300], Validation Loss: 0.0174, Validation Accuracy: 0.9936\n",
      "Epoch [125/300], Training Loss: 0.0188\n",
      "Epoch [125/300], Validation Loss: 0.0172, Validation Accuracy: 0.9943\n",
      "Epoch [126/300], Training Loss: 0.0187\n",
      "Epoch [126/300], Validation Loss: 0.0171, Validation Accuracy: 0.9943\n",
      "Epoch [127/300], Training Loss: 0.0186\n",
      "Epoch [127/300], Validation Loss: 0.0169, Validation Accuracy: 0.9943\n",
      "Epoch [128/300], Training Loss: 0.0184\n",
      "Epoch [128/300], Validation Loss: 0.0167, Validation Accuracy: 0.9950\n",
      "Epoch [129/300], Training Loss: 0.0183\n",
      "Epoch [129/300], Validation Loss: 0.0166, Validation Accuracy: 0.9950\n",
      "Epoch [130/300], Training Loss: 0.0182\n",
      "Epoch [130/300], Validation Loss: 0.0164, Validation Accuracy: 0.9950\n",
      "Epoch [131/300], Training Loss: 0.0180\n",
      "Epoch [131/300], Validation Loss: 0.0163, Validation Accuracy: 0.9950\n",
      "Epoch [132/300], Training Loss: 0.0179\n",
      "Epoch [132/300], Validation Loss: 0.0161, Validation Accuracy: 0.9950\n",
      "Epoch [133/300], Training Loss: 0.0178\n",
      "Epoch [133/300], Validation Loss: 0.0160, Validation Accuracy: 0.9950\n",
      "Epoch [134/300], Training Loss: 0.0177\n",
      "Epoch [134/300], Validation Loss: 0.0159, Validation Accuracy: 0.9950\n",
      "Epoch [135/300], Training Loss: 0.0175\n",
      "Epoch [135/300], Validation Loss: 0.0157, Validation Accuracy: 0.9950\n",
      "Epoch [136/300], Training Loss: 0.0174\n",
      "Epoch [136/300], Validation Loss: 0.0156, Validation Accuracy: 0.9950\n",
      "Epoch [137/300], Training Loss: 0.0173\n",
      "Epoch [137/300], Validation Loss: 0.0154, Validation Accuracy: 0.9950\n",
      "Epoch [138/300], Training Loss: 0.0172\n",
      "Epoch [138/300], Validation Loss: 0.0153, Validation Accuracy: 0.9950\n",
      "Epoch [139/300], Training Loss: 0.0171\n",
      "Epoch [139/300], Validation Loss: 0.0152, Validation Accuracy: 0.9950\n",
      "Epoch [140/300], Training Loss: 0.0169\n",
      "Epoch [140/300], Validation Loss: 0.0150, Validation Accuracy: 0.9957\n",
      "Epoch [141/300], Training Loss: 0.0168\n",
      "Epoch [141/300], Validation Loss: 0.0149, Validation Accuracy: 0.9964\n",
      "Epoch [142/300], Training Loss: 0.0167\n",
      "Epoch [142/300], Validation Loss: 0.0148, Validation Accuracy: 0.9964\n",
      "Epoch [143/300], Training Loss: 0.0166\n",
      "Epoch [143/300], Validation Loss: 0.0147, Validation Accuracy: 0.9971\n",
      "Epoch [144/300], Training Loss: 0.0165\n",
      "Epoch [144/300], Validation Loss: 0.0145, Validation Accuracy: 0.9979\n",
      "Epoch [145/300], Training Loss: 0.0164\n",
      "Epoch [145/300], Validation Loss: 0.0144, Validation Accuracy: 0.9979\n",
      "Epoch [146/300], Training Loss: 0.0163\n",
      "Epoch [146/300], Validation Loss: 0.0143, Validation Accuracy: 0.9979\n",
      "Epoch [147/300], Training Loss: 0.0162\n",
      "Epoch [147/300], Validation Loss: 0.0142, Validation Accuracy: 0.9979\n",
      "Epoch [148/300], Training Loss: 0.0161\n",
      "Epoch [148/300], Validation Loss: 0.0140, Validation Accuracy: 0.9979\n",
      "Epoch [149/300], Training Loss: 0.0160\n",
      "Epoch [149/300], Validation Loss: 0.0139, Validation Accuracy: 0.9979\n",
      "Epoch [150/300], Training Loss: 0.0158\n",
      "Epoch [150/300], Validation Loss: 0.0138, Validation Accuracy: 0.9979\n",
      "Epoch [151/300], Training Loss: 0.0157\n",
      "Epoch [151/300], Validation Loss: 0.0137, Validation Accuracy: 0.9979\n",
      "Epoch [152/300], Training Loss: 0.0156\n",
      "Epoch [152/300], Validation Loss: 0.0136, Validation Accuracy: 0.9979\n",
      "Epoch [153/300], Training Loss: 0.0155\n",
      "Epoch [153/300], Validation Loss: 0.0135, Validation Accuracy: 0.9979\n",
      "Epoch [154/300], Training Loss: 0.0154\n",
      "Epoch [154/300], Validation Loss: 0.0134, Validation Accuracy: 0.9979\n",
      "Epoch [155/300], Training Loss: 0.0153\n",
      "Epoch [155/300], Validation Loss: 0.0133, Validation Accuracy: 0.9979\n",
      "Epoch [156/300], Training Loss: 0.0152\n",
      "Epoch [156/300], Validation Loss: 0.0131, Validation Accuracy: 0.9986\n",
      "Epoch [157/300], Training Loss: 0.0151\n",
      "Epoch [157/300], Validation Loss: 0.0130, Validation Accuracy: 0.9986\n",
      "Epoch [158/300], Training Loss: 0.0151\n",
      "Epoch [158/300], Validation Loss: 0.0129, Validation Accuracy: 0.9986\n",
      "Epoch [159/300], Training Loss: 0.0150\n",
      "Epoch [159/300], Validation Loss: 0.0128, Validation Accuracy: 0.9986\n",
      "Epoch [160/300], Training Loss: 0.0149\n",
      "Epoch [160/300], Validation Loss: 0.0127, Validation Accuracy: 0.9986\n",
      "Epoch [161/300], Training Loss: 0.0148\n",
      "Epoch [161/300], Validation Loss: 0.0126, Validation Accuracy: 0.9986\n",
      "Epoch [162/300], Training Loss: 0.0147\n",
      "Epoch [162/300], Validation Loss: 0.0125, Validation Accuracy: 0.9986\n",
      "Epoch [163/300], Training Loss: 0.0146\n",
      "Epoch [163/300], Validation Loss: 0.0124, Validation Accuracy: 0.9986\n",
      "Epoch [164/300], Training Loss: 0.0145\n",
      "Epoch [164/300], Validation Loss: 0.0123, Validation Accuracy: 0.9986\n",
      "Epoch [165/300], Training Loss: 0.0144\n",
      "Epoch [165/300], Validation Loss: 0.0122, Validation Accuracy: 0.9986\n",
      "Epoch [166/300], Training Loss: 0.0143\n",
      "Epoch [166/300], Validation Loss: 0.0121, Validation Accuracy: 0.9986\n",
      "Epoch [167/300], Training Loss: 0.0142\n",
      "Epoch [167/300], Validation Loss: 0.0120, Validation Accuracy: 0.9986\n",
      "Epoch [168/300], Training Loss: 0.0141\n",
      "Epoch [168/300], Validation Loss: 0.0120, Validation Accuracy: 0.9986\n",
      "Epoch [169/300], Training Loss: 0.0140\n",
      "Epoch [169/300], Validation Loss: 0.0119, Validation Accuracy: 0.9986\n",
      "Epoch [170/300], Training Loss: 0.0140\n",
      "Epoch [170/300], Validation Loss: 0.0118, Validation Accuracy: 0.9986\n",
      "Epoch [171/300], Training Loss: 0.0139\n",
      "Epoch [171/300], Validation Loss: 0.0117, Validation Accuracy: 0.9986\n",
      "Epoch [172/300], Training Loss: 0.0138\n",
      "Epoch [172/300], Validation Loss: 0.0116, Validation Accuracy: 0.9986\n",
      "Epoch [173/300], Training Loss: 0.0137\n",
      "Epoch [173/300], Validation Loss: 0.0115, Validation Accuracy: 0.9986\n",
      "Epoch [174/300], Training Loss: 0.0136\n",
      "Epoch [174/300], Validation Loss: 0.0114, Validation Accuracy: 0.9986\n",
      "Epoch [175/300], Training Loss: 0.0135\n",
      "Epoch [175/300], Validation Loss: 0.0113, Validation Accuracy: 0.9986\n",
      "Epoch [176/300], Training Loss: 0.0135\n",
      "Epoch [176/300], Validation Loss: 0.0112, Validation Accuracy: 0.9986\n",
      "Epoch [177/300], Training Loss: 0.0134\n",
      "Epoch [177/300], Validation Loss: 0.0112, Validation Accuracy: 0.9986\n",
      "Epoch [178/300], Training Loss: 0.0133\n",
      "Epoch [178/300], Validation Loss: 0.0111, Validation Accuracy: 0.9986\n",
      "Epoch [179/300], Training Loss: 0.0132\n",
      "Epoch [179/300], Validation Loss: 0.0110, Validation Accuracy: 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [180/300], Training Loss: 0.0131\n",
      "Epoch [180/300], Validation Loss: 0.0109, Validation Accuracy: 0.9986\n",
      "Epoch [181/300], Training Loss: 0.0131\n",
      "Epoch [181/300], Validation Loss: 0.0108, Validation Accuracy: 0.9986\n",
      "Epoch [182/300], Training Loss: 0.0130\n",
      "Epoch [182/300], Validation Loss: 0.0108, Validation Accuracy: 0.9986\n",
      "Epoch [183/300], Training Loss: 0.0129\n",
      "Epoch [183/300], Validation Loss: 0.0107, Validation Accuracy: 0.9986\n",
      "Epoch [184/300], Training Loss: 0.0128\n",
      "Epoch [184/300], Validation Loss: 0.0106, Validation Accuracy: 0.9986\n",
      "Epoch [185/300], Training Loss: 0.0127\n",
      "Epoch [185/300], Validation Loss: 0.0105, Validation Accuracy: 0.9993\n",
      "Epoch [186/300], Training Loss: 0.0127\n",
      "Epoch [186/300], Validation Loss: 0.0104, Validation Accuracy: 0.9993\n",
      "Epoch [187/300], Training Loss: 0.0126\n",
      "Epoch [187/300], Validation Loss: 0.0104, Validation Accuracy: 0.9993\n",
      "Epoch [188/300], Training Loss: 0.0125\n",
      "Epoch [188/300], Validation Loss: 0.0103, Validation Accuracy: 0.9993\n",
      "Epoch [189/300], Training Loss: 0.0124\n",
      "Epoch [189/300], Validation Loss: 0.0102, Validation Accuracy: 0.9993\n",
      "Epoch [190/300], Training Loss: 0.0124\n",
      "Epoch [190/300], Validation Loss: 0.0101, Validation Accuracy: 0.9993\n",
      "Epoch [191/300], Training Loss: 0.0123\n",
      "Epoch [191/300], Validation Loss: 0.0101, Validation Accuracy: 0.9993\n",
      "Epoch [192/300], Training Loss: 0.0122\n",
      "Epoch [192/300], Validation Loss: 0.0100, Validation Accuracy: 0.9993\n",
      "Epoch [193/300], Training Loss: 0.0122\n",
      "Epoch [193/300], Validation Loss: 0.0099, Validation Accuracy: 0.9993\n",
      "Epoch [194/300], Training Loss: 0.0121\n",
      "Epoch [194/300], Validation Loss: 0.0099, Validation Accuracy: 0.9993\n",
      "Epoch [195/300], Training Loss: 0.0120\n",
      "Epoch [195/300], Validation Loss: 0.0098, Validation Accuracy: 0.9993\n",
      "Epoch [196/300], Training Loss: 0.0119\n",
      "Epoch [196/300], Validation Loss: 0.0097, Validation Accuracy: 0.9993\n",
      "Epoch [197/300], Training Loss: 0.0119\n",
      "Epoch [197/300], Validation Loss: 0.0097, Validation Accuracy: 0.9993\n",
      "Epoch [198/300], Training Loss: 0.0118\n",
      "Epoch [198/300], Validation Loss: 0.0096, Validation Accuracy: 0.9993\n",
      "Epoch [199/300], Training Loss: 0.0117\n",
      "Epoch [199/300], Validation Loss: 0.0095, Validation Accuracy: 0.9993\n",
      "Epoch [200/300], Training Loss: 0.0117\n",
      "Epoch [200/300], Validation Loss: 0.0095, Validation Accuracy: 0.9993\n",
      "Epoch [201/300], Training Loss: 0.0116\n",
      "Epoch [201/300], Validation Loss: 0.0094, Validation Accuracy: 0.9993\n",
      "Epoch [202/300], Training Loss: 0.0115\n",
      "Epoch [202/300], Validation Loss: 0.0093, Validation Accuracy: 0.9993\n",
      "Epoch [203/300], Training Loss: 0.0115\n",
      "Epoch [203/300], Validation Loss: 0.0093, Validation Accuracy: 0.9993\n",
      "Epoch [204/300], Training Loss: 0.0114\n",
      "Epoch [204/300], Validation Loss: 0.0092, Validation Accuracy: 0.9993\n",
      "Epoch [205/300], Training Loss: 0.0113\n",
      "Epoch [205/300], Validation Loss: 0.0091, Validation Accuracy: 0.9993\n",
      "Epoch [206/300], Training Loss: 0.0113\n",
      "Epoch [206/300], Validation Loss: 0.0091, Validation Accuracy: 0.9993\n",
      "Epoch [207/300], Training Loss: 0.0112\n",
      "Epoch [207/300], Validation Loss: 0.0090, Validation Accuracy: 0.9993\n",
      "Epoch [208/300], Training Loss: 0.0111\n",
      "Epoch [208/300], Validation Loss: 0.0090, Validation Accuracy: 0.9993\n",
      "Epoch [209/300], Training Loss: 0.0111\n",
      "Epoch [209/300], Validation Loss: 0.0089, Validation Accuracy: 0.9993\n",
      "Epoch [210/300], Training Loss: 0.0110\n",
      "Epoch [210/300], Validation Loss: 0.0088, Validation Accuracy: 0.9993\n",
      "Epoch [211/300], Training Loss: 0.0110\n",
      "Epoch [211/300], Validation Loss: 0.0088, Validation Accuracy: 0.9993\n",
      "Epoch [212/300], Training Loss: 0.0109\n",
      "Epoch [212/300], Validation Loss: 0.0087, Validation Accuracy: 0.9993\n",
      "Epoch [213/300], Training Loss: 0.0108\n",
      "Epoch [213/300], Validation Loss: 0.0087, Validation Accuracy: 0.9993\n",
      "Epoch [214/300], Training Loss: 0.0108\n",
      "Epoch [214/300], Validation Loss: 0.0086, Validation Accuracy: 0.9993\n",
      "Epoch [215/300], Training Loss: 0.0107\n",
      "Epoch [215/300], Validation Loss: 0.0085, Validation Accuracy: 0.9993\n",
      "Epoch [216/300], Training Loss: 0.0106\n",
      "Epoch [216/300], Validation Loss: 0.0085, Validation Accuracy: 0.9993\n",
      "Epoch [217/300], Training Loss: 0.0106\n",
      "Epoch [217/300], Validation Loss: 0.0084, Validation Accuracy: 0.9993\n",
      "Epoch [218/300], Training Loss: 0.0105\n",
      "Epoch [218/300], Validation Loss: 0.0084, Validation Accuracy: 0.9993\n",
      "Epoch [219/300], Training Loss: 0.0105\n",
      "Epoch [219/300], Validation Loss: 0.0083, Validation Accuracy: 0.9993\n",
      "Epoch [220/300], Training Loss: 0.0104\n",
      "Epoch [220/300], Validation Loss: 0.0083, Validation Accuracy: 0.9993\n",
      "Epoch [221/300], Training Loss: 0.0103\n",
      "Epoch [221/300], Validation Loss: 0.0082, Validation Accuracy: 0.9993\n",
      "Epoch [222/300], Training Loss: 0.0103\n",
      "Epoch [222/300], Validation Loss: 0.0082, Validation Accuracy: 0.9993\n",
      "Epoch [223/300], Training Loss: 0.0102\n",
      "Epoch [223/300], Validation Loss: 0.0081, Validation Accuracy: 0.9993\n",
      "Epoch [224/300], Training Loss: 0.0102\n",
      "Epoch [224/300], Validation Loss: 0.0081, Validation Accuracy: 0.9993\n",
      "Epoch [225/300], Training Loss: 0.0101\n",
      "Epoch [225/300], Validation Loss: 0.0080, Validation Accuracy: 0.9993\n",
      "Epoch [226/300], Training Loss: 0.0101\n",
      "Epoch [226/300], Validation Loss: 0.0080, Validation Accuracy: 0.9993\n",
      "Epoch [227/300], Training Loss: 0.0100\n",
      "Epoch [227/300], Validation Loss: 0.0079, Validation Accuracy: 0.9993\n",
      "Epoch [228/300], Training Loss: 0.0099\n",
      "Epoch [228/300], Validation Loss: 0.0079, Validation Accuracy: 0.9993\n",
      "Epoch [229/300], Training Loss: 0.0099\n",
      "Epoch [229/300], Validation Loss: 0.0078, Validation Accuracy: 0.9993\n",
      "Epoch [230/300], Training Loss: 0.0098\n",
      "Epoch [230/300], Validation Loss: 0.0078, Validation Accuracy: 0.9993\n",
      "Epoch [231/300], Training Loss: 0.0098\n",
      "Epoch [231/300], Validation Loss: 0.0077, Validation Accuracy: 0.9993\n",
      "Epoch [232/300], Training Loss: 0.0097\n",
      "Epoch [232/300], Validation Loss: 0.0077, Validation Accuracy: 0.9993\n",
      "Epoch [233/300], Training Loss: 0.0097\n",
      "Epoch [233/300], Validation Loss: 0.0076, Validation Accuracy: 0.9993\n",
      "Epoch [234/300], Training Loss: 0.0096\n",
      "Epoch [234/300], Validation Loss: 0.0076, Validation Accuracy: 0.9993\n",
      "Epoch [235/300], Training Loss: 0.0096\n",
      "Epoch [235/300], Validation Loss: 0.0075, Validation Accuracy: 0.9993\n",
      "Epoch [236/300], Training Loss: 0.0095\n",
      "Epoch [236/300], Validation Loss: 0.0075, Validation Accuracy: 0.9993\n",
      "Epoch [237/300], Training Loss: 0.0095\n",
      "Epoch [237/300], Validation Loss: 0.0074, Validation Accuracy: 0.9993\n",
      "Epoch [238/300], Training Loss: 0.0094\n",
      "Epoch [238/300], Validation Loss: 0.0074, Validation Accuracy: 0.9993\n",
      "Epoch [239/300], Training Loss: 0.0094\n",
      "Epoch [239/300], Validation Loss: 0.0073, Validation Accuracy: 0.9993\n",
      "Epoch [240/300], Training Loss: 0.0093\n",
      "Epoch [240/300], Validation Loss: 0.0073, Validation Accuracy: 0.9993\n",
      "Epoch [241/300], Training Loss: 0.0093\n",
      "Epoch [241/300], Validation Loss: 0.0073, Validation Accuracy: 0.9993\n",
      "Epoch [242/300], Training Loss: 0.0092\n",
      "Epoch [242/300], Validation Loss: 0.0072, Validation Accuracy: 0.9993\n",
      "Epoch [243/300], Training Loss: 0.0091\n",
      "Epoch [243/300], Validation Loss: 0.0072, Validation Accuracy: 0.9993\n",
      "Epoch [244/300], Training Loss: 0.0091\n",
      "Epoch [244/300], Validation Loss: 0.0071, Validation Accuracy: 0.9993\n",
      "Epoch [245/300], Training Loss: 0.0090\n",
      "Epoch [245/300], Validation Loss: 0.0071, Validation Accuracy: 0.9993\n",
      "Epoch [246/300], Training Loss: 0.0090\n",
      "Epoch [246/300], Validation Loss: 0.0070, Validation Accuracy: 0.9993\n",
      "Epoch [247/300], Training Loss: 0.0090\n",
      "Epoch [247/300], Validation Loss: 0.0070, Validation Accuracy: 0.9993\n",
      "Epoch [248/300], Training Loss: 0.0089\n",
      "Epoch [248/300], Validation Loss: 0.0070, Validation Accuracy: 1.0000\n",
      "Epoch [249/300], Training Loss: 0.0089\n",
      "Epoch [249/300], Validation Loss: 0.0069, Validation Accuracy: 1.0000\n",
      "Epoch [250/300], Training Loss: 0.0088\n",
      "Epoch [250/300], Validation Loss: 0.0069, Validation Accuracy: 1.0000\n",
      "Epoch [251/300], Training Loss: 0.0088\n",
      "Epoch [251/300], Validation Loss: 0.0068, Validation Accuracy: 1.0000\n",
      "Epoch [252/300], Training Loss: 0.0087\n",
      "Epoch [252/300], Validation Loss: 0.0068, Validation Accuracy: 1.0000\n",
      "Epoch [253/300], Training Loss: 0.0087\n",
      "Epoch [253/300], Validation Loss: 0.0068, Validation Accuracy: 1.0000\n",
      "Epoch [254/300], Training Loss: 0.0086\n",
      "Epoch [254/300], Validation Loss: 0.0067, Validation Accuracy: 1.0000\n",
      "Epoch [255/300], Training Loss: 0.0086\n",
      "Epoch [255/300], Validation Loss: 0.0067, Validation Accuracy: 1.0000\n",
      "Epoch [256/300], Training Loss: 0.0085\n",
      "Epoch [256/300], Validation Loss: 0.0066, Validation Accuracy: 1.0000\n",
      "Epoch [257/300], Training Loss: 0.0085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [257/300], Validation Loss: 0.0066, Validation Accuracy: 1.0000\n",
      "Epoch [258/300], Training Loss: 0.0084\n",
      "Epoch [258/300], Validation Loss: 0.0066, Validation Accuracy: 1.0000\n",
      "Epoch [259/300], Training Loss: 0.0084\n",
      "Epoch [259/300], Validation Loss: 0.0065, Validation Accuracy: 1.0000\n",
      "Epoch [260/300], Training Loss: 0.0083\n",
      "Epoch [260/300], Validation Loss: 0.0065, Validation Accuracy: 1.0000\n",
      "Epoch [261/300], Training Loss: 0.0083\n",
      "Epoch [261/300], Validation Loss: 0.0064, Validation Accuracy: 1.0000\n",
      "Epoch [262/300], Training Loss: 0.0083\n",
      "Epoch [262/300], Validation Loss: 0.0064, Validation Accuracy: 1.0000\n",
      "Epoch [263/300], Training Loss: 0.0082\n",
      "Epoch [263/300], Validation Loss: 0.0064, Validation Accuracy: 1.0000\n",
      "Epoch [264/300], Training Loss: 0.0082\n",
      "Epoch [264/300], Validation Loss: 0.0063, Validation Accuracy: 1.0000\n",
      "Epoch [265/300], Training Loss: 0.0081\n",
      "Epoch [265/300], Validation Loss: 0.0063, Validation Accuracy: 1.0000\n",
      "Epoch [266/300], Training Loss: 0.0081\n",
      "Epoch [266/300], Validation Loss: 0.0063, Validation Accuracy: 1.0000\n",
      "Epoch [267/300], Training Loss: 0.0080\n",
      "Epoch [267/300], Validation Loss: 0.0062, Validation Accuracy: 1.0000\n",
      "Epoch [268/300], Training Loss: 0.0080\n",
      "Epoch [268/300], Validation Loss: 0.0062, Validation Accuracy: 1.0000\n",
      "Epoch [269/300], Training Loss: 0.0079\n",
      "Epoch [269/300], Validation Loss: 0.0062, Validation Accuracy: 1.0000\n",
      "Epoch [270/300], Training Loss: 0.0079\n",
      "Epoch [270/300], Validation Loss: 0.0061, Validation Accuracy: 1.0000\n",
      "Epoch [271/300], Training Loss: 0.0079\n",
      "Epoch [271/300], Validation Loss: 0.0061, Validation Accuracy: 1.0000\n",
      "Epoch [272/300], Training Loss: 0.0078\n",
      "Epoch [272/300], Validation Loss: 0.0061, Validation Accuracy: 1.0000\n",
      "Epoch [273/300], Training Loss: 0.0078\n",
      "Epoch [273/300], Validation Loss: 0.0060, Validation Accuracy: 1.0000\n",
      "Epoch [274/300], Training Loss: 0.0077\n",
      "Epoch [274/300], Validation Loss: 0.0060, Validation Accuracy: 1.0000\n",
      "Epoch [275/300], Training Loss: 0.0077\n",
      "Epoch [275/300], Validation Loss: 0.0060, Validation Accuracy: 1.0000\n",
      "Epoch [276/300], Training Loss: 0.0077\n",
      "Epoch [276/300], Validation Loss: 0.0059, Validation Accuracy: 1.0000\n",
      "Epoch [277/300], Training Loss: 0.0076\n",
      "Epoch [277/300], Validation Loss: 0.0059, Validation Accuracy: 1.0000\n",
      "Epoch [278/300], Training Loss: 0.0076\n",
      "Epoch [278/300], Validation Loss: 0.0059, Validation Accuracy: 1.0000\n",
      "Epoch [279/300], Training Loss: 0.0075\n",
      "Epoch [279/300], Validation Loss: 0.0058, Validation Accuracy: 1.0000\n",
      "Epoch [280/300], Training Loss: 0.0075\n",
      "Epoch [280/300], Validation Loss: 0.0058, Validation Accuracy: 1.0000\n",
      "Epoch [281/300], Training Loss: 0.0075\n",
      "Epoch [281/300], Validation Loss: 0.0058, Validation Accuracy: 1.0000\n",
      "Epoch [282/300], Training Loss: 0.0074\n",
      "Epoch [282/300], Validation Loss: 0.0057, Validation Accuracy: 1.0000\n",
      "Epoch [283/300], Training Loss: 0.0074\n",
      "Epoch [283/300], Validation Loss: 0.0057, Validation Accuracy: 1.0000\n",
      "Epoch [284/300], Training Loss: 0.0073\n",
      "Epoch [284/300], Validation Loss: 0.0057, Validation Accuracy: 1.0000\n",
      "Epoch [285/300], Training Loss: 0.0073\n",
      "Epoch [285/300], Validation Loss: 0.0056, Validation Accuracy: 1.0000\n",
      "Epoch [286/300], Training Loss: 0.0073\n",
      "Epoch [286/300], Validation Loss: 0.0056, Validation Accuracy: 1.0000\n",
      "Epoch [287/300], Training Loss: 0.0072\n",
      "Epoch [287/300], Validation Loss: 0.0056, Validation Accuracy: 1.0000\n",
      "Epoch [288/300], Training Loss: 0.0072\n",
      "Epoch [288/300], Validation Loss: 0.0055, Validation Accuracy: 1.0000\n",
      "Epoch [289/300], Training Loss: 0.0071\n",
      "Epoch [289/300], Validation Loss: 0.0055, Validation Accuracy: 1.0000\n",
      "Epoch [290/300], Training Loss: 0.0071\n",
      "Epoch [290/300], Validation Loss: 0.0055, Validation Accuracy: 1.0000\n",
      "Epoch [291/300], Training Loss: 0.0071\n",
      "Epoch [291/300], Validation Loss: 0.0055, Validation Accuracy: 1.0000\n",
      "Epoch [292/300], Training Loss: 0.0070\n",
      "Epoch [292/300], Validation Loss: 0.0054, Validation Accuracy: 1.0000\n",
      "Epoch [293/300], Training Loss: 0.0070\n",
      "Epoch [293/300], Validation Loss: 0.0054, Validation Accuracy: 1.0000\n",
      "Epoch [294/300], Training Loss: 0.0070\n",
      "Epoch [294/300], Validation Loss: 0.0054, Validation Accuracy: 1.0000\n",
      "Epoch [295/300], Training Loss: 0.0069\n",
      "Epoch [295/300], Validation Loss: 0.0053, Validation Accuracy: 1.0000\n",
      "Epoch [296/300], Training Loss: 0.0069\n",
      "Epoch [296/300], Validation Loss: 0.0053, Validation Accuracy: 1.0000\n",
      "Epoch [297/300], Training Loss: 0.0069\n",
      "Epoch [297/300], Validation Loss: 0.0053, Validation Accuracy: 1.0000\n",
      "Epoch [298/300], Training Loss: 0.0068\n",
      "Epoch [298/300], Validation Loss: 0.0053, Validation Accuracy: 1.0000\n",
      "Epoch [299/300], Training Loss: 0.0068\n",
      "Epoch [299/300], Validation Loss: 0.0052, Validation Accuracy: 1.0000\n",
      "Epoch [300/300], Training Loss: 0.0067\n",
      "Epoch [300/300], Validation Loss: 0.0052, Validation Accuracy: 1.0000\n",
      "Test Accuracy: 0.9985744832501782\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features_df = pd.read_csv('features.csv')\n",
    "\n",
    "# Extract features and corresponding labels\n",
    "X = features_df.iloc[:, :-1].values  # features \n",
    "y = features_df.iloc[:, -1].values  # labels \n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the labels\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64 \n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 300 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    outputs = model(X_train_tensor.unsqueeze(1))  \n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs.squeeze(), y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor.unsqueeze(1))\n",
    "        val_loss = criterion(val_outputs.squeeze(), y_val)\n",
    "        _, val_predicted = torch.max(val_outputs, 1)\n",
    "        val_accuracy = accuracy_score(y_val.numpy(), val_predicted.numpy())\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss.item():.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor.unsqueeze(1))\n",
    "    _, test_predicted = torch.max(test_outputs, 1)\n",
    "    test_accuracy = accuracy_score(y_test.numpy(), test_predicted.numpy())\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2689db",
   "metadata": {},
   "source": [
    "## Test phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f32215ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in something directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "\n",
    "        # MFCC (Mel-frequency cepstral coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "        # Chroma feature\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral contrast\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral centroid\n",
    "        spectral_centroids = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Zero-crossing rate\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio).T, axis=0)\n",
    "\n",
    "        # Spectral rolloff\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Combine all features into a 1D array\n",
    "        features = np.hstack([mfccs_processed, chroma_stft, spectral_contrast, spectral_centroids, zero_crossing_rate, spectral_rolloff])\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_name}\")\n",
    "        return None\n",
    "\n",
    "# Specify the directories containing the .mp3 files\n",
    "directories = ['something']\n",
    "\n",
    "# Create an empty DataFrame \n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "for directory in directories:\n",
    "    print(f\"Processing files in {directory} directory\")\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                features = extract_features(file_path)\n",
    "                # Append the features to the DataFrame as a new row\n",
    "                if features is not None:\n",
    "                    features_series = pd.Series(features)\n",
    "                    features_df = pd.concat([features_df, features_series], axis=0)  # Concatenate along rows (axis=0)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered while processing file: {file_path}\")\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8cfb4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-224.141861</td>\n",
       "      <td>123.548615</td>\n",
       "      <td>-11.934964</td>\n",
       "      <td>35.14872</td>\n",
       "      <td>-2.978472</td>\n",
       "      <td>11.988633</td>\n",
       "      <td>-10.192609</td>\n",
       "      <td>7.214376</td>\n",
       "      <td>-13.9877</td>\n",
       "      <td>1.976113</td>\n",
       "      <td>...</td>\n",
       "      <td>20.868756</td>\n",
       "      <td>15.711451</td>\n",
       "      <td>19.730115</td>\n",
       "      <td>19.38868</td>\n",
       "      <td>19.780333</td>\n",
       "      <td>19.137458</td>\n",
       "      <td>41.547228</td>\n",
       "      <td>1692.69833</td>\n",
       "      <td>0.082245</td>\n",
       "      <td>3374.557483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2         3         4          5   \\\n",
       "0 -224.141861  123.548615 -11.934964  35.14872 -2.978472  11.988633   \n",
       "\n",
       "          6         7        8         9   ...         52         53  \\\n",
       "0 -10.192609  7.214376 -13.9877  1.976113  ...  20.868756  15.711451   \n",
       "\n",
       "          54        55         56         57         58          59        60  \\\n",
       "0  19.730115  19.38868  19.780333  19.137458  41.547228  1692.69833  0.082245   \n",
       "\n",
       "            61  \n",
       "0  3374.557483  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new= features_df.T\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e7bf0",
   "metadata": {},
   "source": [
    "## load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f7f60ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loaded_model = RNN( input_size, hidden_size, num_classes)\n",
    "\n",
    "\n",
    "loaded_model.load_state_dict(torch.load('rnn_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b079b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.eval()  \n",
    "\n",
    "\n",
    "X_new = scaler.transform(X_new) \n",
    "X_new_tensor = torch.tensor(X_new, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    new_outputs = loaded_model(X_new_tensor.unsqueeze(1))\n",
    "    _, new_predicted = torch.max(new_outputs, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d09666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "print(new_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab21417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing audio buffer with 1-minute audio...\n",
      "Initialization complete.\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 0.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 0.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 0.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 0.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 0.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 0.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 0.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n",
      "Predicted Class: 1.0\n",
      "Sliding the window by 10 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 100\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Entry point\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[43mrecord_and_classify_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 64\u001b[0m, in \u001b[0;36mrecord_and_classify_audio\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Record new 10 seconds of audio data\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, ten_sec_frames):\n\u001b[0;32m---> 64\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     audio_frames\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Save the recorded audio to a WAV file\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import os\n",
    "import pandas as pd  # Import pandas if not already imported\n",
    "import torch  # Import PyTorch if not already imported\n",
    "\n",
    "\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "\n",
    "        # MFCC (Mel-frequency cepstral coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "        # Chroma feature\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral contrast\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral centroid\n",
    "        spectral_centroids = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Zero-crossing rate\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio).T, axis=0)\n",
    "\n",
    "        # Spectral rolloff\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Combine all features into a 1D array\n",
    "        features = np.hstack([mfccs_processed, chroma_stft, spectral_contrast, spectral_centroids, zero_crossing_rate, spectral_rolloff])\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_name}\")\n",
    "        return None\n",
    "\n",
    "def record_and_classify_audio():\n",
    "    audio_duration = 60  # Record audio for 1 minute\n",
    "    sample_rate = 44100  # 44.1kHz\n",
    "    ten_sec_frames = int(sample_rate / 1024 * 10)  # Number of frames for 10 seconds\n",
    "\n",
    "    audio_frames = []\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=sample_rate, input=True, frames_per_buffer=1024)\n",
    "    \n",
    "    # Initialize the buffer with 1-minute audio data\n",
    "    print(\"Initializing audio buffer with 1-minute audio...\")\n",
    "    for _ in range(0, int(sample_rate / 1024 * audio_duration)):\n",
    "        data = stream.read(1024)\n",
    "        audio_frames.append(data)\n",
    "    print(\"Initialization complete.\")\n",
    "\n",
    "    while True:\n",
    "        # Slide the window by 10 seconds\n",
    "        print(\"Sliding the window by 10 seconds...\")\n",
    "        audio_frames = audio_frames[ten_sec_frames:]  # Remove the first 10 seconds\n",
    "        \n",
    "        # Record new 10 seconds of audio data\n",
    "        for _ in range(0, ten_sec_frames):\n",
    "            data = stream.read(1024)\n",
    "            audio_frames.append(data)\n",
    "\n",
    "        # Save the recorded audio to a WAV file\n",
    "        output_audio_file = \"recorded_audio.wav\"\n",
    "        wf = wave.open(output_audio_file, 'wb')\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(b''.join(audio_frames))\n",
    "        wf.close()\n",
    "\n",
    "        # extract features \n",
    "        recorded_features = extract_features(output_audio_file)\n",
    "\n",
    "        if recorded_features is not None:\n",
    "            recorded_df = pd.DataFrame([recorded_features])\n",
    "            recorded_df = scaler.transform(recorded_df)\n",
    "            model.eval()\n",
    "            recorded_tensor = torch.tensor(recorded_df, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                predicted_output = model(recorded_tensor.unsqueeze(1))\n",
    "                _, predicted_class = torch.max(predicted_output, 1)\n",
    "\n",
    "            predicted_class_label = label_encoder.inverse_transform(predicted_class.numpy())\n",
    "            print(\"Predicted Class:\", predicted_class_label[0])\n",
    "\n",
    "            # Delete the audio file\n",
    "            os.remove(output_audio_file)\n",
    "        else:\n",
    "            print(\"Error occurred while extracting features from recorded audio.\")\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    record_and_classify_audio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789a5c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing 1-minute audio buffer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.008] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@0.008] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n",
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliding the window by 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waqar/.local/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return f(*args, **kwargs)\n",
      "Exception in thread Thread-6 (record_and_classify_audio):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_61232/829340840.py\", line 68, in record_and_classify_audio\n",
      "  File \"/home/waqar/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_61232/2817500600.py\", line 47, in forward\n",
      "IndexError: too many indices for tensor of dimension 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m audio_thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Start video capture and display in the main thread\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[43mcapture_and_display_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m audio_thread\u001b[38;5;241m.\u001b[39mjoin()\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36mcapture_and_display_video\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[1;32m     18\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo\u001b[39m\u001b[38;5;124m'\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m480\u001b[39m)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import pandas as pd\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def capture_and_display_video():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            cv2.imshow('Video', cv2.resize(frame, (640, 480)))\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "def record_and_classify_audio():\n",
    "    audio_duration = 60  # 1 minute\n",
    "    sample_rate = 44100  \n",
    "    ten_sec_frames = int(sample_rate / 1024 * 10)\n",
    "\n",
    "    audio_frames = []\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=sample_rate, input=True, frames_per_buffer=1024)\n",
    "\n",
    "    # Initialize the audio buffer\n",
    "    print(\"Initializing 1-minute audio buffer...\")\n",
    "    for _ in range(0, int(sample_rate / 1024 * audio_duration)):\n",
    "        data = stream.read(1024)\n",
    "        audio_frames.append(data)\n",
    "\n",
    "    while True:\n",
    "        print(\"Sliding the window by 10 seconds...\")\n",
    "        audio_frames = audio_frames[ten_sec_frames:]\n",
    "        \n",
    "        for _ in range(0, ten_sec_frames):\n",
    "            data = stream.read(1024)\n",
    "            audio_frames.append(data)\n",
    "\n",
    "        output_audio_file = \"recorded_audio.wav\"\n",
    "        wf = wave.open(output_audio_file, 'wb')\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(b''.join(audio_frames))\n",
    "        wf.close()\n",
    "\n",
    "        recorded_features = extract_features(output_audio_file)\n",
    "\n",
    "        if recorded_features is not None:\n",
    "            recorded_df = pd.DataFrame([recorded_features])\n",
    "            recorded_df = scaler.transform(recorded_df)\n",
    "            \n",
    "            model.eval()\n",
    "            recorded_tensor = torch.tensor(recorded_df, dtype=torch.float32)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predicted_output = model(recorded_tensor)\n",
    "                _, predicted_class = torch.max(predicted_output, 1)\n",
    "            \n",
    "            predicted_class_label = label_encoder.inverse_transform(predicted_class.numpy())\n",
    "            print(\"Predicted Class:\", predicted_class_label[0])\n",
    "\n",
    "            os.remove(output_audio_file)\n",
    "        else:\n",
    "            print(\"Error in feature extraction.\")\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "# Entry point\n",
    "if __name__ == '__main__':\n",
    "    # Start audio recording and processing in a separate thread\n",
    "    audio_thread = threading.Thread(target=record_and_classify_audio)\n",
    "    audio_thread.start()\n",
    "    \n",
    "    # Start video capture and display in the main thread\n",
    "    capture_and_display_video()\n",
    "\n",
    "    audio_thread.join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cc9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def test_video_capture():\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Couldn't open the camera.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Couldn't read a frame.\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow('Test', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "test_video_capture()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e0db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
