{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd282ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in my_new_60/commercial directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3616/3616 [1:35:51<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in my_new_60/non_commercial directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██▊                                   | 256/3397 [06:15<1:15:44,  1.45s/it]/home/waqar/.local/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return f(*args, **kwargs)\n",
      "100%|█████████████████████████████████████| 3397/3397 [1:26:41<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to features.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "\n",
    "        # MFCC (Mel-frequency cepstral coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "        # Chroma feature\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral contrast\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral centroid\n",
    "        spectral_centroids = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Zero-crossing rate\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio).T, axis=0)\n",
    "\n",
    "        # Spectral rolloff\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Combine all features into a 1D array\n",
    "        features = np.hstack([mfccs_processed, chroma_stft, spectral_contrast, spectral_centroids, zero_crossing_rate, spectral_rolloff])\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_name}\")\n",
    "        return None\n",
    "\n",
    "directories = ['my_new_60/commercial', 'my_new_60/non_commercial']\n",
    "label_dict = {'my_new_60/commercial': 0, 'my_new_60/non_commercial': 1}\n",
    "\n",
    "# Create an empty DataFrame to store the features\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "for directory in directories:\n",
    "    print(f\"Processing files in {directory} directory\")\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                features = extract_features(file_path)\n",
    "                # Append the features to the DataFrame\n",
    "                if features is not None:\n",
    "                    temp_df = pd.DataFrame([np.append(features, label_dict[directory])])\n",
    "                    features_df = pd.concat([features_df, temp_df], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered while processing file: {file_path}\")\n",
    "                continue\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "try:\n",
    "    features_df.to_csv('features.csv', index=False)\n",
    "    print(\"Features saved to features.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Error encountered while saving features to CSV: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5c48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf0af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5ab1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Training Loss: 0.8146\n",
      "Epoch [1/300], Validation Loss: 0.7448, Validation Accuracy: 0.3493\n",
      "Epoch [2/300], Training Loss: 0.7426\n",
      "Epoch [2/300], Validation Loss: 0.6784, Validation Accuracy: 0.5909\n",
      "Epoch [3/300], Training Loss: 0.6755\n",
      "Epoch [3/300], Validation Loss: 0.6169, Validation Accuracy: 0.8011\n",
      "Epoch [4/300], Training Loss: 0.6135\n",
      "Epoch [4/300], Validation Loss: 0.5605, Validation Accuracy: 0.9009\n",
      "Epoch [5/300], Training Loss: 0.5566\n",
      "Epoch [5/300], Validation Loss: 0.5090, Validation Accuracy: 0.9351\n",
      "Epoch [6/300], Training Loss: 0.5048\n",
      "Epoch [6/300], Validation Loss: 0.4623, Validation Accuracy: 0.9522\n",
      "Epoch [7/300], Training Loss: 0.4578\n",
      "Epoch [7/300], Validation Loss: 0.4201, Validation Accuracy: 0.9615\n",
      "Epoch [8/300], Training Loss: 0.4154\n",
      "Epoch [8/300], Validation Loss: 0.3820, Validation Accuracy: 0.9694\n",
      "Epoch [9/300], Training Loss: 0.3774\n",
      "Epoch [9/300], Validation Loss: 0.3479, Validation Accuracy: 0.9708\n",
      "Epoch [10/300], Training Loss: 0.3433\n",
      "Epoch [10/300], Validation Loss: 0.3174, Validation Accuracy: 0.9736\n",
      "Epoch [11/300], Training Loss: 0.3129\n",
      "Epoch [11/300], Validation Loss: 0.2901, Validation Accuracy: 0.9729\n",
      "Epoch [12/300], Training Loss: 0.2858\n",
      "Epoch [12/300], Validation Loss: 0.2658, Validation Accuracy: 0.9743\n",
      "Epoch [13/300], Training Loss: 0.2617\n",
      "Epoch [13/300], Validation Loss: 0.2442, Validation Accuracy: 0.9758\n",
      "Epoch [14/300], Training Loss: 0.2403\n",
      "Epoch [14/300], Validation Loss: 0.2249, Validation Accuracy: 0.9765\n",
      "Epoch [15/300], Training Loss: 0.2213\n",
      "Epoch [15/300], Validation Loss: 0.2078, Validation Accuracy: 0.9751\n",
      "Epoch [16/300], Training Loss: 0.2044\n",
      "Epoch [16/300], Validation Loss: 0.1925, Validation Accuracy: 0.9736\n",
      "Epoch [17/300], Training Loss: 0.1893\n",
      "Epoch [17/300], Validation Loss: 0.1788, Validation Accuracy: 0.9736\n",
      "Epoch [18/300], Training Loss: 0.1760\n",
      "Epoch [18/300], Validation Loss: 0.1667, Validation Accuracy: 0.9736\n",
      "Epoch [19/300], Training Loss: 0.1641\n",
      "Epoch [19/300], Validation Loss: 0.1558, Validation Accuracy: 0.9751\n",
      "Epoch [20/300], Training Loss: 0.1535\n",
      "Epoch [20/300], Validation Loss: 0.1461, Validation Accuracy: 0.9758\n",
      "Epoch [21/300], Training Loss: 0.1440\n",
      "Epoch [21/300], Validation Loss: 0.1374, Validation Accuracy: 0.9758\n",
      "Epoch [22/300], Training Loss: 0.1355\n",
      "Epoch [22/300], Validation Loss: 0.1295, Validation Accuracy: 0.9765\n",
      "Epoch [23/300], Training Loss: 0.1279\n",
      "Epoch [23/300], Validation Loss: 0.1225, Validation Accuracy: 0.9786\n",
      "Epoch [24/300], Training Loss: 0.1211\n",
      "Epoch [24/300], Validation Loss: 0.1161, Validation Accuracy: 0.9786\n",
      "Epoch [25/300], Training Loss: 0.1149\n",
      "Epoch [25/300], Validation Loss: 0.1104, Validation Accuracy: 0.9793\n",
      "Epoch [26/300], Training Loss: 0.1093\n",
      "Epoch [26/300], Validation Loss: 0.1052, Validation Accuracy: 0.9800\n",
      "Epoch [27/300], Training Loss: 0.1042\n",
      "Epoch [27/300], Validation Loss: 0.1005, Validation Accuracy: 0.9808\n",
      "Epoch [28/300], Training Loss: 0.0996\n",
      "Epoch [28/300], Validation Loss: 0.0961, Validation Accuracy: 0.9815\n",
      "Epoch [29/300], Training Loss: 0.0954\n",
      "Epoch [29/300], Validation Loss: 0.0922, Validation Accuracy: 0.9815\n",
      "Epoch [30/300], Training Loss: 0.0916\n",
      "Epoch [30/300], Validation Loss: 0.0886, Validation Accuracy: 0.9815\n",
      "Epoch [31/300], Training Loss: 0.0881\n",
      "Epoch [31/300], Validation Loss: 0.0853, Validation Accuracy: 0.9815\n",
      "Epoch [32/300], Training Loss: 0.0849\n",
      "Epoch [32/300], Validation Loss: 0.0822, Validation Accuracy: 0.9822\n",
      "Epoch [33/300], Training Loss: 0.0819\n",
      "Epoch [33/300], Validation Loss: 0.0794, Validation Accuracy: 0.9815\n",
      "Epoch [34/300], Training Loss: 0.0791\n",
      "Epoch [34/300], Validation Loss: 0.0768, Validation Accuracy: 0.9829\n",
      "Epoch [35/300], Training Loss: 0.0766\n",
      "Epoch [35/300], Validation Loss: 0.0744, Validation Accuracy: 0.9829\n",
      "Epoch [36/300], Training Loss: 0.0742\n",
      "Epoch [36/300], Validation Loss: 0.0721, Validation Accuracy: 0.9836\n",
      "Epoch [37/300], Training Loss: 0.0720\n",
      "Epoch [37/300], Validation Loss: 0.0700, Validation Accuracy: 0.9836\n",
      "Epoch [38/300], Training Loss: 0.0699\n",
      "Epoch [38/300], Validation Loss: 0.0680, Validation Accuracy: 0.9843\n",
      "Epoch [39/300], Training Loss: 0.0680\n",
      "Epoch [39/300], Validation Loss: 0.0662, Validation Accuracy: 0.9850\n",
      "Epoch [40/300], Training Loss: 0.0661\n",
      "Epoch [40/300], Validation Loss: 0.0645, Validation Accuracy: 0.9850\n",
      "Epoch [41/300], Training Loss: 0.0644\n",
      "Epoch [41/300], Validation Loss: 0.0628, Validation Accuracy: 0.9850\n",
      "Epoch [42/300], Training Loss: 0.0628\n",
      "Epoch [42/300], Validation Loss: 0.0613, Validation Accuracy: 0.9850\n",
      "Epoch [43/300], Training Loss: 0.0613\n",
      "Epoch [43/300], Validation Loss: 0.0599, Validation Accuracy: 0.9857\n",
      "Epoch [44/300], Training Loss: 0.0599\n",
      "Epoch [44/300], Validation Loss: 0.0585, Validation Accuracy: 0.9857\n",
      "Epoch [45/300], Training Loss: 0.0585\n",
      "Epoch [45/300], Validation Loss: 0.0572, Validation Accuracy: 0.9857\n",
      "Epoch [46/300], Training Loss: 0.0572\n",
      "Epoch [46/300], Validation Loss: 0.0560, Validation Accuracy: 0.9865\n",
      "Epoch [47/300], Training Loss: 0.0560\n",
      "Epoch [47/300], Validation Loss: 0.0548, Validation Accuracy: 0.9865\n",
      "Epoch [48/300], Training Loss: 0.0548\n",
      "Epoch [48/300], Validation Loss: 0.0537, Validation Accuracy: 0.9872\n",
      "Epoch [49/300], Training Loss: 0.0537\n",
      "Epoch [49/300], Validation Loss: 0.0526, Validation Accuracy: 0.9872\n",
      "Epoch [50/300], Training Loss: 0.0527\n",
      "Epoch [50/300], Validation Loss: 0.0516, Validation Accuracy: 0.9865\n",
      "Epoch [51/300], Training Loss: 0.0517\n",
      "Epoch [51/300], Validation Loss: 0.0506, Validation Accuracy: 0.9865\n",
      "Epoch [52/300], Training Loss: 0.0507\n",
      "Epoch [52/300], Validation Loss: 0.0497, Validation Accuracy: 0.9872\n",
      "Epoch [53/300], Training Loss: 0.0498\n",
      "Epoch [53/300], Validation Loss: 0.0488, Validation Accuracy: 0.9879\n",
      "Epoch [54/300], Training Loss: 0.0489\n",
      "Epoch [54/300], Validation Loss: 0.0480, Validation Accuracy: 0.9879\n",
      "Epoch [55/300], Training Loss: 0.0481\n",
      "Epoch [55/300], Validation Loss: 0.0472, Validation Accuracy: 0.9879\n",
      "Epoch [56/300], Training Loss: 0.0473\n",
      "Epoch [56/300], Validation Loss: 0.0464, Validation Accuracy: 0.9886\n",
      "Epoch [57/300], Training Loss: 0.0465\n",
      "Epoch [57/300], Validation Loss: 0.0456, Validation Accuracy: 0.9886\n",
      "Epoch [58/300], Training Loss: 0.0457\n",
      "Epoch [58/300], Validation Loss: 0.0449, Validation Accuracy: 0.9886\n",
      "Epoch [59/300], Training Loss: 0.0450\n",
      "Epoch [59/300], Validation Loss: 0.0442, Validation Accuracy: 0.9886\n",
      "Epoch [60/300], Training Loss: 0.0443\n",
      "Epoch [60/300], Validation Loss: 0.0435, Validation Accuracy: 0.9886\n",
      "Epoch [61/300], Training Loss: 0.0437\n",
      "Epoch [61/300], Validation Loss: 0.0428, Validation Accuracy: 0.9886\n",
      "Epoch [62/300], Training Loss: 0.0430\n",
      "Epoch [62/300], Validation Loss: 0.0422, Validation Accuracy: 0.9886\n",
      "Epoch [63/300], Training Loss: 0.0424\n",
      "Epoch [63/300], Validation Loss: 0.0415, Validation Accuracy: 0.9879\n",
      "Epoch [64/300], Training Loss: 0.0418\n",
      "Epoch [64/300], Validation Loss: 0.0409, Validation Accuracy: 0.9879\n",
      "Epoch [65/300], Training Loss: 0.0412\n",
      "Epoch [65/300], Validation Loss: 0.0404, Validation Accuracy: 0.9886\n",
      "Epoch [66/300], Training Loss: 0.0407\n",
      "Epoch [66/300], Validation Loss: 0.0398, Validation Accuracy: 0.9872\n",
      "Epoch [67/300], Training Loss: 0.0401\n",
      "Epoch [67/300], Validation Loss: 0.0392, Validation Accuracy: 0.9872\n",
      "Epoch [68/300], Training Loss: 0.0396\n",
      "Epoch [68/300], Validation Loss: 0.0387, Validation Accuracy: 0.9865\n",
      "Epoch [69/300], Training Loss: 0.0391\n",
      "Epoch [69/300], Validation Loss: 0.0382, Validation Accuracy: 0.9865\n",
      "Epoch [70/300], Training Loss: 0.0386\n",
      "Epoch [70/300], Validation Loss: 0.0377, Validation Accuracy: 0.9865\n",
      "Epoch [71/300], Training Loss: 0.0382\n",
      "Epoch [71/300], Validation Loss: 0.0372, Validation Accuracy: 0.9865\n",
      "Epoch [72/300], Training Loss: 0.0377\n",
      "Epoch [72/300], Validation Loss: 0.0367, Validation Accuracy: 0.9879\n",
      "Epoch [73/300], Training Loss: 0.0372\n",
      "Epoch [73/300], Validation Loss: 0.0362, Validation Accuracy: 0.9879\n",
      "Epoch [74/300], Training Loss: 0.0368\n",
      "Epoch [74/300], Validation Loss: 0.0358, Validation Accuracy: 0.9879\n",
      "Epoch [75/300], Training Loss: 0.0364\n",
      "Epoch [75/300], Validation Loss: 0.0353, Validation Accuracy: 0.9879\n",
      "Epoch [76/300], Training Loss: 0.0360\n",
      "Epoch [76/300], Validation Loss: 0.0349, Validation Accuracy: 0.9879\n",
      "Epoch [77/300], Training Loss: 0.0356\n",
      "Epoch [77/300], Validation Loss: 0.0344, Validation Accuracy: 0.9886\n",
      "Epoch [78/300], Training Loss: 0.0352\n",
      "Epoch [78/300], Validation Loss: 0.0340, Validation Accuracy: 0.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/300], Training Loss: 0.0348\n",
      "Epoch [79/300], Validation Loss: 0.0336, Validation Accuracy: 0.9879\n",
      "Epoch [80/300], Training Loss: 0.0344\n",
      "Epoch [80/300], Validation Loss: 0.0332, Validation Accuracy: 0.9879\n",
      "Epoch [81/300], Training Loss: 0.0341\n",
      "Epoch [81/300], Validation Loss: 0.0328, Validation Accuracy: 0.9879\n",
      "Epoch [82/300], Training Loss: 0.0337\n",
      "Epoch [82/300], Validation Loss: 0.0325, Validation Accuracy: 0.9879\n",
      "Epoch [83/300], Training Loss: 0.0334\n",
      "Epoch [83/300], Validation Loss: 0.0321, Validation Accuracy: 0.9879\n",
      "Epoch [84/300], Training Loss: 0.0331\n",
      "Epoch [84/300], Validation Loss: 0.0317, Validation Accuracy: 0.9879\n",
      "Epoch [85/300], Training Loss: 0.0327\n",
      "Epoch [85/300], Validation Loss: 0.0314, Validation Accuracy: 0.9886\n",
      "Epoch [86/300], Training Loss: 0.0324\n",
      "Epoch [86/300], Validation Loss: 0.0310, Validation Accuracy: 0.9886\n",
      "Epoch [87/300], Training Loss: 0.0321\n",
      "Epoch [87/300], Validation Loss: 0.0307, Validation Accuracy: 0.9886\n",
      "Epoch [88/300], Training Loss: 0.0318\n",
      "Epoch [88/300], Validation Loss: 0.0303, Validation Accuracy: 0.9886\n",
      "Epoch [89/300], Training Loss: 0.0315\n",
      "Epoch [89/300], Validation Loss: 0.0300, Validation Accuracy: 0.9886\n",
      "Epoch [90/300], Training Loss: 0.0312\n",
      "Epoch [90/300], Validation Loss: 0.0297, Validation Accuracy: 0.9893\n",
      "Epoch [91/300], Training Loss: 0.0309\n",
      "Epoch [91/300], Validation Loss: 0.0294, Validation Accuracy: 0.9893\n",
      "Epoch [92/300], Training Loss: 0.0306\n",
      "Epoch [92/300], Validation Loss: 0.0291, Validation Accuracy: 0.9893\n",
      "Epoch [93/300], Training Loss: 0.0304\n",
      "Epoch [93/300], Validation Loss: 0.0288, Validation Accuracy: 0.9893\n",
      "Epoch [94/300], Training Loss: 0.0301\n",
      "Epoch [94/300], Validation Loss: 0.0285, Validation Accuracy: 0.9893\n",
      "Epoch [95/300], Training Loss: 0.0298\n",
      "Epoch [95/300], Validation Loss: 0.0282, Validation Accuracy: 0.9893\n",
      "Epoch [96/300], Training Loss: 0.0296\n",
      "Epoch [96/300], Validation Loss: 0.0279, Validation Accuracy: 0.9893\n",
      "Epoch [97/300], Training Loss: 0.0293\n",
      "Epoch [97/300], Validation Loss: 0.0276, Validation Accuracy: 0.9893\n",
      "Epoch [98/300], Training Loss: 0.0291\n",
      "Epoch [98/300], Validation Loss: 0.0273, Validation Accuracy: 0.9893\n",
      "Epoch [99/300], Training Loss: 0.0288\n",
      "Epoch [99/300], Validation Loss: 0.0271, Validation Accuracy: 0.9893\n",
      "Epoch [100/300], Training Loss: 0.0286\n",
      "Epoch [100/300], Validation Loss: 0.0268, Validation Accuracy: 0.9893\n",
      "Epoch [101/300], Training Loss: 0.0284\n",
      "Epoch [101/300], Validation Loss: 0.0265, Validation Accuracy: 0.9893\n",
      "Epoch [102/300], Training Loss: 0.0281\n",
      "Epoch [102/300], Validation Loss: 0.0263, Validation Accuracy: 0.9893\n",
      "Epoch [103/300], Training Loss: 0.0279\n",
      "Epoch [103/300], Validation Loss: 0.0260, Validation Accuracy: 0.9893\n",
      "Epoch [104/300], Training Loss: 0.0277\n",
      "Epoch [104/300], Validation Loss: 0.0258, Validation Accuracy: 0.9893\n",
      "Epoch [105/300], Training Loss: 0.0275\n",
      "Epoch [105/300], Validation Loss: 0.0255, Validation Accuracy: 0.9893\n",
      "Epoch [106/300], Training Loss: 0.0272\n",
      "Epoch [106/300], Validation Loss: 0.0253, Validation Accuracy: 0.9900\n",
      "Epoch [107/300], Training Loss: 0.0270\n",
      "Epoch [107/300], Validation Loss: 0.0250, Validation Accuracy: 0.9900\n",
      "Epoch [108/300], Training Loss: 0.0268\n",
      "Epoch [108/300], Validation Loss: 0.0248, Validation Accuracy: 0.9900\n",
      "Epoch [109/300], Training Loss: 0.0266\n",
      "Epoch [109/300], Validation Loss: 0.0246, Validation Accuracy: 0.9900\n",
      "Epoch [110/300], Training Loss: 0.0264\n",
      "Epoch [110/300], Validation Loss: 0.0243, Validation Accuracy: 0.9900\n",
      "Epoch [111/300], Training Loss: 0.0262\n",
      "Epoch [111/300], Validation Loss: 0.0241, Validation Accuracy: 0.9907\n",
      "Epoch [112/300], Training Loss: 0.0260\n",
      "Epoch [112/300], Validation Loss: 0.0239, Validation Accuracy: 0.9907\n",
      "Epoch [113/300], Training Loss: 0.0258\n",
      "Epoch [113/300], Validation Loss: 0.0237, Validation Accuracy: 0.9907\n",
      "Epoch [114/300], Training Loss: 0.0256\n",
      "Epoch [114/300], Validation Loss: 0.0234, Validation Accuracy: 0.9907\n",
      "Epoch [115/300], Training Loss: 0.0254\n",
      "Epoch [115/300], Validation Loss: 0.0232, Validation Accuracy: 0.9914\n",
      "Epoch [116/300], Training Loss: 0.0252\n",
      "Epoch [116/300], Validation Loss: 0.0230, Validation Accuracy: 0.9914\n",
      "Epoch [117/300], Training Loss: 0.0251\n",
      "Epoch [117/300], Validation Loss: 0.0228, Validation Accuracy: 0.9914\n",
      "Epoch [118/300], Training Loss: 0.0249\n",
      "Epoch [118/300], Validation Loss: 0.0226, Validation Accuracy: 0.9914\n",
      "Epoch [119/300], Training Loss: 0.0247\n",
      "Epoch [119/300], Validation Loss: 0.0224, Validation Accuracy: 0.9914\n",
      "Epoch [120/300], Training Loss: 0.0245\n",
      "Epoch [120/300], Validation Loss: 0.0222, Validation Accuracy: 0.9914\n",
      "Epoch [121/300], Training Loss: 0.0243\n",
      "Epoch [121/300], Validation Loss: 0.0220, Validation Accuracy: 0.9914\n",
      "Epoch [122/300], Training Loss: 0.0242\n",
      "Epoch [122/300], Validation Loss: 0.0218, Validation Accuracy: 0.9922\n",
      "Epoch [123/300], Training Loss: 0.0240\n",
      "Epoch [123/300], Validation Loss: 0.0216, Validation Accuracy: 0.9922\n",
      "Epoch [124/300], Training Loss: 0.0238\n",
      "Epoch [124/300], Validation Loss: 0.0214, Validation Accuracy: 0.9922\n",
      "Epoch [125/300], Training Loss: 0.0236\n",
      "Epoch [125/300], Validation Loss: 0.0212, Validation Accuracy: 0.9922\n",
      "Epoch [126/300], Training Loss: 0.0235\n",
      "Epoch [126/300], Validation Loss: 0.0210, Validation Accuracy: 0.9922\n",
      "Epoch [127/300], Training Loss: 0.0233\n",
      "Epoch [127/300], Validation Loss: 0.0208, Validation Accuracy: 0.9922\n",
      "Epoch [128/300], Training Loss: 0.0232\n",
      "Epoch [128/300], Validation Loss: 0.0207, Validation Accuracy: 0.9922\n",
      "Epoch [129/300], Training Loss: 0.0230\n",
      "Epoch [129/300], Validation Loss: 0.0205, Validation Accuracy: 0.9929\n",
      "Epoch [130/300], Training Loss: 0.0228\n",
      "Epoch [130/300], Validation Loss: 0.0203, Validation Accuracy: 0.9929\n",
      "Epoch [131/300], Training Loss: 0.0227\n",
      "Epoch [131/300], Validation Loss: 0.0201, Validation Accuracy: 0.9929\n",
      "Epoch [132/300], Training Loss: 0.0225\n",
      "Epoch [132/300], Validation Loss: 0.0200, Validation Accuracy: 0.9929\n",
      "Epoch [133/300], Training Loss: 0.0224\n",
      "Epoch [133/300], Validation Loss: 0.0198, Validation Accuracy: 0.9936\n",
      "Epoch [134/300], Training Loss: 0.0222\n",
      "Epoch [134/300], Validation Loss: 0.0196, Validation Accuracy: 0.9936\n",
      "Epoch [135/300], Training Loss: 0.0221\n",
      "Epoch [135/300], Validation Loss: 0.0195, Validation Accuracy: 0.9936\n",
      "Epoch [136/300], Training Loss: 0.0219\n",
      "Epoch [136/300], Validation Loss: 0.0193, Validation Accuracy: 0.9936\n",
      "Epoch [137/300], Training Loss: 0.0218\n",
      "Epoch [137/300], Validation Loss: 0.0191, Validation Accuracy: 0.9943\n",
      "Epoch [138/300], Training Loss: 0.0216\n",
      "Epoch [138/300], Validation Loss: 0.0190, Validation Accuracy: 0.9943\n",
      "Epoch [139/300], Training Loss: 0.0215\n",
      "Epoch [139/300], Validation Loss: 0.0188, Validation Accuracy: 0.9943\n",
      "Epoch [140/300], Training Loss: 0.0214\n",
      "Epoch [140/300], Validation Loss: 0.0187, Validation Accuracy: 0.9943\n",
      "Epoch [141/300], Training Loss: 0.0212\n",
      "Epoch [141/300], Validation Loss: 0.0185, Validation Accuracy: 0.9943\n",
      "Epoch [142/300], Training Loss: 0.0211\n",
      "Epoch [142/300], Validation Loss: 0.0184, Validation Accuracy: 0.9943\n",
      "Epoch [143/300], Training Loss: 0.0209\n",
      "Epoch [143/300], Validation Loss: 0.0182, Validation Accuracy: 0.9943\n",
      "Epoch [144/300], Training Loss: 0.0208\n",
      "Epoch [144/300], Validation Loss: 0.0181, Validation Accuracy: 0.9957\n",
      "Epoch [145/300], Training Loss: 0.0207\n",
      "Epoch [145/300], Validation Loss: 0.0179, Validation Accuracy: 0.9957\n",
      "Epoch [146/300], Training Loss: 0.0205\n",
      "Epoch [146/300], Validation Loss: 0.0178, Validation Accuracy: 0.9957\n",
      "Epoch [147/300], Training Loss: 0.0204\n",
      "Epoch [147/300], Validation Loss: 0.0176, Validation Accuracy: 0.9957\n",
      "Epoch [148/300], Training Loss: 0.0203\n",
      "Epoch [148/300], Validation Loss: 0.0175, Validation Accuracy: 0.9957\n",
      "Epoch [149/300], Training Loss: 0.0202\n",
      "Epoch [149/300], Validation Loss: 0.0174, Validation Accuracy: 0.9964\n",
      "Epoch [150/300], Training Loss: 0.0200\n",
      "Epoch [150/300], Validation Loss: 0.0172, Validation Accuracy: 0.9964\n",
      "Epoch [151/300], Training Loss: 0.0199\n",
      "Epoch [151/300], Validation Loss: 0.0171, Validation Accuracy: 0.9964\n",
      "Epoch [152/300], Training Loss: 0.0198\n",
      "Epoch [152/300], Validation Loss: 0.0169, Validation Accuracy: 0.9964\n",
      "Epoch [153/300], Training Loss: 0.0197\n",
      "Epoch [153/300], Validation Loss: 0.0168, Validation Accuracy: 0.9964\n",
      "Epoch [154/300], Training Loss: 0.0195\n",
      "Epoch [154/300], Validation Loss: 0.0167, Validation Accuracy: 0.9964\n",
      "Epoch [155/300], Training Loss: 0.0194\n",
      "Epoch [155/300], Validation Loss: 0.0165, Validation Accuracy: 0.9964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [156/300], Training Loss: 0.0193\n",
      "Epoch [156/300], Validation Loss: 0.0164, Validation Accuracy: 0.9964\n",
      "Epoch [157/300], Training Loss: 0.0192\n",
      "Epoch [157/300], Validation Loss: 0.0163, Validation Accuracy: 0.9964\n",
      "Epoch [158/300], Training Loss: 0.0191\n",
      "Epoch [158/300], Validation Loss: 0.0162, Validation Accuracy: 0.9964\n",
      "Epoch [159/300], Training Loss: 0.0190\n",
      "Epoch [159/300], Validation Loss: 0.0160, Validation Accuracy: 0.9964\n",
      "Epoch [160/300], Training Loss: 0.0188\n",
      "Epoch [160/300], Validation Loss: 0.0159, Validation Accuracy: 0.9964\n",
      "Epoch [161/300], Training Loss: 0.0187\n",
      "Epoch [161/300], Validation Loss: 0.0158, Validation Accuracy: 0.9964\n",
      "Epoch [162/300], Training Loss: 0.0186\n",
      "Epoch [162/300], Validation Loss: 0.0157, Validation Accuracy: 0.9971\n",
      "Epoch [163/300], Training Loss: 0.0185\n",
      "Epoch [163/300], Validation Loss: 0.0156, Validation Accuracy: 0.9971\n",
      "Epoch [164/300], Training Loss: 0.0184\n",
      "Epoch [164/300], Validation Loss: 0.0154, Validation Accuracy: 0.9971\n",
      "Epoch [165/300], Training Loss: 0.0183\n",
      "Epoch [165/300], Validation Loss: 0.0153, Validation Accuracy: 0.9971\n",
      "Epoch [166/300], Training Loss: 0.0182\n",
      "Epoch [166/300], Validation Loss: 0.0152, Validation Accuracy: 0.9971\n",
      "Epoch [167/300], Training Loss: 0.0181\n",
      "Epoch [167/300], Validation Loss: 0.0151, Validation Accuracy: 0.9971\n",
      "Epoch [168/300], Training Loss: 0.0180\n",
      "Epoch [168/300], Validation Loss: 0.0150, Validation Accuracy: 0.9971\n",
      "Epoch [169/300], Training Loss: 0.0179\n",
      "Epoch [169/300], Validation Loss: 0.0149, Validation Accuracy: 0.9971\n",
      "Epoch [170/300], Training Loss: 0.0178\n",
      "Epoch [170/300], Validation Loss: 0.0148, Validation Accuracy: 0.9971\n",
      "Epoch [171/300], Training Loss: 0.0177\n",
      "Epoch [171/300], Validation Loss: 0.0147, Validation Accuracy: 0.9971\n",
      "Epoch [172/300], Training Loss: 0.0176\n",
      "Epoch [172/300], Validation Loss: 0.0146, Validation Accuracy: 0.9971\n",
      "Epoch [173/300], Training Loss: 0.0175\n",
      "Epoch [173/300], Validation Loss: 0.0145, Validation Accuracy: 0.9971\n",
      "Epoch [174/300], Training Loss: 0.0174\n",
      "Epoch [174/300], Validation Loss: 0.0143, Validation Accuracy: 0.9971\n",
      "Epoch [175/300], Training Loss: 0.0173\n",
      "Epoch [175/300], Validation Loss: 0.0142, Validation Accuracy: 0.9971\n",
      "Epoch [176/300], Training Loss: 0.0172\n",
      "Epoch [176/300], Validation Loss: 0.0141, Validation Accuracy: 0.9979\n",
      "Epoch [177/300], Training Loss: 0.0171\n",
      "Epoch [177/300], Validation Loss: 0.0140, Validation Accuracy: 0.9979\n",
      "Epoch [178/300], Training Loss: 0.0170\n",
      "Epoch [178/300], Validation Loss: 0.0139, Validation Accuracy: 0.9979\n",
      "Epoch [179/300], Training Loss: 0.0169\n",
      "Epoch [179/300], Validation Loss: 0.0138, Validation Accuracy: 0.9979\n",
      "Epoch [180/300], Training Loss: 0.0168\n",
      "Epoch [180/300], Validation Loss: 0.0137, Validation Accuracy: 0.9979\n",
      "Epoch [181/300], Training Loss: 0.0167\n",
      "Epoch [181/300], Validation Loss: 0.0137, Validation Accuracy: 0.9979\n",
      "Epoch [182/300], Training Loss: 0.0166\n",
      "Epoch [182/300], Validation Loss: 0.0136, Validation Accuracy: 0.9979\n",
      "Epoch [183/300], Training Loss: 0.0165\n",
      "Epoch [183/300], Validation Loss: 0.0135, Validation Accuracy: 0.9979\n",
      "Epoch [184/300], Training Loss: 0.0164\n",
      "Epoch [184/300], Validation Loss: 0.0134, Validation Accuracy: 0.9979\n",
      "Epoch [185/300], Training Loss: 0.0163\n",
      "Epoch [185/300], Validation Loss: 0.0133, Validation Accuracy: 0.9979\n",
      "Epoch [186/300], Training Loss: 0.0163\n",
      "Epoch [186/300], Validation Loss: 0.0132, Validation Accuracy: 0.9979\n",
      "Epoch [187/300], Training Loss: 0.0162\n",
      "Epoch [187/300], Validation Loss: 0.0131, Validation Accuracy: 0.9979\n",
      "Epoch [188/300], Training Loss: 0.0161\n",
      "Epoch [188/300], Validation Loss: 0.0130, Validation Accuracy: 0.9979\n",
      "Epoch [189/300], Training Loss: 0.0160\n",
      "Epoch [189/300], Validation Loss: 0.0129, Validation Accuracy: 0.9979\n",
      "Epoch [190/300], Training Loss: 0.0159\n",
      "Epoch [190/300], Validation Loss: 0.0128, Validation Accuracy: 0.9971\n",
      "Epoch [191/300], Training Loss: 0.0158\n",
      "Epoch [191/300], Validation Loss: 0.0127, Validation Accuracy: 0.9971\n",
      "Epoch [192/300], Training Loss: 0.0157\n",
      "Epoch [192/300], Validation Loss: 0.0127, Validation Accuracy: 0.9971\n",
      "Epoch [193/300], Training Loss: 0.0157\n",
      "Epoch [193/300], Validation Loss: 0.0126, Validation Accuracy: 0.9971\n",
      "Epoch [194/300], Training Loss: 0.0156\n",
      "Epoch [194/300], Validation Loss: 0.0125, Validation Accuracy: 0.9971\n",
      "Epoch [195/300], Training Loss: 0.0155\n",
      "Epoch [195/300], Validation Loss: 0.0124, Validation Accuracy: 0.9979\n",
      "Epoch [196/300], Training Loss: 0.0154\n",
      "Epoch [196/300], Validation Loss: 0.0123, Validation Accuracy: 0.9979\n",
      "Epoch [197/300], Training Loss: 0.0153\n",
      "Epoch [197/300], Validation Loss: 0.0122, Validation Accuracy: 0.9979\n",
      "Epoch [198/300], Training Loss: 0.0152\n",
      "Epoch [198/300], Validation Loss: 0.0122, Validation Accuracy: 0.9979\n",
      "Epoch [199/300], Training Loss: 0.0152\n",
      "Epoch [199/300], Validation Loss: 0.0121, Validation Accuracy: 0.9979\n",
      "Epoch [200/300], Training Loss: 0.0151\n",
      "Epoch [200/300], Validation Loss: 0.0120, Validation Accuracy: 0.9979\n",
      "Epoch [201/300], Training Loss: 0.0150\n",
      "Epoch [201/300], Validation Loss: 0.0119, Validation Accuracy: 0.9979\n",
      "Epoch [202/300], Training Loss: 0.0149\n",
      "Epoch [202/300], Validation Loss: 0.0119, Validation Accuracy: 0.9979\n",
      "Epoch [203/300], Training Loss: 0.0149\n",
      "Epoch [203/300], Validation Loss: 0.0118, Validation Accuracy: 0.9979\n",
      "Epoch [204/300], Training Loss: 0.0148\n",
      "Epoch [204/300], Validation Loss: 0.0117, Validation Accuracy: 0.9979\n",
      "Epoch [205/300], Training Loss: 0.0147\n",
      "Epoch [205/300], Validation Loss: 0.0116, Validation Accuracy: 0.9979\n",
      "Epoch [206/300], Training Loss: 0.0146\n",
      "Epoch [206/300], Validation Loss: 0.0116, Validation Accuracy: 0.9979\n",
      "Epoch [207/300], Training Loss: 0.0146\n",
      "Epoch [207/300], Validation Loss: 0.0115, Validation Accuracy: 0.9979\n",
      "Epoch [208/300], Training Loss: 0.0145\n",
      "Epoch [208/300], Validation Loss: 0.0114, Validation Accuracy: 0.9979\n",
      "Epoch [209/300], Training Loss: 0.0144\n",
      "Epoch [209/300], Validation Loss: 0.0113, Validation Accuracy: 0.9979\n",
      "Epoch [210/300], Training Loss: 0.0143\n",
      "Epoch [210/300], Validation Loss: 0.0113, Validation Accuracy: 0.9979\n",
      "Epoch [211/300], Training Loss: 0.0143\n",
      "Epoch [211/300], Validation Loss: 0.0112, Validation Accuracy: 0.9979\n",
      "Epoch [212/300], Training Loss: 0.0142\n",
      "Epoch [212/300], Validation Loss: 0.0111, Validation Accuracy: 0.9979\n",
      "Epoch [213/300], Training Loss: 0.0141\n",
      "Epoch [213/300], Validation Loss: 0.0111, Validation Accuracy: 0.9979\n",
      "Epoch [214/300], Training Loss: 0.0140\n",
      "Epoch [214/300], Validation Loss: 0.0110, Validation Accuracy: 0.9979\n",
      "Epoch [215/300], Training Loss: 0.0140\n",
      "Epoch [215/300], Validation Loss: 0.0109, Validation Accuracy: 0.9979\n",
      "Epoch [216/300], Training Loss: 0.0139\n",
      "Epoch [216/300], Validation Loss: 0.0109, Validation Accuracy: 0.9979\n",
      "Epoch [217/300], Training Loss: 0.0138\n",
      "Epoch [217/300], Validation Loss: 0.0108, Validation Accuracy: 0.9979\n",
      "Epoch [218/300], Training Loss: 0.0138\n",
      "Epoch [218/300], Validation Loss: 0.0107, Validation Accuracy: 0.9979\n",
      "Epoch [219/300], Training Loss: 0.0137\n",
      "Epoch [219/300], Validation Loss: 0.0107, Validation Accuracy: 0.9979\n",
      "Epoch [220/300], Training Loss: 0.0136\n",
      "Epoch [220/300], Validation Loss: 0.0106, Validation Accuracy: 0.9986\n",
      "Epoch [221/300], Training Loss: 0.0136\n",
      "Epoch [221/300], Validation Loss: 0.0105, Validation Accuracy: 0.9986\n",
      "Epoch [222/300], Training Loss: 0.0135\n",
      "Epoch [222/300], Validation Loss: 0.0105, Validation Accuracy: 0.9993\n",
      "Epoch [223/300], Training Loss: 0.0134\n",
      "Epoch [223/300], Validation Loss: 0.0104, Validation Accuracy: 0.9993\n",
      "Epoch [224/300], Training Loss: 0.0134\n",
      "Epoch [224/300], Validation Loss: 0.0104, Validation Accuracy: 0.9993\n",
      "Epoch [225/300], Training Loss: 0.0133\n",
      "Epoch [225/300], Validation Loss: 0.0103, Validation Accuracy: 0.9993\n",
      "Epoch [226/300], Training Loss: 0.0132\n",
      "Epoch [226/300], Validation Loss: 0.0102, Validation Accuracy: 0.9993\n",
      "Epoch [227/300], Training Loss: 0.0132\n",
      "Epoch [227/300], Validation Loss: 0.0102, Validation Accuracy: 0.9993\n",
      "Epoch [228/300], Training Loss: 0.0131\n",
      "Epoch [228/300], Validation Loss: 0.0101, Validation Accuracy: 0.9993\n",
      "Epoch [229/300], Training Loss: 0.0131\n",
      "Epoch [229/300], Validation Loss: 0.0101, Validation Accuracy: 0.9993\n",
      "Epoch [230/300], Training Loss: 0.0130\n",
      "Epoch [230/300], Validation Loss: 0.0100, Validation Accuracy: 0.9993\n",
      "Epoch [231/300], Training Loss: 0.0129\n",
      "Epoch [231/300], Validation Loss: 0.0099, Validation Accuracy: 0.9993\n",
      "Epoch [232/300], Training Loss: 0.0129\n",
      "Epoch [232/300], Validation Loss: 0.0099, Validation Accuracy: 0.9993\n",
      "Epoch [233/300], Training Loss: 0.0128\n",
      "Epoch [233/300], Validation Loss: 0.0098, Validation Accuracy: 0.9993\n",
      "Epoch [234/300], Training Loss: 0.0127\n",
      "Epoch [234/300], Validation Loss: 0.0098, Validation Accuracy: 0.9993\n",
      "Epoch [235/300], Training Loss: 0.0127\n",
      "Epoch [235/300], Validation Loss: 0.0097, Validation Accuracy: 0.9993\n",
      "Epoch [236/300], Training Loss: 0.0126\n",
      "Epoch [236/300], Validation Loss: 0.0097, Validation Accuracy: 0.9993\n",
      "Epoch [237/300], Training Loss: 0.0126\n",
      "Epoch [237/300], Validation Loss: 0.0096, Validation Accuracy: 0.9993\n",
      "Epoch [238/300], Training Loss: 0.0125\n",
      "Epoch [238/300], Validation Loss: 0.0096, Validation Accuracy: 0.9993\n",
      "Epoch [239/300], Training Loss: 0.0124\n",
      "Epoch [239/300], Validation Loss: 0.0095, Validation Accuracy: 0.9993\n",
      "Epoch [240/300], Training Loss: 0.0124\n",
      "Epoch [240/300], Validation Loss: 0.0095, Validation Accuracy: 0.9993\n",
      "Epoch [241/300], Training Loss: 0.0123\n",
      "Epoch [241/300], Validation Loss: 0.0094, Validation Accuracy: 0.9993\n",
      "Epoch [242/300], Training Loss: 0.0123\n",
      "Epoch [242/300], Validation Loss: 0.0094, Validation Accuracy: 0.9993\n",
      "Epoch [243/300], Training Loss: 0.0122\n",
      "Epoch [243/300], Validation Loss: 0.0093, Validation Accuracy: 0.9993\n",
      "Epoch [244/300], Training Loss: 0.0122\n",
      "Epoch [244/300], Validation Loss: 0.0093, Validation Accuracy: 0.9993\n",
      "Epoch [245/300], Training Loss: 0.0121\n",
      "Epoch [245/300], Validation Loss: 0.0092, Validation Accuracy: 0.9993\n",
      "Epoch [246/300], Training Loss: 0.0121\n",
      "Epoch [246/300], Validation Loss: 0.0092, Validation Accuracy: 0.9993\n",
      "Epoch [247/300], Training Loss: 0.0120\n",
      "Epoch [247/300], Validation Loss: 0.0091, Validation Accuracy: 0.9993\n",
      "Epoch [248/300], Training Loss: 0.0119\n",
      "Epoch [248/300], Validation Loss: 0.0091, Validation Accuracy: 0.9993\n",
      "Epoch [249/300], Training Loss: 0.0119\n",
      "Epoch [249/300], Validation Loss: 0.0090, Validation Accuracy: 0.9993\n",
      "Epoch [250/300], Training Loss: 0.0118\n",
      "Epoch [250/300], Validation Loss: 0.0090, Validation Accuracy: 0.9993\n",
      "Epoch [251/300], Training Loss: 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [251/300], Validation Loss: 0.0089, Validation Accuracy: 0.9993\n",
      "Epoch [252/300], Training Loss: 0.0117\n",
      "Epoch [252/300], Validation Loss: 0.0089, Validation Accuracy: 0.9993\n",
      "Epoch [253/300], Training Loss: 0.0117\n",
      "Epoch [253/300], Validation Loss: 0.0088, Validation Accuracy: 0.9993\n",
      "Epoch [254/300], Training Loss: 0.0116\n",
      "Epoch [254/300], Validation Loss: 0.0088, Validation Accuracy: 0.9993\n",
      "Epoch [255/300], Training Loss: 0.0116\n",
      "Epoch [255/300], Validation Loss: 0.0087, Validation Accuracy: 0.9993\n",
      "Epoch [256/300], Training Loss: 0.0115\n",
      "Epoch [256/300], Validation Loss: 0.0087, Validation Accuracy: 0.9993\n",
      "Epoch [257/300], Training Loss: 0.0115\n",
      "Epoch [257/300], Validation Loss: 0.0086, Validation Accuracy: 0.9993\n",
      "Epoch [258/300], Training Loss: 0.0114\n",
      "Epoch [258/300], Validation Loss: 0.0086, Validation Accuracy: 0.9993\n",
      "Epoch [259/300], Training Loss: 0.0114\n",
      "Epoch [259/300], Validation Loss: 0.0085, Validation Accuracy: 0.9993\n",
      "Epoch [260/300], Training Loss: 0.0113\n",
      "Epoch [260/300], Validation Loss: 0.0085, Validation Accuracy: 0.9993\n",
      "Epoch [261/300], Training Loss: 0.0113\n",
      "Epoch [261/300], Validation Loss: 0.0085, Validation Accuracy: 0.9993\n",
      "Epoch [262/300], Training Loss: 0.0112\n",
      "Epoch [262/300], Validation Loss: 0.0084, Validation Accuracy: 0.9993\n",
      "Epoch [263/300], Training Loss: 0.0112\n",
      "Epoch [263/300], Validation Loss: 0.0084, Validation Accuracy: 0.9993\n",
      "Epoch [264/300], Training Loss: 0.0111\n",
      "Epoch [264/300], Validation Loss: 0.0083, Validation Accuracy: 0.9993\n",
      "Epoch [265/300], Training Loss: 0.0111\n",
      "Epoch [265/300], Validation Loss: 0.0083, Validation Accuracy: 0.9993\n",
      "Epoch [266/300], Training Loss: 0.0110\n",
      "Epoch [266/300], Validation Loss: 0.0082, Validation Accuracy: 0.9993\n",
      "Epoch [267/300], Training Loss: 0.0110\n",
      "Epoch [267/300], Validation Loss: 0.0082, Validation Accuracy: 0.9993\n",
      "Epoch [268/300], Training Loss: 0.0109\n",
      "Epoch [268/300], Validation Loss: 0.0082, Validation Accuracy: 0.9993\n",
      "Epoch [269/300], Training Loss: 0.0109\n",
      "Epoch [269/300], Validation Loss: 0.0081, Validation Accuracy: 0.9993\n",
      "Epoch [270/300], Training Loss: 0.0108\n",
      "Epoch [270/300], Validation Loss: 0.0081, Validation Accuracy: 0.9993\n",
      "Epoch [271/300], Training Loss: 0.0108\n",
      "Epoch [271/300], Validation Loss: 0.0080, Validation Accuracy: 0.9993\n",
      "Epoch [272/300], Training Loss: 0.0107\n",
      "Epoch [272/300], Validation Loss: 0.0080, Validation Accuracy: 0.9993\n",
      "Epoch [273/300], Training Loss: 0.0107\n",
      "Epoch [273/300], Validation Loss: 0.0080, Validation Accuracy: 0.9993\n",
      "Epoch [274/300], Training Loss: 0.0106\n",
      "Epoch [274/300], Validation Loss: 0.0079, Validation Accuracy: 0.9993\n",
      "Epoch [275/300], Training Loss: 0.0106\n",
      "Epoch [275/300], Validation Loss: 0.0079, Validation Accuracy: 0.9993\n",
      "Epoch [276/300], Training Loss: 0.0105\n",
      "Epoch [276/300], Validation Loss: 0.0078, Validation Accuracy: 0.9993\n",
      "Epoch [277/300], Training Loss: 0.0105\n",
      "Epoch [277/300], Validation Loss: 0.0078, Validation Accuracy: 0.9993\n",
      "Epoch [278/300], Training Loss: 0.0104\n",
      "Epoch [278/300], Validation Loss: 0.0078, Validation Accuracy: 0.9993\n",
      "Epoch [279/300], Training Loss: 0.0104\n",
      "Epoch [279/300], Validation Loss: 0.0077, Validation Accuracy: 0.9993\n",
      "Epoch [280/300], Training Loss: 0.0104\n",
      "Epoch [280/300], Validation Loss: 0.0077, Validation Accuracy: 0.9993\n",
      "Epoch [281/300], Training Loss: 0.0103\n",
      "Epoch [281/300], Validation Loss: 0.0076, Validation Accuracy: 0.9993\n",
      "Epoch [282/300], Training Loss: 0.0103\n",
      "Epoch [282/300], Validation Loss: 0.0076, Validation Accuracy: 0.9993\n",
      "Epoch [283/300], Training Loss: 0.0102\n",
      "Epoch [283/300], Validation Loss: 0.0076, Validation Accuracy: 0.9993\n",
      "Epoch [284/300], Training Loss: 0.0102\n",
      "Epoch [284/300], Validation Loss: 0.0075, Validation Accuracy: 0.9993\n",
      "Epoch [285/300], Training Loss: 0.0101\n",
      "Epoch [285/300], Validation Loss: 0.0075, Validation Accuracy: 0.9993\n",
      "Epoch [286/300], Training Loss: 0.0101\n",
      "Epoch [286/300], Validation Loss: 0.0075, Validation Accuracy: 0.9993\n",
      "Epoch [287/300], Training Loss: 0.0100\n",
      "Epoch [287/300], Validation Loss: 0.0074, Validation Accuracy: 0.9993\n",
      "Epoch [288/300], Training Loss: 0.0100\n",
      "Epoch [288/300], Validation Loss: 0.0074, Validation Accuracy: 0.9993\n",
      "Epoch [289/300], Training Loss: 0.0100\n",
      "Epoch [289/300], Validation Loss: 0.0074, Validation Accuracy: 0.9993\n",
      "Epoch [290/300], Training Loss: 0.0099\n",
      "Epoch [290/300], Validation Loss: 0.0073, Validation Accuracy: 0.9993\n",
      "Epoch [291/300], Training Loss: 0.0099\n",
      "Epoch [291/300], Validation Loss: 0.0073, Validation Accuracy: 0.9993\n",
      "Epoch [292/300], Training Loss: 0.0098\n",
      "Epoch [292/300], Validation Loss: 0.0073, Validation Accuracy: 0.9993\n",
      "Epoch [293/300], Training Loss: 0.0098\n",
      "Epoch [293/300], Validation Loss: 0.0072, Validation Accuracy: 0.9993\n",
      "Epoch [294/300], Training Loss: 0.0097\n",
      "Epoch [294/300], Validation Loss: 0.0072, Validation Accuracy: 0.9993\n",
      "Epoch [295/300], Training Loss: 0.0097\n",
      "Epoch [295/300], Validation Loss: 0.0072, Validation Accuracy: 0.9993\n",
      "Epoch [296/300], Training Loss: 0.0097\n",
      "Epoch [296/300], Validation Loss: 0.0071, Validation Accuracy: 0.9993\n",
      "Epoch [297/300], Training Loss: 0.0096\n",
      "Epoch [297/300], Validation Loss: 0.0071, Validation Accuracy: 0.9993\n",
      "Epoch [298/300], Training Loss: 0.0096\n",
      "Epoch [298/300], Validation Loss: 0.0071, Validation Accuracy: 0.9993\n",
      "Epoch [299/300], Training Loss: 0.0095\n",
      "Epoch [299/300], Validation Loss: 0.0070, Validation Accuracy: 0.9993\n",
      "Epoch [300/300], Training Loss: 0.0095\n",
      "Epoch [300/300], Validation Loss: 0.0070, Validation Accuracy: 0.9993\n",
      "Test Accuracy: 0.9971489665003563\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have already loaded your features_df\n",
    "\n",
    "# Extract the MFCC features and corresponding labels\n",
    "X = features_df.iloc[:, :-1].values  # Assuming MFCC features are in columns 1 to n\n",
    "y = features_df.iloc[:, -1].values  # Assuming labels are in the first column\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the labels\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64  # You can adjust this as needed\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 300  # You can adjust this as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    outputs = model(X_train_tensor.unsqueeze(1))  # Add an extra dimension for sequence length\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs.squeeze(), y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor.unsqueeze(1))\n",
    "        val_loss = criterion(val_outputs.squeeze(), y_val)\n",
    "        _, val_predicted = torch.max(val_outputs, 1)\n",
    "        val_accuracy = accuracy_score(y_val.numpy(), val_predicted.numpy())\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss.item():.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor.unsqueeze(1))\n",
    "    _, test_predicted = torch.max(test_outputs, 1)\n",
    "    test_accuracy = accuracy_score(y_test.numpy(), test_predicted.numpy())\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1039df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pytorch_model_new.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained SVM model to a file\n",
    "joblib.dump(model, 'pytorch_model_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e914e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in something directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "\n",
    "        # MFCC (Mel-frequency cepstral coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "        # Chroma feature\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral contrast\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral centroid\n",
    "        spectral_centroids = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Zero-crossing rate\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio).T, axis=0)\n",
    "\n",
    "        # Spectral rolloff\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Combine all features into a 1D array\n",
    "        features = np.hstack([mfccs_processed, chroma_stft, spectral_contrast, spectral_centroids, zero_crossing_rate, spectral_rolloff])\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_name}\")\n",
    "        return None\n",
    "\n",
    "# Specify the directories containing the .mp3 files\n",
    "directories = ['something']\n",
    "\n",
    "# Create an empty DataFrame to store the features\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "for directory in directories:\n",
    "    print(f\"Processing files in {directory} directory\")\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                features = extract_features(file_path)\n",
    "                # Append the features to the DataFrame as a new row\n",
    "                if features is not None:\n",
    "                    features_series = pd.Series(features)\n",
    "                    features_df = pd.concat([features_df, features_series], axis=0)  # Concatenate along rows (axis=0)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered while processing file: {file_path}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "# Rename the DataFrame columns as needed\n",
    "# features_df.columns = [list_of_feature_names]\n",
    "\n",
    "# Now, you have the features in the 'features_df' DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6060a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-204.075348</td>\n",
       "      <td>98.238022</td>\n",
       "      <td>-22.208324</td>\n",
       "      <td>31.998226</td>\n",
       "      <td>-8.63063</td>\n",
       "      <td>18.084925</td>\n",
       "      <td>-6.083037</td>\n",
       "      <td>10.879937</td>\n",
       "      <td>-8.298679</td>\n",
       "      <td>11.969007</td>\n",
       "      <td>...</td>\n",
       "      <td>21.219985</td>\n",
       "      <td>14.533117</td>\n",
       "      <td>16.203547</td>\n",
       "      <td>15.333577</td>\n",
       "      <td>16.834598</td>\n",
       "      <td>17.268652</td>\n",
       "      <td>40.600173</td>\n",
       "      <td>2210.834018</td>\n",
       "      <td>0.091058</td>\n",
       "      <td>4664.645053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3        4          5         6   \\\n",
       "0 -204.075348  98.238022 -22.208324  31.998226 -8.63063  18.084925 -6.083037   \n",
       "\n",
       "          7         8          9   ...         52         53         54  \\\n",
       "0  10.879937 -8.298679  11.969007  ...  21.219985  14.533117  16.203547   \n",
       "\n",
       "          55         56         57         58           59        60  \\\n",
       "0  15.333577  16.834598  17.268652  40.600173  2210.834018  0.091058   \n",
       "\n",
       "            61  \n",
       "0  4664.645053  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new= features_df.T\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c2a1bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model architecture first\n",
    "loaded_model = RNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Load the trained weights\n",
    "loaded_model.load_state_dict(torch.load('rnn_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4548d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Assuming you have new data in X_new (make sure to preprocess it the same way as the training data)\n",
    "X_new = scaler.transform(X_new)  # Standardize the new data\n",
    "X_new_tensor = torch.tensor(X_new, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    new_outputs = loaded_model(X_new_tensor.unsqueeze(1))\n",
    "    _, new_predicted = torch.max(new_outputs, 1)\n",
    "\n",
    "# 'new_predicted' now contains the predicted class labels for your new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86a91ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "print(new_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae66a59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in something1 directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▍                                          | 1/30 [00:02<01:06,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while processing file: something1/Attorney in Fort Hood Murder Case Slams Army's Investigation [C-H0-Z-m7lQ].wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▉                                         | 2/30 [00:04<01:01,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while processing file: something1/Allied Nations Celebrate 75th Anniversary of VE Day [PnNyfj6AOh4].wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▍                                       | 3/30 [00:06<00:52,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while processing file: something1/Bonus Footage of Kilmeade's Exclusive White House Tour [ybhKTd4tkok].wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████▊                                      | 4/30 [00:08<00:52,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while processing file: something1/Army Christmas Special Featured on Fox Nation [8HnIlPSMKD4].wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████▎                                    | 5/30 [00:10<00:51,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while processing file: something1/Abby Hornacek practices social distancing out in nature [-mTeqItwbWE].wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 6/30 [00:14<01:05,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered while processing file: something1/Beth Moore shares wisdom from the Book of John [_09-qTCXunk].wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 6/30 [00:15<01:03,  2.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Append the features to the DataFrame as a new row\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(file_name):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m         audio, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkaiser_fast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# MFCC (Mel-frequency cepstral coefficients)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         mfccs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39maudio, sr\u001b[38;5;241m=\u001b[39msample_rate, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    180\u001b[0m     y \u001b[38;5;241m=\u001b[39m to_mono(y)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     sr \u001b[38;5;241m=\u001b[39m sr_native\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:617\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m soxr\u001b[38;5;241m.\u001b[39mresample(y\u001b[38;5;241m.\u001b[39mT, orig_sr, target_sr, quality\u001b[38;5;241m=\u001b[39mres_type)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 617\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mresampy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fix:\n\u001b[1;32m    620\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mfix_length(y_hat, size\u001b[38;5;241m=\u001b[39mn_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/resampy/core.py:168\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         resample_f_s(\n\u001b[1;32m    159\u001b[0m             x\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis),\n\u001b[1;32m    160\u001b[0m             t_out,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m             y\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, axis),\n\u001b[1;32m    166\u001b[0m         )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[43mresample_f_s\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterp_win\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterp_delta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numba/np/ufunc/gufunc.py:192\u001b[0m, in \u001b[0;36mGUFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(sig)\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_ufunc()\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "\n",
    "        # MFCC (Mel-frequency cepstral coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "        # Chroma feature\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral contrast\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral centroid\n",
    "        spectral_centroids = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Zero-crossing rate\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio).T, axis=0)\n",
    "\n",
    "        # Spectral rolloff\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Combine all features into a 1D array\n",
    "        features = np.hstack([mfccs_processed, chroma_stft, spectral_contrast, spectral_centroids, zero_crossing_rate, spectral_rolloff])\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_name}\")\n",
    "        return None\n",
    "\n",
    "# Specify the directories containing the .mp3 files\n",
    "directories = ['something1']\n",
    "\n",
    "# Create an empty DataFrame to store the features\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "for directory in directories:\n",
    "    print(f\"Processing files in {directory} directory\")\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                features = extract_features(file_path)\n",
    "                # Append the features to the DataFrame as a new row\n",
    "                if features is not None:\n",
    "                    features_df = features_df.concat(pd.Series(features), ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered while processing file: {file_path}\")\n",
    "                continue\n",
    "\n",
    "# Rename the DataFrame columns as needed\n",
    "# features_df.columns = [list_of_feature_names]\n",
    "\n",
    "# Now, you have the features in the 'features_df' DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224610d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
