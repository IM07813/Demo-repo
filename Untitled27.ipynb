{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cbbe5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Training Loss: 0.6664\n",
      "Epoch [1/300], Validation Loss: 0.5877, Validation Accuracy: 0.7377\n",
      "Epoch [2/300], Training Loss: 0.5916\n",
      "Epoch [2/300], Validation Loss: 0.5218, Validation Accuracy: 0.8147\n",
      "Epoch [3/300], Training Loss: 0.5246\n",
      "Epoch [3/300], Validation Loss: 0.4633, Validation Accuracy: 0.8803\n",
      "Epoch [4/300], Training Loss: 0.4651\n",
      "Epoch [4/300], Validation Loss: 0.4117, Validation Accuracy: 0.9202\n",
      "Epoch [5/300], Training Loss: 0.4128\n",
      "Epoch [5/300], Validation Loss: 0.3666, Validation Accuracy: 0.9487\n",
      "Epoch [6/300], Training Loss: 0.3670\n",
      "Epoch [6/300], Validation Loss: 0.3273, Validation Accuracy: 0.9587\n",
      "Epoch [7/300], Training Loss: 0.3272\n",
      "Epoch [7/300], Validation Loss: 0.2933, Validation Accuracy: 0.9629\n",
      "Epoch [8/300], Training Loss: 0.2927\n",
      "Epoch [8/300], Validation Loss: 0.2638, Validation Accuracy: 0.9672\n",
      "Epoch [9/300], Training Loss: 0.2630\n",
      "Epoch [9/300], Validation Loss: 0.2383, Validation Accuracy: 0.9694\n",
      "Epoch [10/300], Training Loss: 0.2373\n",
      "Epoch [10/300], Validation Loss: 0.2163, Validation Accuracy: 0.9729\n",
      "Epoch [11/300], Training Loss: 0.2152\n",
      "Epoch [11/300], Validation Loss: 0.1973, Validation Accuracy: 0.9751\n",
      "Epoch [12/300], Training Loss: 0.1961\n",
      "Epoch [12/300], Validation Loss: 0.1809, Validation Accuracy: 0.9758\n",
      "Epoch [13/300], Training Loss: 0.1796\n",
      "Epoch [13/300], Validation Loss: 0.1666, Validation Accuracy: 0.9758\n",
      "Epoch [14/300], Training Loss: 0.1654\n",
      "Epoch [14/300], Validation Loss: 0.1541, Validation Accuracy: 0.9772\n",
      "Epoch [15/300], Training Loss: 0.1530\n",
      "Epoch [15/300], Validation Loss: 0.1433, Validation Accuracy: 0.9786\n",
      "Epoch [16/300], Training Loss: 0.1421\n",
      "Epoch [16/300], Validation Loss: 0.1338, Validation Accuracy: 0.9793\n",
      "Epoch [17/300], Training Loss: 0.1327\n",
      "Epoch [17/300], Validation Loss: 0.1254, Validation Accuracy: 0.9793\n",
      "Epoch [18/300], Training Loss: 0.1243\n",
      "Epoch [18/300], Validation Loss: 0.1180, Validation Accuracy: 0.9800\n",
      "Epoch [19/300], Training Loss: 0.1170\n",
      "Epoch [19/300], Validation Loss: 0.1114, Validation Accuracy: 0.9800\n",
      "Epoch [20/300], Training Loss: 0.1105\n",
      "Epoch [20/300], Validation Loss: 0.1055, Validation Accuracy: 0.9808\n",
      "Epoch [21/300], Training Loss: 0.1047\n",
      "Epoch [21/300], Validation Loss: 0.1003, Validation Accuracy: 0.9808\n",
      "Epoch [22/300], Training Loss: 0.0995\n",
      "Epoch [22/300], Validation Loss: 0.0956, Validation Accuracy: 0.9822\n",
      "Epoch [23/300], Training Loss: 0.0948\n",
      "Epoch [23/300], Validation Loss: 0.0913, Validation Accuracy: 0.9822\n",
      "Epoch [24/300], Training Loss: 0.0906\n",
      "Epoch [24/300], Validation Loss: 0.0874, Validation Accuracy: 0.9822\n",
      "Epoch [25/300], Training Loss: 0.0867\n",
      "Epoch [25/300], Validation Loss: 0.0839, Validation Accuracy: 0.9822\n",
      "Epoch [26/300], Training Loss: 0.0832\n",
      "Epoch [26/300], Validation Loss: 0.0807, Validation Accuracy: 0.9822\n",
      "Epoch [27/300], Training Loss: 0.0800\n",
      "Epoch [27/300], Validation Loss: 0.0777, Validation Accuracy: 0.9822\n",
      "Epoch [28/300], Training Loss: 0.0771\n",
      "Epoch [28/300], Validation Loss: 0.0750, Validation Accuracy: 0.9829\n",
      "Epoch [29/300], Training Loss: 0.0744\n",
      "Epoch [29/300], Validation Loss: 0.0724, Validation Accuracy: 0.9829\n",
      "Epoch [30/300], Training Loss: 0.0719\n",
      "Epoch [30/300], Validation Loss: 0.0701, Validation Accuracy: 0.9829\n",
      "Epoch [31/300], Training Loss: 0.0695\n",
      "Epoch [31/300], Validation Loss: 0.0679, Validation Accuracy: 0.9836\n",
      "Epoch [32/300], Training Loss: 0.0674\n",
      "Epoch [32/300], Validation Loss: 0.0659, Validation Accuracy: 0.9850\n",
      "Epoch [33/300], Training Loss: 0.0653\n",
      "Epoch [33/300], Validation Loss: 0.0640, Validation Accuracy: 0.9850\n",
      "Epoch [34/300], Training Loss: 0.0634\n",
      "Epoch [34/300], Validation Loss: 0.0622, Validation Accuracy: 0.9850\n",
      "Epoch [35/300], Training Loss: 0.0617\n",
      "Epoch [35/300], Validation Loss: 0.0605, Validation Accuracy: 0.9857\n",
      "Epoch [36/300], Training Loss: 0.0600\n",
      "Epoch [36/300], Validation Loss: 0.0589, Validation Accuracy: 0.9857\n",
      "Epoch [37/300], Training Loss: 0.0584\n",
      "Epoch [37/300], Validation Loss: 0.0574, Validation Accuracy: 0.9857\n",
      "Epoch [38/300], Training Loss: 0.0569\n",
      "Epoch [38/300], Validation Loss: 0.0560, Validation Accuracy: 0.9865\n",
      "Epoch [39/300], Training Loss: 0.0555\n",
      "Epoch [39/300], Validation Loss: 0.0546, Validation Accuracy: 0.9865\n",
      "Epoch [40/300], Training Loss: 0.0542\n",
      "Epoch [40/300], Validation Loss: 0.0533, Validation Accuracy: 0.9865\n",
      "Epoch [41/300], Training Loss: 0.0529\n",
      "Epoch [41/300], Validation Loss: 0.0521, Validation Accuracy: 0.9865\n",
      "Epoch [42/300], Training Loss: 0.0517\n",
      "Epoch [42/300], Validation Loss: 0.0509, Validation Accuracy: 0.9865\n",
      "Epoch [43/300], Training Loss: 0.0506\n",
      "Epoch [43/300], Validation Loss: 0.0498, Validation Accuracy: 0.9872\n",
      "Epoch [44/300], Training Loss: 0.0495\n",
      "Epoch [44/300], Validation Loss: 0.0488, Validation Accuracy: 0.9872\n",
      "Epoch [45/300], Training Loss: 0.0485\n",
      "Epoch [45/300], Validation Loss: 0.0477, Validation Accuracy: 0.9872\n",
      "Epoch [46/300], Training Loss: 0.0475\n",
      "Epoch [46/300], Validation Loss: 0.0468, Validation Accuracy: 0.9865\n",
      "Epoch [47/300], Training Loss: 0.0466\n",
      "Epoch [47/300], Validation Loss: 0.0458, Validation Accuracy: 0.9857\n",
      "Epoch [48/300], Training Loss: 0.0457\n",
      "Epoch [48/300], Validation Loss: 0.0449, Validation Accuracy: 0.9857\n",
      "Epoch [49/300], Training Loss: 0.0448\n",
      "Epoch [49/300], Validation Loss: 0.0440, Validation Accuracy: 0.9857\n",
      "Epoch [50/300], Training Loss: 0.0440\n",
      "Epoch [50/300], Validation Loss: 0.0432, Validation Accuracy: 0.9850\n",
      "Epoch [51/300], Training Loss: 0.0432\n",
      "Epoch [51/300], Validation Loss: 0.0424, Validation Accuracy: 0.9857\n",
      "Epoch [52/300], Training Loss: 0.0424\n",
      "Epoch [52/300], Validation Loss: 0.0416, Validation Accuracy: 0.9872\n",
      "Epoch [53/300], Training Loss: 0.0417\n",
      "Epoch [53/300], Validation Loss: 0.0409, Validation Accuracy: 0.9872\n",
      "Epoch [54/300], Training Loss: 0.0410\n",
      "Epoch [54/300], Validation Loss: 0.0402, Validation Accuracy: 0.9872\n",
      "Epoch [55/300], Training Loss: 0.0403\n",
      "Epoch [55/300], Validation Loss: 0.0395, Validation Accuracy: 0.9872\n",
      "Epoch [56/300], Training Loss: 0.0397\n",
      "Epoch [56/300], Validation Loss: 0.0388, Validation Accuracy: 0.9879\n",
      "Epoch [57/300], Training Loss: 0.0390\n",
      "Epoch [57/300], Validation Loss: 0.0382, Validation Accuracy: 0.9872\n",
      "Epoch [58/300], Training Loss: 0.0384\n",
      "Epoch [58/300], Validation Loss: 0.0375, Validation Accuracy: 0.9886\n",
      "Epoch [59/300], Training Loss: 0.0379\n",
      "Epoch [59/300], Validation Loss: 0.0369, Validation Accuracy: 0.9886\n",
      "Epoch [60/300], Training Loss: 0.0373\n",
      "Epoch [60/300], Validation Loss: 0.0364, Validation Accuracy: 0.9893\n",
      "Epoch [61/300], Training Loss: 0.0368\n",
      "Epoch [61/300], Validation Loss: 0.0358, Validation Accuracy: 0.9893\n",
      "Epoch [62/300], Training Loss: 0.0363\n",
      "Epoch [62/300], Validation Loss: 0.0353, Validation Accuracy: 0.9893\n",
      "Epoch [63/300], Training Loss: 0.0358\n",
      "Epoch [63/300], Validation Loss: 0.0347, Validation Accuracy: 0.9893\n",
      "Epoch [64/300], Training Loss: 0.0353\n",
      "Epoch [64/300], Validation Loss: 0.0342, Validation Accuracy: 0.9900\n",
      "Epoch [65/300], Training Loss: 0.0348\n",
      "Epoch [65/300], Validation Loss: 0.0337, Validation Accuracy: 0.9893\n",
      "Epoch [66/300], Training Loss: 0.0344\n",
      "Epoch [66/300], Validation Loss: 0.0333, Validation Accuracy: 0.9893\n",
      "Epoch [67/300], Training Loss: 0.0339\n",
      "Epoch [67/300], Validation Loss: 0.0328, Validation Accuracy: 0.9893\n",
      "Epoch [68/300], Training Loss: 0.0335\n",
      "Epoch [68/300], Validation Loss: 0.0323, Validation Accuracy: 0.9893\n",
      "Epoch [69/300], Training Loss: 0.0331\n",
      "Epoch [69/300], Validation Loss: 0.0319, Validation Accuracy: 0.9893\n",
      "Epoch [70/300], Training Loss: 0.0327\n",
      "Epoch [70/300], Validation Loss: 0.0315, Validation Accuracy: 0.9900\n",
      "Epoch [71/300], Training Loss: 0.0324\n",
      "Epoch [71/300], Validation Loss: 0.0311, Validation Accuracy: 0.9900\n",
      "Epoch [72/300], Training Loss: 0.0320\n",
      "Epoch [72/300], Validation Loss: 0.0307, Validation Accuracy: 0.9893\n",
      "Epoch [73/300], Training Loss: 0.0316\n",
      "Epoch [73/300], Validation Loss: 0.0303, Validation Accuracy: 0.9893\n",
      "Epoch [74/300], Training Loss: 0.0313\n",
      "Epoch [74/300], Validation Loss: 0.0299, Validation Accuracy: 0.9893\n",
      "Epoch [75/300], Training Loss: 0.0309\n",
      "Epoch [75/300], Validation Loss: 0.0296, Validation Accuracy: 0.9893\n",
      "Epoch [76/300], Training Loss: 0.0306\n",
      "Epoch [76/300], Validation Loss: 0.0292, Validation Accuracy: 0.9900\n",
      "Epoch [77/300], Training Loss: 0.0303\n",
      "Epoch [77/300], Validation Loss: 0.0289, Validation Accuracy: 0.9907\n",
      "Epoch [78/300], Training Loss: 0.0300\n",
      "Epoch [78/300], Validation Loss: 0.0286, Validation Accuracy: 0.9907\n",
      "Epoch [79/300], Training Loss: 0.0297\n",
      "Epoch [79/300], Validation Loss: 0.0282, Validation Accuracy: 0.9907\n",
      "Epoch [80/300], Training Loss: 0.0294\n",
      "Epoch [80/300], Validation Loss: 0.0279, Validation Accuracy: 0.9907\n",
      "Epoch [81/300], Training Loss: 0.0291\n",
      "Epoch [81/300], Validation Loss: 0.0276, Validation Accuracy: 0.9914\n",
      "Epoch [82/300], Training Loss: 0.0288\n",
      "Epoch [82/300], Validation Loss: 0.0273, Validation Accuracy: 0.9914\n",
      "Epoch [83/300], Training Loss: 0.0285\n",
      "Epoch [83/300], Validation Loss: 0.0270, Validation Accuracy: 0.9914\n",
      "Epoch [84/300], Training Loss: 0.0282\n",
      "Epoch [84/300], Validation Loss: 0.0267, Validation Accuracy: 0.9914\n",
      "Epoch [85/300], Training Loss: 0.0280\n",
      "Epoch [85/300], Validation Loss: 0.0264, Validation Accuracy: 0.9914\n",
      "Epoch [86/300], Training Loss: 0.0277\n",
      "Epoch [86/300], Validation Loss: 0.0262, Validation Accuracy: 0.9914\n",
      "Epoch [87/300], Training Loss: 0.0275\n",
      "Epoch [87/300], Validation Loss: 0.0259, Validation Accuracy: 0.9914\n",
      "Epoch [88/300], Training Loss: 0.0272\n",
      "Epoch [88/300], Validation Loss: 0.0256, Validation Accuracy: 0.9914\n",
      "Epoch [89/300], Training Loss: 0.0270\n",
      "Epoch [89/300], Validation Loss: 0.0254, Validation Accuracy: 0.9914\n",
      "Epoch [90/300], Training Loss: 0.0267\n",
      "Epoch [90/300], Validation Loss: 0.0251, Validation Accuracy: 0.9922\n",
      "Epoch [91/300], Training Loss: 0.0265\n",
      "Epoch [91/300], Validation Loss: 0.0249, Validation Accuracy: 0.9929\n",
      "Epoch [92/300], Training Loss: 0.0262\n",
      "Epoch [92/300], Validation Loss: 0.0246, Validation Accuracy: 0.9929\n",
      "Epoch [93/300], Training Loss: 0.0260\n",
      "Epoch [93/300], Validation Loss: 0.0244, Validation Accuracy: 0.9936\n",
      "Epoch [94/300], Training Loss: 0.0258\n",
      "Epoch [94/300], Validation Loss: 0.0241, Validation Accuracy: 0.9936\n",
      "Epoch [95/300], Training Loss: 0.0256\n",
      "Epoch [95/300], Validation Loss: 0.0239, Validation Accuracy: 0.9936\n",
      "Epoch [96/300], Training Loss: 0.0254\n",
      "Epoch [96/300], Validation Loss: 0.0237, Validation Accuracy: 0.9936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/300], Training Loss: 0.0251\n",
      "Epoch [97/300], Validation Loss: 0.0234, Validation Accuracy: 0.9936\n",
      "Epoch [98/300], Training Loss: 0.0249\n",
      "Epoch [98/300], Validation Loss: 0.0232, Validation Accuracy: 0.9936\n",
      "Epoch [99/300], Training Loss: 0.0247\n",
      "Epoch [99/300], Validation Loss: 0.0230, Validation Accuracy: 0.9936\n",
      "Epoch [100/300], Training Loss: 0.0245\n",
      "Epoch [100/300], Validation Loss: 0.0228, Validation Accuracy: 0.9936\n",
      "Epoch [101/300], Training Loss: 0.0243\n",
      "Epoch [101/300], Validation Loss: 0.0226, Validation Accuracy: 0.9936\n",
      "Epoch [102/300], Training Loss: 0.0241\n",
      "Epoch [102/300], Validation Loss: 0.0224, Validation Accuracy: 0.9943\n",
      "Epoch [103/300], Training Loss: 0.0239\n",
      "Epoch [103/300], Validation Loss: 0.0222, Validation Accuracy: 0.9943\n",
      "Epoch [104/300], Training Loss: 0.0237\n",
      "Epoch [104/300], Validation Loss: 0.0220, Validation Accuracy: 0.9943\n",
      "Epoch [105/300], Training Loss: 0.0235\n",
      "Epoch [105/300], Validation Loss: 0.0218, Validation Accuracy: 0.9943\n",
      "Epoch [106/300], Training Loss: 0.0234\n",
      "Epoch [106/300], Validation Loss: 0.0216, Validation Accuracy: 0.9943\n",
      "Epoch [107/300], Training Loss: 0.0232\n",
      "Epoch [107/300], Validation Loss: 0.0214, Validation Accuracy: 0.9943\n",
      "Epoch [108/300], Training Loss: 0.0230\n",
      "Epoch [108/300], Validation Loss: 0.0212, Validation Accuracy: 0.9943\n",
      "Epoch [109/300], Training Loss: 0.0228\n",
      "Epoch [109/300], Validation Loss: 0.0210, Validation Accuracy: 0.9943\n",
      "Epoch [110/300], Training Loss: 0.0226\n",
      "Epoch [110/300], Validation Loss: 0.0208, Validation Accuracy: 0.9950\n",
      "Epoch [111/300], Training Loss: 0.0225\n",
      "Epoch [111/300], Validation Loss: 0.0206, Validation Accuracy: 0.9950\n",
      "Epoch [112/300], Training Loss: 0.0223\n",
      "Epoch [112/300], Validation Loss: 0.0205, Validation Accuracy: 0.9950\n",
      "Epoch [113/300], Training Loss: 0.0221\n",
      "Epoch [113/300], Validation Loss: 0.0203, Validation Accuracy: 0.9950\n",
      "Epoch [114/300], Training Loss: 0.0220\n",
      "Epoch [114/300], Validation Loss: 0.0201, Validation Accuracy: 0.9950\n",
      "Epoch [115/300], Training Loss: 0.0218\n",
      "Epoch [115/300], Validation Loss: 0.0199, Validation Accuracy: 0.9950\n",
      "Epoch [116/300], Training Loss: 0.0216\n",
      "Epoch [116/300], Validation Loss: 0.0198, Validation Accuracy: 0.9950\n",
      "Epoch [117/300], Training Loss: 0.0215\n",
      "Epoch [117/300], Validation Loss: 0.0196, Validation Accuracy: 0.9950\n",
      "Epoch [118/300], Training Loss: 0.0213\n",
      "Epoch [118/300], Validation Loss: 0.0194, Validation Accuracy: 0.9950\n",
      "Epoch [119/300], Training Loss: 0.0212\n",
      "Epoch [119/300], Validation Loss: 0.0193, Validation Accuracy: 0.9957\n",
      "Epoch [120/300], Training Loss: 0.0210\n",
      "Epoch [120/300], Validation Loss: 0.0191, Validation Accuracy: 0.9964\n",
      "Epoch [121/300], Training Loss: 0.0209\n",
      "Epoch [121/300], Validation Loss: 0.0189, Validation Accuracy: 0.9964\n",
      "Epoch [122/300], Training Loss: 0.0207\n",
      "Epoch [122/300], Validation Loss: 0.0188, Validation Accuracy: 0.9964\n",
      "Epoch [123/300], Training Loss: 0.0206\n",
      "Epoch [123/300], Validation Loss: 0.0186, Validation Accuracy: 0.9964\n",
      "Epoch [124/300], Training Loss: 0.0204\n",
      "Epoch [124/300], Validation Loss: 0.0185, Validation Accuracy: 0.9964\n",
      "Epoch [125/300], Training Loss: 0.0203\n",
      "Epoch [125/300], Validation Loss: 0.0183, Validation Accuracy: 0.9964\n",
      "Epoch [126/300], Training Loss: 0.0201\n",
      "Epoch [126/300], Validation Loss: 0.0182, Validation Accuracy: 0.9964\n",
      "Epoch [127/300], Training Loss: 0.0200\n",
      "Epoch [127/300], Validation Loss: 0.0180, Validation Accuracy: 0.9964\n",
      "Epoch [128/300], Training Loss: 0.0199\n",
      "Epoch [128/300], Validation Loss: 0.0179, Validation Accuracy: 0.9964\n",
      "Epoch [129/300], Training Loss: 0.0197\n",
      "Epoch [129/300], Validation Loss: 0.0177, Validation Accuracy: 0.9964\n",
      "Epoch [130/300], Training Loss: 0.0196\n",
      "Epoch [130/300], Validation Loss: 0.0176, Validation Accuracy: 0.9964\n",
      "Epoch [131/300], Training Loss: 0.0194\n",
      "Epoch [131/300], Validation Loss: 0.0175, Validation Accuracy: 0.9964\n",
      "Epoch [132/300], Training Loss: 0.0193\n",
      "Epoch [132/300], Validation Loss: 0.0173, Validation Accuracy: 0.9964\n",
      "Epoch [133/300], Training Loss: 0.0192\n",
      "Epoch [133/300], Validation Loss: 0.0172, Validation Accuracy: 0.9964\n",
      "Epoch [134/300], Training Loss: 0.0191\n",
      "Epoch [134/300], Validation Loss: 0.0170, Validation Accuracy: 0.9964\n",
      "Epoch [135/300], Training Loss: 0.0189\n",
      "Epoch [135/300], Validation Loss: 0.0169, Validation Accuracy: 0.9964\n",
      "Epoch [136/300], Training Loss: 0.0188\n",
      "Epoch [136/300], Validation Loss: 0.0168, Validation Accuracy: 0.9964\n",
      "Epoch [137/300], Training Loss: 0.0187\n",
      "Epoch [137/300], Validation Loss: 0.0166, Validation Accuracy: 0.9964\n",
      "Epoch [138/300], Training Loss: 0.0186\n",
      "Epoch [138/300], Validation Loss: 0.0165, Validation Accuracy: 0.9964\n",
      "Epoch [139/300], Training Loss: 0.0184\n",
      "Epoch [139/300], Validation Loss: 0.0164, Validation Accuracy: 0.9964\n",
      "Epoch [140/300], Training Loss: 0.0183\n",
      "Epoch [140/300], Validation Loss: 0.0163, Validation Accuracy: 0.9964\n",
      "Epoch [141/300], Training Loss: 0.0182\n",
      "Epoch [141/300], Validation Loss: 0.0161, Validation Accuracy: 0.9964\n",
      "Epoch [142/300], Training Loss: 0.0181\n",
      "Epoch [142/300], Validation Loss: 0.0160, Validation Accuracy: 0.9964\n",
      "Epoch [143/300], Training Loss: 0.0180\n",
      "Epoch [143/300], Validation Loss: 0.0159, Validation Accuracy: 0.9964\n",
      "Epoch [144/300], Training Loss: 0.0178\n",
      "Epoch [144/300], Validation Loss: 0.0158, Validation Accuracy: 0.9964\n",
      "Epoch [145/300], Training Loss: 0.0177\n",
      "Epoch [145/300], Validation Loss: 0.0156, Validation Accuracy: 0.9964\n",
      "Epoch [146/300], Training Loss: 0.0176\n",
      "Epoch [146/300], Validation Loss: 0.0155, Validation Accuracy: 0.9964\n",
      "Epoch [147/300], Training Loss: 0.0175\n",
      "Epoch [147/300], Validation Loss: 0.0154, Validation Accuracy: 0.9964\n",
      "Epoch [148/300], Training Loss: 0.0174\n",
      "Epoch [148/300], Validation Loss: 0.0153, Validation Accuracy: 0.9964\n",
      "Epoch [149/300], Training Loss: 0.0173\n",
      "Epoch [149/300], Validation Loss: 0.0152, Validation Accuracy: 0.9964\n",
      "Epoch [150/300], Training Loss: 0.0172\n",
      "Epoch [150/300], Validation Loss: 0.0151, Validation Accuracy: 0.9964\n",
      "Epoch [151/300], Training Loss: 0.0171\n",
      "Epoch [151/300], Validation Loss: 0.0149, Validation Accuracy: 0.9964\n",
      "Epoch [152/300], Training Loss: 0.0170\n",
      "Epoch [152/300], Validation Loss: 0.0148, Validation Accuracy: 0.9964\n",
      "Epoch [153/300], Training Loss: 0.0169\n",
      "Epoch [153/300], Validation Loss: 0.0147, Validation Accuracy: 0.9964\n",
      "Epoch [154/300], Training Loss: 0.0168\n",
      "Epoch [154/300], Validation Loss: 0.0146, Validation Accuracy: 0.9964\n",
      "Epoch [155/300], Training Loss: 0.0167\n",
      "Epoch [155/300], Validation Loss: 0.0145, Validation Accuracy: 0.9971\n",
      "Epoch [156/300], Training Loss: 0.0166\n",
      "Epoch [156/300], Validation Loss: 0.0144, Validation Accuracy: 0.9971\n",
      "Epoch [157/300], Training Loss: 0.0165\n",
      "Epoch [157/300], Validation Loss: 0.0143, Validation Accuracy: 0.9979\n",
      "Epoch [158/300], Training Loss: 0.0164\n",
      "Epoch [158/300], Validation Loss: 0.0142, Validation Accuracy: 0.9979\n",
      "Epoch [159/300], Training Loss: 0.0163\n",
      "Epoch [159/300], Validation Loss: 0.0141, Validation Accuracy: 0.9979\n",
      "Epoch [160/300], Training Loss: 0.0162\n",
      "Epoch [160/300], Validation Loss: 0.0140, Validation Accuracy: 0.9979\n",
      "Epoch [161/300], Training Loss: 0.0161\n",
      "Epoch [161/300], Validation Loss: 0.0139, Validation Accuracy: 0.9979\n",
      "Epoch [162/300], Training Loss: 0.0160\n",
      "Epoch [162/300], Validation Loss: 0.0138, Validation Accuracy: 0.9979\n",
      "Epoch [163/300], Training Loss: 0.0159\n",
      "Epoch [163/300], Validation Loss: 0.0137, Validation Accuracy: 0.9979\n",
      "Epoch [164/300], Training Loss: 0.0158\n",
      "Epoch [164/300], Validation Loss: 0.0136, Validation Accuracy: 0.9979\n",
      "Epoch [165/300], Training Loss: 0.0157\n",
      "Epoch [165/300], Validation Loss: 0.0135, Validation Accuracy: 0.9979\n",
      "Epoch [166/300], Training Loss: 0.0156\n",
      "Epoch [166/300], Validation Loss: 0.0134, Validation Accuracy: 0.9979\n",
      "Epoch [167/300], Training Loss: 0.0155\n",
      "Epoch [167/300], Validation Loss: 0.0133, Validation Accuracy: 0.9979\n",
      "Epoch [168/300], Training Loss: 0.0154\n",
      "Epoch [168/300], Validation Loss: 0.0132, Validation Accuracy: 0.9979\n",
      "Epoch [169/300], Training Loss: 0.0153\n",
      "Epoch [169/300], Validation Loss: 0.0131, Validation Accuracy: 0.9979\n",
      "Epoch [170/300], Training Loss: 0.0152\n",
      "Epoch [170/300], Validation Loss: 0.0130, Validation Accuracy: 0.9979\n",
      "Epoch [171/300], Training Loss: 0.0151\n",
      "Epoch [171/300], Validation Loss: 0.0129, Validation Accuracy: 0.9979\n",
      "Epoch [172/300], Training Loss: 0.0151\n",
      "Epoch [172/300], Validation Loss: 0.0129, Validation Accuracy: 0.9979\n",
      "Epoch [173/300], Training Loss: 0.0150\n",
      "Epoch [173/300], Validation Loss: 0.0128, Validation Accuracy: 0.9979\n",
      "Epoch [174/300], Training Loss: 0.0149\n",
      "Epoch [174/300], Validation Loss: 0.0127, Validation Accuracy: 0.9979\n",
      "Epoch [175/300], Training Loss: 0.0148\n",
      "Epoch [175/300], Validation Loss: 0.0126, Validation Accuracy: 0.9979\n",
      "Epoch [176/300], Training Loss: 0.0147\n",
      "Epoch [176/300], Validation Loss: 0.0125, Validation Accuracy: 0.9979\n",
      "Epoch [177/300], Training Loss: 0.0146\n",
      "Epoch [177/300], Validation Loss: 0.0124, Validation Accuracy: 0.9979\n",
      "Epoch [178/300], Training Loss: 0.0145\n",
      "Epoch [178/300], Validation Loss: 0.0123, Validation Accuracy: 0.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [179/300], Training Loss: 0.0145\n",
      "Epoch [179/300], Validation Loss: 0.0122, Validation Accuracy: 0.9979\n",
      "Epoch [180/300], Training Loss: 0.0144\n",
      "Epoch [180/300], Validation Loss: 0.0122, Validation Accuracy: 0.9979\n",
      "Epoch [181/300], Training Loss: 0.0143\n",
      "Epoch [181/300], Validation Loss: 0.0121, Validation Accuracy: 0.9979\n",
      "Epoch [182/300], Training Loss: 0.0142\n",
      "Epoch [182/300], Validation Loss: 0.0120, Validation Accuracy: 0.9979\n",
      "Epoch [183/300], Training Loss: 0.0141\n",
      "Epoch [183/300], Validation Loss: 0.0119, Validation Accuracy: 0.9979\n",
      "Epoch [184/300], Training Loss: 0.0141\n",
      "Epoch [184/300], Validation Loss: 0.0118, Validation Accuracy: 0.9979\n",
      "Epoch [185/300], Training Loss: 0.0140\n",
      "Epoch [185/300], Validation Loss: 0.0118, Validation Accuracy: 0.9979\n",
      "Epoch [186/300], Training Loss: 0.0139\n",
      "Epoch [186/300], Validation Loss: 0.0117, Validation Accuracy: 0.9979\n",
      "Epoch [187/300], Training Loss: 0.0138\n",
      "Epoch [187/300], Validation Loss: 0.0116, Validation Accuracy: 0.9979\n",
      "Epoch [188/300], Training Loss: 0.0138\n",
      "Epoch [188/300], Validation Loss: 0.0115, Validation Accuracy: 0.9979\n",
      "Epoch [189/300], Training Loss: 0.0137\n",
      "Epoch [189/300], Validation Loss: 0.0115, Validation Accuracy: 0.9979\n",
      "Epoch [190/300], Training Loss: 0.0136\n",
      "Epoch [190/300], Validation Loss: 0.0114, Validation Accuracy: 0.9979\n",
      "Epoch [191/300], Training Loss: 0.0135\n",
      "Epoch [191/300], Validation Loss: 0.0113, Validation Accuracy: 0.9979\n",
      "Epoch [192/300], Training Loss: 0.0135\n",
      "Epoch [192/300], Validation Loss: 0.0112, Validation Accuracy: 0.9979\n",
      "Epoch [193/300], Training Loss: 0.0134\n",
      "Epoch [193/300], Validation Loss: 0.0112, Validation Accuracy: 0.9979\n",
      "Epoch [194/300], Training Loss: 0.0133\n",
      "Epoch [194/300], Validation Loss: 0.0111, Validation Accuracy: 0.9979\n",
      "Epoch [195/300], Training Loss: 0.0132\n",
      "Epoch [195/300], Validation Loss: 0.0110, Validation Accuracy: 0.9979\n",
      "Epoch [196/300], Training Loss: 0.0132\n",
      "Epoch [196/300], Validation Loss: 0.0109, Validation Accuracy: 0.9979\n",
      "Epoch [197/300], Training Loss: 0.0131\n",
      "Epoch [197/300], Validation Loss: 0.0109, Validation Accuracy: 0.9986\n",
      "Epoch [198/300], Training Loss: 0.0130\n",
      "Epoch [198/300], Validation Loss: 0.0108, Validation Accuracy: 0.9986\n",
      "Epoch [199/300], Training Loss: 0.0130\n",
      "Epoch [199/300], Validation Loss: 0.0107, Validation Accuracy: 0.9986\n",
      "Epoch [200/300], Training Loss: 0.0129\n",
      "Epoch [200/300], Validation Loss: 0.0107, Validation Accuracy: 0.9986\n",
      "Epoch [201/300], Training Loss: 0.0128\n",
      "Epoch [201/300], Validation Loss: 0.0106, Validation Accuracy: 0.9986\n",
      "Epoch [202/300], Training Loss: 0.0127\n",
      "Epoch [202/300], Validation Loss: 0.0105, Validation Accuracy: 0.9986\n",
      "Epoch [203/300], Training Loss: 0.0127\n",
      "Epoch [203/300], Validation Loss: 0.0105, Validation Accuracy: 0.9986\n",
      "Epoch [204/300], Training Loss: 0.0126\n",
      "Epoch [204/300], Validation Loss: 0.0104, Validation Accuracy: 0.9986\n",
      "Epoch [205/300], Training Loss: 0.0125\n",
      "Epoch [205/300], Validation Loss: 0.0103, Validation Accuracy: 0.9986\n",
      "Epoch [206/300], Training Loss: 0.0125\n",
      "Epoch [206/300], Validation Loss: 0.0103, Validation Accuracy: 0.9986\n",
      "Epoch [207/300], Training Loss: 0.0124\n",
      "Epoch [207/300], Validation Loss: 0.0102, Validation Accuracy: 0.9986\n",
      "Epoch [208/300], Training Loss: 0.0123\n",
      "Epoch [208/300], Validation Loss: 0.0101, Validation Accuracy: 0.9986\n",
      "Epoch [209/300], Training Loss: 0.0123\n",
      "Epoch [209/300], Validation Loss: 0.0101, Validation Accuracy: 0.9986\n",
      "Epoch [210/300], Training Loss: 0.0122\n",
      "Epoch [210/300], Validation Loss: 0.0100, Validation Accuracy: 0.9986\n",
      "Epoch [211/300], Training Loss: 0.0121\n",
      "Epoch [211/300], Validation Loss: 0.0099, Validation Accuracy: 0.9986\n",
      "Epoch [212/300], Training Loss: 0.0121\n",
      "Epoch [212/300], Validation Loss: 0.0099, Validation Accuracy: 0.9986\n",
      "Epoch [213/300], Training Loss: 0.0120\n",
      "Epoch [213/300], Validation Loss: 0.0098, Validation Accuracy: 0.9986\n",
      "Epoch [214/300], Training Loss: 0.0120\n",
      "Epoch [214/300], Validation Loss: 0.0098, Validation Accuracy: 0.9986\n",
      "Epoch [215/300], Training Loss: 0.0119\n",
      "Epoch [215/300], Validation Loss: 0.0097, Validation Accuracy: 0.9986\n",
      "Epoch [216/300], Training Loss: 0.0118\n",
      "Epoch [216/300], Validation Loss: 0.0096, Validation Accuracy: 0.9986\n",
      "Epoch [217/300], Training Loss: 0.0118\n",
      "Epoch [217/300], Validation Loss: 0.0096, Validation Accuracy: 0.9986\n",
      "Epoch [218/300], Training Loss: 0.0117\n",
      "Epoch [218/300], Validation Loss: 0.0095, Validation Accuracy: 0.9986\n",
      "Epoch [219/300], Training Loss: 0.0116\n",
      "Epoch [219/300], Validation Loss: 0.0095, Validation Accuracy: 0.9986\n",
      "Epoch [220/300], Training Loss: 0.0116\n",
      "Epoch [220/300], Validation Loss: 0.0094, Validation Accuracy: 0.9986\n",
      "Epoch [221/300], Training Loss: 0.0115\n",
      "Epoch [221/300], Validation Loss: 0.0093, Validation Accuracy: 0.9986\n",
      "Epoch [222/300], Training Loss: 0.0115\n",
      "Epoch [222/300], Validation Loss: 0.0093, Validation Accuracy: 0.9986\n",
      "Epoch [223/300], Training Loss: 0.0114\n",
      "Epoch [223/300], Validation Loss: 0.0092, Validation Accuracy: 0.9986\n",
      "Epoch [224/300], Training Loss: 0.0113\n",
      "Epoch [224/300], Validation Loss: 0.0092, Validation Accuracy: 0.9986\n",
      "Epoch [225/300], Training Loss: 0.0113\n",
      "Epoch [225/300], Validation Loss: 0.0091, Validation Accuracy: 0.9986\n",
      "Epoch [226/300], Training Loss: 0.0112\n",
      "Epoch [226/300], Validation Loss: 0.0091, Validation Accuracy: 0.9986\n",
      "Epoch [227/300], Training Loss: 0.0112\n",
      "Epoch [227/300], Validation Loss: 0.0090, Validation Accuracy: 0.9986\n",
      "Epoch [228/300], Training Loss: 0.0111\n",
      "Epoch [228/300], Validation Loss: 0.0090, Validation Accuracy: 0.9986\n",
      "Epoch [229/300], Training Loss: 0.0111\n",
      "Epoch [229/300], Validation Loss: 0.0089, Validation Accuracy: 0.9986\n",
      "Epoch [230/300], Training Loss: 0.0110\n",
      "Epoch [230/300], Validation Loss: 0.0088, Validation Accuracy: 0.9986\n",
      "Epoch [231/300], Training Loss: 0.0109\n",
      "Epoch [231/300], Validation Loss: 0.0088, Validation Accuracy: 0.9986\n",
      "Epoch [232/300], Training Loss: 0.0109\n",
      "Epoch [232/300], Validation Loss: 0.0087, Validation Accuracy: 0.9986\n",
      "Epoch [233/300], Training Loss: 0.0108\n",
      "Epoch [233/300], Validation Loss: 0.0087, Validation Accuracy: 0.9986\n",
      "Epoch [234/300], Training Loss: 0.0108\n",
      "Epoch [234/300], Validation Loss: 0.0086, Validation Accuracy: 0.9986\n",
      "Epoch [235/300], Training Loss: 0.0107\n",
      "Epoch [235/300], Validation Loss: 0.0086, Validation Accuracy: 0.9986\n",
      "Epoch [236/300], Training Loss: 0.0107\n",
      "Epoch [236/300], Validation Loss: 0.0085, Validation Accuracy: 0.9986\n",
      "Epoch [237/300], Training Loss: 0.0106\n",
      "Epoch [237/300], Validation Loss: 0.0085, Validation Accuracy: 0.9986\n",
      "Epoch [238/300], Training Loss: 0.0106\n",
      "Epoch [238/300], Validation Loss: 0.0084, Validation Accuracy: 0.9986\n",
      "Epoch [239/300], Training Loss: 0.0105\n",
      "Epoch [239/300], Validation Loss: 0.0084, Validation Accuracy: 0.9986\n",
      "Epoch [240/300], Training Loss: 0.0105\n",
      "Epoch [240/300], Validation Loss: 0.0083, Validation Accuracy: 0.9986\n",
      "Epoch [241/300], Training Loss: 0.0104\n",
      "Epoch [241/300], Validation Loss: 0.0083, Validation Accuracy: 0.9986\n",
      "Epoch [242/300], Training Loss: 0.0104\n",
      "Epoch [242/300], Validation Loss: 0.0082, Validation Accuracy: 0.9986\n",
      "Epoch [243/300], Training Loss: 0.0103\n",
      "Epoch [243/300], Validation Loss: 0.0082, Validation Accuracy: 0.9986\n",
      "Epoch [244/300], Training Loss: 0.0102\n",
      "Epoch [244/300], Validation Loss: 0.0082, Validation Accuracy: 0.9986\n",
      "Epoch [245/300], Training Loss: 0.0102\n",
      "Epoch [245/300], Validation Loss: 0.0081, Validation Accuracy: 0.9986\n",
      "Epoch [246/300], Training Loss: 0.0101\n",
      "Epoch [246/300], Validation Loss: 0.0081, Validation Accuracy: 0.9986\n",
      "Epoch [247/300], Training Loss: 0.0101\n",
      "Epoch [247/300], Validation Loss: 0.0080, Validation Accuracy: 0.9986\n",
      "Epoch [248/300], Training Loss: 0.0100\n",
      "Epoch [248/300], Validation Loss: 0.0080, Validation Accuracy: 0.9986\n",
      "Epoch [249/300], Training Loss: 0.0100\n",
      "Epoch [249/300], Validation Loss: 0.0079, Validation Accuracy: 0.9986\n",
      "Epoch [250/300], Training Loss: 0.0099\n",
      "Epoch [250/300], Validation Loss: 0.0079, Validation Accuracy: 0.9986\n",
      "Epoch [251/300], Training Loss: 0.0099\n",
      "Epoch [251/300], Validation Loss: 0.0078, Validation Accuracy: 0.9986\n",
      "Epoch [252/300], Training Loss: 0.0098\n",
      "Epoch [252/300], Validation Loss: 0.0078, Validation Accuracy: 0.9986\n",
      "Epoch [253/300], Training Loss: 0.0098\n",
      "Epoch [253/300], Validation Loss: 0.0078, Validation Accuracy: 0.9986\n",
      "Epoch [254/300], Training Loss: 0.0097\n",
      "Epoch [254/300], Validation Loss: 0.0077, Validation Accuracy: 0.9986\n",
      "Epoch [255/300], Training Loss: 0.0097\n",
      "Epoch [255/300], Validation Loss: 0.0077, Validation Accuracy: 0.9986\n",
      "Epoch [256/300], Training Loss: 0.0097\n",
      "Epoch [256/300], Validation Loss: 0.0076, Validation Accuracy: 0.9986\n",
      "Epoch [257/300], Training Loss: 0.0096\n",
      "Epoch [257/300], Validation Loss: 0.0076, Validation Accuracy: 0.9986\n",
      "Epoch [258/300], Training Loss: 0.0096\n",
      "Epoch [258/300], Validation Loss: 0.0075, Validation Accuracy: 0.9986\n",
      "Epoch [259/300], Training Loss: 0.0095\n",
      "Epoch [259/300], Validation Loss: 0.0075, Validation Accuracy: 0.9986\n",
      "Epoch [260/300], Training Loss: 0.0095\n",
      "Epoch [260/300], Validation Loss: 0.0075, Validation Accuracy: 0.9986\n",
      "Epoch [261/300], Training Loss: 0.0094\n",
      "Epoch [261/300], Validation Loss: 0.0074, Validation Accuracy: 0.9986\n",
      "Epoch [262/300], Training Loss: 0.0094\n",
      "Epoch [262/300], Validation Loss: 0.0074, Validation Accuracy: 0.9986\n",
      "Epoch [263/300], Training Loss: 0.0093\n",
      "Epoch [263/300], Validation Loss: 0.0073, Validation Accuracy: 0.9986\n",
      "Epoch [264/300], Training Loss: 0.0093\n",
      "Epoch [264/300], Validation Loss: 0.0073, Validation Accuracy: 0.9986\n",
      "Epoch [265/300], Training Loss: 0.0092\n",
      "Epoch [265/300], Validation Loss: 0.0073, Validation Accuracy: 0.9986\n",
      "Epoch [266/300], Training Loss: 0.0092\n",
      "Epoch [266/300], Validation Loss: 0.0072, Validation Accuracy: 0.9986\n",
      "Epoch [267/300], Training Loss: 0.0091\n",
      "Epoch [267/300], Validation Loss: 0.0072, Validation Accuracy: 0.9986\n",
      "Epoch [268/300], Training Loss: 0.0091\n",
      "Epoch [268/300], Validation Loss: 0.0071, Validation Accuracy: 0.9986\n",
      "Epoch [269/300], Training Loss: 0.0091\n",
      "Epoch [269/300], Validation Loss: 0.0071, Validation Accuracy: 0.9986\n",
      "Epoch [270/300], Training Loss: 0.0090\n",
      "Epoch [270/300], Validation Loss: 0.0071, Validation Accuracy: 0.9986\n",
      "Epoch [271/300], Training Loss: 0.0090\n",
      "Epoch [271/300], Validation Loss: 0.0070, Validation Accuracy: 0.9986\n",
      "Epoch [272/300], Training Loss: 0.0089\n",
      "Epoch [272/300], Validation Loss: 0.0070, Validation Accuracy: 0.9986\n",
      "Epoch [273/300], Training Loss: 0.0089\n",
      "Epoch [273/300], Validation Loss: 0.0070, Validation Accuracy: 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [274/300], Training Loss: 0.0088\n",
      "Epoch [274/300], Validation Loss: 0.0069, Validation Accuracy: 0.9986\n",
      "Epoch [275/300], Training Loss: 0.0088\n",
      "Epoch [275/300], Validation Loss: 0.0069, Validation Accuracy: 0.9986\n",
      "Epoch [276/300], Training Loss: 0.0088\n",
      "Epoch [276/300], Validation Loss: 0.0068, Validation Accuracy: 0.9986\n",
      "Epoch [277/300], Training Loss: 0.0087\n",
      "Epoch [277/300], Validation Loss: 0.0068, Validation Accuracy: 0.9986\n",
      "Epoch [278/300], Training Loss: 0.0087\n",
      "Epoch [278/300], Validation Loss: 0.0068, Validation Accuracy: 0.9986\n",
      "Epoch [279/300], Training Loss: 0.0086\n",
      "Epoch [279/300], Validation Loss: 0.0067, Validation Accuracy: 0.9986\n",
      "Epoch [280/300], Training Loss: 0.0086\n",
      "Epoch [280/300], Validation Loss: 0.0067, Validation Accuracy: 0.9986\n",
      "Epoch [281/300], Training Loss: 0.0085\n",
      "Epoch [281/300], Validation Loss: 0.0067, Validation Accuracy: 0.9986\n",
      "Epoch [282/300], Training Loss: 0.0085\n",
      "Epoch [282/300], Validation Loss: 0.0066, Validation Accuracy: 0.9986\n",
      "Epoch [283/300], Training Loss: 0.0085\n",
      "Epoch [283/300], Validation Loss: 0.0066, Validation Accuracy: 0.9993\n",
      "Epoch [284/300], Training Loss: 0.0084\n",
      "Epoch [284/300], Validation Loss: 0.0066, Validation Accuracy: 0.9993\n",
      "Epoch [285/300], Training Loss: 0.0084\n",
      "Epoch [285/300], Validation Loss: 0.0065, Validation Accuracy: 0.9993\n",
      "Epoch [286/300], Training Loss: 0.0083\n",
      "Epoch [286/300], Validation Loss: 0.0065, Validation Accuracy: 0.9993\n",
      "Epoch [287/300], Training Loss: 0.0083\n",
      "Epoch [287/300], Validation Loss: 0.0065, Validation Accuracy: 0.9993\n",
      "Epoch [288/300], Training Loss: 0.0083\n",
      "Epoch [288/300], Validation Loss: 0.0064, Validation Accuracy: 0.9993\n",
      "Epoch [289/300], Training Loss: 0.0082\n",
      "Epoch [289/300], Validation Loss: 0.0064, Validation Accuracy: 0.9993\n",
      "Epoch [290/300], Training Loss: 0.0082\n",
      "Epoch [290/300], Validation Loss: 0.0064, Validation Accuracy: 0.9993\n",
      "Epoch [291/300], Training Loss: 0.0081\n",
      "Epoch [291/300], Validation Loss: 0.0063, Validation Accuracy: 0.9993\n",
      "Epoch [292/300], Training Loss: 0.0081\n",
      "Epoch [292/300], Validation Loss: 0.0063, Validation Accuracy: 0.9993\n",
      "Epoch [293/300], Training Loss: 0.0081\n",
      "Epoch [293/300], Validation Loss: 0.0063, Validation Accuracy: 0.9993\n",
      "Epoch [294/300], Training Loss: 0.0080\n",
      "Epoch [294/300], Validation Loss: 0.0062, Validation Accuracy: 0.9993\n",
      "Epoch [295/300], Training Loss: 0.0080\n",
      "Epoch [295/300], Validation Loss: 0.0062, Validation Accuracy: 0.9993\n",
      "Epoch [296/300], Training Loss: 0.0080\n",
      "Epoch [296/300], Validation Loss: 0.0062, Validation Accuracy: 0.9993\n",
      "Epoch [297/300], Training Loss: 0.0079\n",
      "Epoch [297/300], Validation Loss: 0.0061, Validation Accuracy: 0.9993\n",
      "Epoch [298/300], Training Loss: 0.0079\n",
      "Epoch [298/300], Validation Loss: 0.0061, Validation Accuracy: 1.0000\n",
      "Epoch [299/300], Training Loss: 0.0078\n",
      "Epoch [299/300], Validation Loss: 0.0061, Validation Accuracy: 1.0000\n",
      "Epoch [300/300], Training Loss: 0.0078\n",
      "Epoch [300/300], Validation Loss: 0.0061, Validation Accuracy: 1.0000\n",
      "Test Accuracy: 0.9978617248752673\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features_df = pd.read_csv('features.csv')\n",
    "\n",
    "# Extract the MFCC features and corresponding labels\n",
    "X = features_df.iloc[:, :-1].values  # Assuming MFCC features are in columns 1 to n\n",
    "y = features_df.iloc[:, -1].values  # Assuming labels are in the first column\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the labels\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the RNN model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64  # You can adjust this as needed\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 300  # You can adjust this as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    outputs = model(X_train_tensor.unsqueeze(1))  # Add an extra dimension for sequence length\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs.squeeze(), y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor.unsqueeze(1))\n",
    "        val_loss = criterion(val_outputs.squeeze(), y_val)\n",
    "        _, val_predicted = torch.max(val_outputs, 1)\n",
    "        val_accuracy = accuracy_score(y_val.numpy(), val_predicted.numpy())\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss.item():.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor.unsqueeze(1))\n",
    "    _, test_predicted = torch.max(test_outputs, 1)\n",
    "    test_accuracy = accuracy_score(y_test.numpy(), test_predicted.numpy())\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f34531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pytorch_model_new.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained SVM model to a file\n",
    "joblib.dump(model, 'pytorch_model_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ef045c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in something directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:03<00:00,  3.21s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "\n",
    "        # MFCC (Mel-frequency cepstral coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_processed = np.mean(mfccs.T, axis=0)\n",
    "\n",
    "        # Chroma feature\n",
    "        chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral contrast\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Spectral centroid\n",
    "        spectral_centroids = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Zero-crossing rate\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio).T, axis=0)\n",
    "\n",
    "        # Spectral rolloff\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sample_rate).T, axis=0)\n",
    "\n",
    "        # Combine all features into a 1D array\n",
    "        features = np.hstack([mfccs_processed, chroma_stft, spectral_contrast, spectral_centroids, zero_crossing_rate, spectral_rolloff])\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_name}\")\n",
    "        return None\n",
    "\n",
    "# Specify the directories containing the .mp3 files\n",
    "directories = ['something']\n",
    "\n",
    "# Create an empty DataFrame to store the features\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "for directory in directories:\n",
    "    print(f\"Processing files in {directory} directory\")\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                features = extract_features(file_path)\n",
    "                # Append the features to the DataFrame as a new row\n",
    "                if features is not None:\n",
    "                    features_series = pd.Series(features)\n",
    "                    features_df = pd.concat([features_df, features_series], axis=0)  # Concatenate along rows (axis=0)\n",
    "            except Exception as e:\n",
    "                print(f\"Error encountered while processing file: {file_path}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "# Rename the DataFrame columns as needed\n",
    "# features_df.columns = [list_of_feature_names]\n",
    "\n",
    "# Now, you have the features in the 'features_df' DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b15a22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-224.141861</td>\n",
       "      <td>123.548615</td>\n",
       "      <td>-11.934964</td>\n",
       "      <td>35.14872</td>\n",
       "      <td>-2.978472</td>\n",
       "      <td>11.988633</td>\n",
       "      <td>-10.192609</td>\n",
       "      <td>7.214376</td>\n",
       "      <td>-13.9877</td>\n",
       "      <td>1.976113</td>\n",
       "      <td>...</td>\n",
       "      <td>20.868756</td>\n",
       "      <td>15.711451</td>\n",
       "      <td>19.730115</td>\n",
       "      <td>19.38868</td>\n",
       "      <td>19.780333</td>\n",
       "      <td>19.137458</td>\n",
       "      <td>41.547228</td>\n",
       "      <td>1692.69833</td>\n",
       "      <td>0.082245</td>\n",
       "      <td>3374.557483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2         3         4          5   \\\n",
       "0 -224.141861  123.548615 -11.934964  35.14872 -2.978472  11.988633   \n",
       "\n",
       "          6         7        8         9   ...         52         53  \\\n",
       "0 -10.192609  7.214376 -13.9877  1.976113  ...  20.868756  15.711451   \n",
       "\n",
       "          54        55         56         57         58          59        60  \\\n",
       "0  19.730115  19.38868  19.780333  19.137458  41.547228  1692.69833  0.082245   \n",
       "\n",
       "            61  \n",
       "0  3374.557483  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new= features_df.T\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f74bd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model architecture first\n",
    "loaded_model = RNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Load the trained weights\n",
    "loaded_model.load_state_dict(torch.load('rnn_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf485ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "loaded_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Assuming you have new data in X_new (make sure to preprocess it the same way as the training data)\n",
    "X_new = scaler.transform(X_new)  # Standardize the new data\n",
    "X_new_tensor = torch.tensor(X_new, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    new_outputs = loaded_model(X_new_tensor.unsqueeze(1))\n",
    "    _, new_predicted = torch.max(new_outputs, 1)\n",
    "\n",
    "# 'new_predicted' now contains the predicted class labels for your new data\n",
    "print(new_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f140f9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
